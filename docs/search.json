[
  {
    "objectID": "tipsheet.html",
    "href": "tipsheet.html",
    "title": "431 Project B Tips",
    "section": "",
    "text": "I wanted to pass along these tips, most of which have came up in assessing last year’s projects.\n\nThis should be a good set of things to review (along with the Project B Checklist) as you’re preparing your final materials for submission."
  },
  {
    "objectID": "tipsheet.html#what-is-this",
    "href": "tipsheet.html#what-is-this",
    "title": "431 Project B Tips",
    "section": "",
    "text": "I wanted to pass along these tips, most of which have came up in assessing last year’s projects.\n\nThis should be a good set of things to review (along with the Project B Checklist) as you’re preparing your final materials for submission."
  },
  {
    "objectID": "tipsheet.html#yaml-and-setup-issues",
    "href": "tipsheet.html#yaml-and-setup-issues",
    "title": "431 Project B Tips",
    "section": "YAML and Setup issues",
    "text": "YAML and Setup issues\n\nNo hashtags preceding R results. I would like you to be sure that your R output is not preceded by hashtags. The easiest way to ensure this is to include the following code at the top of your code, where you load your R packages.\n\nknitr::opts_chunk$set(comment = NA)\n\nTheming gg-Plots. I would like you to use either theme_bw() or theme_light() globally, rather than including it in the code of every individual plot you build. So include something like\n\ntheme_set(theme_bw())\nimmediately after you load the tidyverse, and then don’t include theming of this sort in your individual plots, unless you are deliberately adding some specialized theming elements for a specific plot.\n\nClean List of R Packages. Your list of R packages should be clean for each study, which means:\n\n\ntidyverse is loaded last\nnone of the core tidyverse packages (core list is here) are loaded\nall packages you will load for this study are in one place\nno packages are loaded that you don’t use in your work."
  },
  {
    "objectID": "tipsheet.html#general-issues",
    "href": "tipsheet.html#general-issues",
    "title": "431 Project B Tips",
    "section": "General Issues",
    "text": "General Issues\n\nCheck your HTML for plot-text transition problems. One of the hardest things to get people to do is add empty lines in R Markdown after they create a plot or heading. Forgetting to do this can cause your plots to show up in the HTML with the start of the next paragraph shown to the right of the plot instead of below the plot. Make sure you avoid this mistake.\nMissing Data Mechanism and Dealing with Missingness. You need to have an explicit statement about your assumed missing data mechanism, including either the term MCAR, MAR or MNAR, in both Study 1 and Study 2, and you have to be specific about what you’ve done. This should be part of your HTML file everywhere where you impute (as in Study 2 variables other than your outcome and key predictor) or filter to complete cases (as in Study 1 and with your Study 2 outcome and key predictor). None of your analyses (in Study 1 or Study 2) should involve missing values: either you should have imputed missing values or you should have filtered to complete cases.\nSpell check doesn’t check headings and subheadings. Using spell check in R Studio is trivial (just hit F7) and important, but be aware that you still need to read your HTML to be sure that you don’t have problems. A particular issue is that the spell check doesn’t check your headings and subheadings so you’ll want to pay especially close attention to those pieces. In particular, I’ve seen several people misspell the word “Transformations” in section 6 of Study 2.\nYour confidence level is 90%, not 95%. All of Project B uses a 90% confidence level, so the phrase “p &lt; 0.05” is 100% irrelevant to this work. If you must compare a p value to something, be sure it is 0.10. I would also strongly suggest you search through your work and eliminate the terms “statistical significance” and even “significant” unless you have a very good reason to include them.\nOrder multi-categorical factors properly. Please respect the ordering of multicategorical variables, especially in Analyses C and E for Study 1. Be sure that you adjust the levels of your factor so that they use the natural order of the variable. If you have a nominal multi-categorical variable, like race/ethnicity, in Study 2, then I suggest you order the levels of that factor variable from largest to smallest in terms of number of subjects, so that the baseline group will be the one that appears most frequently in your data.\nDon’t change numeric variables to factors. If you change a numeric variable to a factor, and then change it back into a numeric variable, that will create many, many problems. Don’t do that. Instead, create a new factor variable if you’re going to convert a numeric variable into categories."
  },
  {
    "objectID": "tipsheet.html#nhanes-issues",
    "href": "tipsheet.html#nhanes-issues",
    "title": "431 Project B Tips",
    "section": "NHANES issues",
    "text": "NHANES issues\n\nNHANES isn’t a random sample. Don’t suggest or state that it is. So the NHANES sampling procedure is a limitation in terms of you cannot really generalize to the US population with NHANES unless you use survey weighting.\nSpecify your approach if not standard. If you’re using NHANES data but either not using the 2017-March 2020 data, or not using adults ages 21-79, be sure that you’ve made that abundantly clear everywhere where it’s relevant, including at least in the Data Description section for Study 1 and Study 2."
  },
  {
    "objectID": "tipsheet.html#study-1-issues",
    "href": "tipsheet.html#study-1-issues",
    "title": "431 Project B Tips",
    "section": "Study 1 Issues",
    "text": "Study 1 Issues\n\nStudy 1 Analyses must stand on their own. Each of your four Study 1 Analyses should stand on its own, in the sense that you should specify the relevant group of subjects, the exposure and the outcome in words at the start of each of those analyses. Please label these as Analysis A, B, C, D or E, (leaving out one, of course) as I did in building the assignment.\nDescribe the direction and size of estimated effects. In Project B, you should have no statements about statistical significance or any synonym. Estimate effects whenever possible, including a confidence interval. This is easy for Study 2 and for Study 1 Analyses A, B, and D, I think, but more challenging for C and E. Be sure to carefully focus your description of your result on the direction and size of the effect you estimate, in the context of your problem.\n\n\nFor instance, a terrible sentence in Analysis B would be something like “We saw a significant difference between males and females on mean systolic blood pressure.”\nA better sentence would be something like “The mean systolic blood pressure for males was 3 mm Hg higher than that of females, with a 90% CI of (1, 5).” Notice that this better sentence includes the actual units of measurement, and not something generic like “points”.\n\n\nPaired vs. Independent Samples. In Analyses A and B for Study 1, be sure that you provide a logical argument near the top of your work for why the data you are studying use (in Analysis A, paired) (in Analysis B, independent) samples.\nSimplifying Conclusions in Analysis D. In Analysis D of Study 1, in writing up your conclusions after forming an appropriate 2x2 table, and specifying the probabilities of obtaining your outcome within each exposure group as estimated at the top of the table, it is completely sufficient to provide your interpretation of either:\n\n\nthe relative risk and the odds ratio and their confidence intervals, or\nthe relative risk and the difference in probabilities, with their confidence intervals.\n\n\nDescribe some percentages in Analysis E. In Analysis E for Study 1, you should focus your interpretation of the result from your table and chi-square test on a comparison of interesting percentages from your table, in addition to the p value and a visualization of the results."
  },
  {
    "objectID": "tipsheet.html#study-2-issues",
    "href": "tipsheet.html#study-2-issues",
    "title": "431 Project B Tips",
    "section": "Study 2 Issues",
    "text": "Study 2 Issues\n\nResidual Plots should be tall. When building residual plots, whether with check_model() or something else, make them tall, by incorporating r, fig.height = 8 into your chunk header for that code. For example, this is the default size:\n\n\nm1 &lt;- lm(mpg ~ disp + wt, data = mtcars)\ncheck_model(m1)\n\n\n\n\n\n\n\n\nand below is what you get if you add #| fig.height: 8 at the start of the code chunk.\n\nm1 &lt;- lm(mpg ~ disp + wt, data = mtcars)\ncheck_model(m1)\n\n\n\n\n\n\n\n\nThis helps us see things more effectively, especially with large sample sizes in the plots. So please do it.\n\nBox-Cox. In Study 2, in the Transformation of Outcome section, please show the Box-Cox analysis immediately after the starting graphical summary (as opposed to the strange approach I used in the template) and then either use it (which is fine) or specify why you’ve decided not to use it. Remember that a Box-Cox \\(\\lambda\\) near 0 suggests a logarithmic transformation, and that a Box-Cox \\(\\lambda\\) of 1 indicates no transformation.\nUsing Validated R-Square. In Study 2, you should use the validated R-square you develop in section 10.3.2 as part of your discussion in both Sections 10.4 and 11.1. (in addition to whatever else you decide to use) to help describe how successful your winning model is. You should also reflect in Section 11.1 (Chosen Model, within the Discussion section) on the relationship between the original training sample R-square you observed for your chosen model and the validated R-square you calculated for that model in section 10.3.2. Here, you want to assess how overconfident or underconfident your original R-square was, basically."
  },
  {
    "objectID": "tipsheet.html#and-finally",
    "href": "tipsheet.html#and-finally",
    "title": "431 Project B Tips",
    "section": "And finally…",
    "text": "And finally…\n\nThe Discussion section is important. The piece of your HTML that I guarantee I will be looking at to help me settle on your final grade is the Discussion section in Study 2. I expect to see meaningful paragraphs there in response to the required elements. So don’t neglect that material just because it comes last.\n\nDon’t forget to submit:\n\nyour Study 1 qmd and HTML, and your Study 2 qmd and HTML to Canvas no later than the deadline.\nyour data, if you’re not using NHANES, to Canvas no later than the deadline,\nyour Project B self-evaluation form after you submit your Canvas materials, and no later than the deadline.\nyour CWRU class evaluation by their deadline.\n\nThanks and good luck to you all!"
  },
  {
    "objectID": "study2b.html",
    "href": "study2b.html",
    "title": "Study 2 Report Specifications",
    "section": "",
    "text": "Produce a beautiful HTML report. It should include:"
  },
  {
    "objectID": "study2b.html#headings-you-should-use-in-the-study-2-report",
    "href": "study2b.html#headings-you-should-use-in-the-study-2-report",
    "title": "Study 2 Report Specifications",
    "section": "Headings you should use in the Study 2 report",
    "text": "Headings you should use in the Study 2 report\nAll of your work should be done in a fresh R project in a clean directory on your computer.\n\nSetup and Data Ingest\nCleaning the Data\n\nBe sure to review the material (including the Tips on Cleaning Data) provided in the Data Development section of this website, in particular regarding how to deal with missing data in Study 2.\nIf you have any missing data which you impute as part of Study 2, provide a description of that process as a subsection here, and demonstrate that imputation was needed, specify the missing data mechanism you are assuming (MAR or MCAR are the available choices) and then demonstrate that after imputation you have a complete data set.\n\nCodebook and Data Description\n\nFollow the headings and steps laid out in the Study 1 instructions for this section.\nYou should include subsections for your codebook, a listing of your analytic tibble, and a numeric description, as you did in Study 1.\nMake the word Outcome in bold the first word of the description for your outcome in your codebook.\nMake the words Key Predictor in bold the first two words of the description for your key predictor in your codebook.\n\nMy Research Question\n\nSpecify your research question, with whatever introduction and background you feel is required for Dr. Love to understand its importance. If you have a pre-analytic guess as to how this will work out in your setting, please feel encouraged to include that here. The actual question should end with a question mark, and be appropriate for the nature of the analyses to come.\n\nPartitioning the Data\n\nSplit the data into two samples (a model training sample containing 60-80% of the data, and a model test sample containing the remaining 20-40%.) Details on how to do this are available here.\nBe sure to demonstrate that each subject in the original data wound up in either your training or your test sample.\n\nTransforming the Outcome\n\nUsing your training sample, provide appropriate, well-labeled visualizations of your outcome, and investigate potential transformations of that outcome for the purpose of fitting regression models in a useful way.\nMake a clear decision about what transformation (if any) you want to use. Don’t use a transformation you cannot interpret.\nIf your outcome is symmetric but with outliers, power transformations will not be of much help.\nIf your outcome includes non-positive values, you may have to add the same value to each observation of the outcome before using power transformations. (For instance, if some of your values of your raw outcome are 0, you might add 1 to each observation before considering a transformation.)\n\nThe Big Model\n\nFit a linear regression model including all of your candidate predictors for your (possibly transformed) outcome within your training sample. Summarize its prediction equation, and the other materials available through a tidy summary of the coefficients.\nIf you want to divide this work into subsections, that’s up to you.\n\nThe Smaller Model\n\nFit a linear regression model using a subset of your predictors that is interesting, again using the training sample. Summarize its prediction equation, and the other materials available through a tidy summary of the coefficients.\nYour subset must include at least the key predictor, and a perfectly reasonable strategy for this project is simply to compare the “naive” model with the key predictor alone to the full model with all predictors you have identified.\nIf you prefer to use another subset of predictors from your big model as your smaller model, that’s fine, too. If you’d prefer to use an automated or semi-automated strategy for identifying your subset of predictors from the big model, that’s also fine.\nIf you want to divide this work into subsections, that would be helpful.\n\nIn-Sample Comparison\n\nPresent four subsections here, as labeled below.\nIn Quality of Fit, summarize the quality of fit (focusing on \\(R^2\\), adjusted \\(R^2\\), AIC and BIC) within the training sample.\nIn Posterior Predictive Checks, comment on systematic discrepancies you observe for each model between the real and simulated data.\nIn Assessing Assumptions, create and assess residual plots (specifically you should be looking at the assumptions of linearity, constant variance and Normality) for each of the two models. Also discuss whether there are any highly influential points, and if so, identify them.\nIn Comparing the Models, comment on the relative strengths and weaknesses of the two models within your training sample. A graph of some key summaries would be appropriate, accompanied by comments on assumptions and posterior predictive checks. Which model do you prefer, based on this information?\n\nModel Validation\n\nThis should have four subsections, as labeled below.\nCalculating Prediction Errors Apply each of your models to the test sample to predict the outcome and do whatever back-transformation of predictions is necessary.\nVisualizing the Predictions Provide an appropriate visualization of the outcome predictions (after back-transformation) as compared to the actual outcome values, made by the two models in your test sample. Are they similar?\n\nSuch plots help you see the range of predicted values for each model on the X axis, and compare it to the range of observed values on the Y axis. Many models will be overly conservative, only predicting outcomes within a small range. For instance, if your big model’s range of predictions is much more in keeping with the observed range, that’s a reason to like the big model.\nSuch plots also help you see if one of the models matches the line for observed = predicted better than the other within your test sample.\n\nSummarizing the Errors Then summarize the following values, all on the scale of the original untransformed outcome, across the observations in your test sample, in an attractive table.\n\nsquare root of the mean squared prediction error (RMSPE)\nmean absolute prediction error (MAPE)\nmaximum absolute prediction error (MAE)\nsquared correlation of the actual and predicted values (validated \\(R^2\\))\n\nComparing the Models Use the results from the previous two subsections to comment on the relative strengths and weaknesses of the two models within your test sample. Which model do you prefer now?\n\nDiscussion\n\nThis should have four subsections, as labeled below.\nChosen Model\n\nSpecify which model you’ve chosen, based on your conclusions from sections 9 and 10.\n\nAnswering My Question\n\nUse the result of this model to answer your research question in a few sentences. Comment on whether your results matched up with your pre-analysis expectations, and also specify any limitations you see on this conclusion.\n\nNext Steps\n\nDiscuss an interesting next step you would like to pursue to learn more about this sort of research question or to go further with these data.\n\nReflection\n\nBriefly describe what you would have done differently in Study 2 had you known at the start of the project what you have learned by doing it.\n\n\nInclude the session information with session_info() from the xfun package as a separate section at the end of your report."
  },
  {
    "objectID": "study1c.html",
    "href": "study1c.html",
    "title": "Study 1 Sample Report",
    "section": "",
    "text": "A Study 1 Sample Report will be posted soon."
  },
  {
    "objectID": "study1a.html",
    "href": "study1a.html",
    "title": "Required Study 1 Analyses",
    "section": "",
    "text": "In your four analyses (chosen from five possibilities), you will be doing:"
  },
  {
    "objectID": "study1a.html#data-management",
    "href": "study1a.html#data-management",
    "title": "Required Study 1 Analyses",
    "section": "Data Management",
    "text": "Data Management\n\nAll data merging and cleaning must be included in your Quarto report, starting from the raw data obtained either through the nhanesA package or via reading in your non-NHANES raw data, so that we can replicate your work.\nYou can use the data as they were collected (quantitative, binary or multi-categorical), but you can also create categorical variables from the quantitative variables provided, should that be of interest in one or more of your analyses.\n\nShould you decide a categorical variable from a quantitative one, be sure to describe that process carefully, and demonstrate that each level of your created categorical variable contains the minimum number of observations specified on the Data Development page."
  },
  {
    "objectID": "study1a.html#analyses-youll-do",
    "href": "study1a.html#analyses-youll-do",
    "title": "Required Study 1 Analyses",
    "section": "Analyses You’ll Do",
    "text": "Analyses You’ll Do\nYou will complete any four of the following five Analyses, and present these results in your Study 1 Report.\nFor each of these analyses, you will provide complete code (including whatever you did to clean the raw data for the variables you are studying), appropriate visualizations and detailed explanations of your analytic decisions, and conclusions. Use a 90% confidence level for all Study 1 work, please.\n\nAgain, if you are using NHANES data, you will need between 500 and 8,750 observations with a minimum of 500 observations containing complete data on all of the variables you will use in Study 1.\nIf you are using any other data source, you will need between 250 and 10,000 observations, and at least 250 with complete data on all variables you will use in Study 1.\n\nEach analysis should be self-contained (so that I don’t have to read Analysis A first to understand Analysis C, for example). Present each new analysis as a subsection with an appropriate heading in the table of contents.\n\nAnalysis A. Compare two means/medians using paired samples\nHere, you will need to identify two quantitative variables (outcomes) which are paired (so that they have a natural link between them, and use the same units of measurement.) You’ll analyze the results and build a confidence interval for the population mean difference with an appropriate t-based or bootstrap procedure. Again, we require that all variables treated as quantitative in Study 1 (Analyses A, B, or C) contain at least 15 unique values.\n\n\nAnalysis B. Compare two means/medians using independent samples\nHere, you will need to identify one quantitative (outcome) and one categorical variable (binary - 2 levels.) You’ll analyze the results and build a confidence interval for the difference in means with an appropriate t-based or bootstrap procedure. Note that it’s generally easier to find independent samples comparisons than paired samples comparisons in most of the data I expect you’ll be using. This would require a quantitative outcome (with at least 15 unique values), and a binary categorical variable which divides the data into two subgroups, so that each subgroup has a minimum of 30 observations.\n\n\nAnalysis C. Compare 3-6 means/medians using independent samples\nHere, you will need to identify one quantitative (outcome) and one categorical variable (multi-categorical with 3-6 levels.) Here, you should be thinking about an analysis of variance with pre-planned Tukey HSD pairwise comparisons. This would require a quantitative outcome (with at least 15 unique values), and a multi-categorical variable with 3-6 categories which divides the data into subgroups, so that each subgroup has a minimum of 30 observations.\n\n\nAnalysis D. Create and analyze a \\(2 \\times 2\\) table\nHere, you will need to identify two categorical (binary) variables. Each cell of the resulting 2 x 2 table should contain a minimum of 30 subjects. You should be focused on the relative risk, odds ratio and risk difference comparisons.\n\n\nAnalysis E. Create and analyze a \\(J \\times K\\) table, where \\(2 \\leq J \\leq 5\\) and \\(3 \\leq K \\leq 5\\)\nHere, you will need to identify two categorical variables, at least one of which should contain 3-5 levels, while the other contains 2-5 levels. Each cell in the cross-tabulation of the two variables within the table should have a minimum of 15 observations. Here, you should be providing an appropriate cross-tabulation, the results of a chi-square test, accompanied by a useful visualization and description of the nature of the observed association."
  },
  {
    "objectID": "register.html",
    "href": "register.html",
    "title": "Registration for Project B",
    "section": "",
    "text": "You will use this Google Form to register for Project B. The deadline (for Project B Registration) is specified on the Course Calendar (it is in mid-November.)\n\nThe form should open on November 1. If it’s after November 1, and you cannot access the form, please let Dr. Love know via email or Campuswire so he can open it up.\nYour response will be automatically emailed to your CWRU email once you submit the form. If you need to edit your submission, you can do so with the link included in that email.\nIf you are working with a partner, there will be an opportunity to indicate that on this form, and only one of you (you or your partner) should complete the whole thing, while the other person needs to only complete a few of the items, as you’ll see.\n\nOnce your form is complete, Dr. Love will review your submission and get back to you to tell you whether your proposed approach is approved or not. If not, you’ll have to edit your submission and resubmit the form."
  },
  {
    "objectID": "register.html#the-registration-form",
    "href": "register.html#the-registration-form",
    "title": "Registration for Project B",
    "section": "",
    "text": "You will use this Google Form to register for Project B. The deadline (for Project B Registration) is specified on the Course Calendar (it is in mid-November.)\n\nThe form should open on November 1. If it’s after November 1, and you cannot access the form, please let Dr. Love know via email or Campuswire so he can open it up.\nYour response will be automatically emailed to your CWRU email once you submit the form. If you need to edit your submission, you can do so with the link included in that email.\nIf you are working with a partner, there will be an opportunity to indicate that on this form, and only one of you (you or your partner) should complete the whole thing, while the other person needs to only complete a few of the items, as you’ll see.\n\nOnce your form is complete, Dr. Love will review your submission and get back to you to tell you whether your proposed approach is approved or not. If not, you’ll have to edit your submission and resubmit the form."
  },
  {
    "objectID": "register.html#what-do-you-need-to-do-before-filling-out-the-form",
    "href": "register.html#what-do-you-need-to-do-before-filling-out-the-form",
    "title": "Registration for Project B",
    "section": "What Do You Need To Do Before Filling Out the Form?",
    "text": "What Do You Need To Do Before Filling Out the Form?\nFive things.\n\nDetermine whether or not you will work with a partner, and coordinate with that person to get all necessary tasks completed.\nIdentify whether you will use NHANES data or something else.\nObtain the data and figure out which variables you will use in Study 1 and in Study 2, making sure to meet the specifications for each study specified in the data development instructions.\nWithin your Study 2 variables, identify the number of observations in your data set with complete data on your variables (including your study ID code, your outcome, your key predictor and your 3-8 additional predictors).\nIdentify which times on December 6-11 work for you (and your partner) among those that are available (see below.) You’ll need to select at least five of the 20 available 75-minute periods in total, and this must include times on at least two different dates. The time slots are specified below.\n\n\nTime Periods for Presentations\nYour actual presentation time will be 20 minutes, but we have divided the schedule into 75 minute blocks below. During each block, we will schedule 3 presentations. On site means Dr. Love’s office at the School of Medicine at CWRU, and Zoom means via Zoom. Note that December 9 is a reading day, and the last day of class (for all classes) is December 6. Regardless of when you give your presentation, your final report is due at the deadline (December 11 at noon) in the course calendar.\nNote that you will need to select at least 5 of the available 20 time periods, and that those selections cannot all be on the same date.\n\nFriday December 6 (Zoom only) - last day of classes\n\n9:15 AM - 10:30 AM\n3:00 PM - 4:15 PM\n4:15 PM - 5:30 PM\n\n\n\nMonday December 9 (either On Site or Zoom) - Reading Day\n\n8:30 - 9:45 AM\n9:45 - 11:00 AM\n11:00 AM - 12:15 PM\n12:15 PM - 1:30 PM\n1:30 PM - 2:45 PM\n2:45 PM - 4:00 PM\n4:00 PM - 5:15 PM\n\n\n\nTuesday December 10 (Zoom only)\n\n8:30 - 9:45 AM\n9:45 - 11:00 AM\n11:00 AM - 12:15 PM\n12:15 PM - 1:30 PM\n1:30 PM - 2:45 PM\n2:45 PM - 4:00 PM\n5:00 PM - 6:15 PM\n\n\n\nWednesday December 11 (Zoom only)\n\n8:00 - 9:15 AM\n9:15 - 10:30 AM\n10:30 - 11:45 AM\n\nAll Project B Portfolios are due at Noon Wednesday 2024-12-11."
  },
  {
    "objectID": "data3.html",
    "href": "data3.html",
    "title": "Using Something other than NHANES",
    "section": "",
    "text": "This page describes what to do if you want to use something other than NHANES data for Project B. If you want to use NHANES data, then you should visit this page instead.\nIn either case, be sure to read through and verify that your data meet the Data Requirements for Study 1 and Study 2 described on our Data Development page.\nTo encourage people to use data other than NHANES, there is a four-point bonus in the final project B grade available for all projects which use non-NHANES data."
  },
  {
    "objectID": "data3.html#if-youre-using-data-from-another-source",
    "href": "data3.html#if-youre-using-data-from-another-source",
    "title": "Using Something other than NHANES",
    "section": "If you’re using data from another source",
    "text": "If you’re using data from another source\nIf you don’t want to use NHANES data, you will need to obtain Dr. Love’s approval through the registration form. Here are the data specifications.\n\nThe data must be freely available to all, and there must be no risk associated with your using the data for this project of any kind. Your use of the data for this project must not be subject to IRB approval, or the approval of anyone other than you (so, for example, if you would also need the approval of a principal investigator to use the data, that won’t work for Project B.)\n\nThere can be no protected health information or protected information or privacy risk of any kind involved with the data.\n\nDr. Love will need to see your source for the data in its entirety. You will need to be able to provide a link to a web page from which you (and Dr. Love and anyone else) can download the raw data as part of your registration for the project in mid-November.\nThe data must be cross-sectional, rather than longitudinal.\n\nThe only exception to this rule would be data where a baseline set of predictors is measured, which might include the baseline measure of the outcome, and then the outcome (and only the outcome) is measured at a later time.\n\nThe data must not be hierarchical, so everything must be measured at the subject level.\n\nWe cannot have subjects nested in states, for instance, with some variables measured only at the state level included in your set of variables.\nThe data you select must in all ways be suitable for the analyses required in Project B.\n\nThe data must not be from County Health Rankings, nor can they appear in any teaching repository of data (including the ones at Cleveland Clinic), nor can they be data from our 431 materials, including Lab assignments, Course Notes or Class Slides.\nThe data must not be pre-compiled as part of an R package, but rather available in raw form and ingested into R by you.\nDr. Love has a strong preference for data that describe individual people or animals, as opposed to other types of “subjects”. Who the subjects (rows) of your data are must be completely clear. No genomics data, either, in Project B - Dr. Love is insufficiently familiar with that sort of data.\nDr. Love can refuse to let you use a data set for any reason at all, and this includes the reason that he’s tired of the data set.\n\nPlease visit the Data Requirements for Study 1 and Study 2 on the Data Development page to ensure that your data will meet all necessary requirements."
  },
  {
    "objectID": "data1.html",
    "href": "data1.html",
    "title": "Data Development",
    "section": "",
    "text": "You must use the same data source for Study 1 and Study 2 in Project B. That data source must either be:\n\nNHANES data, as discussed here.\nsomething else, as discussed here.\n\nTo encourage people to use data other than NHANES, there is a four-point bonus in the final project B grade available for all projects which use non-NHANES data.\n\n\n\nData Requirements for Study 1 and Study 2\n\nNumber of observations\n\nIf you are using NHANES data, you will need between 500 and 7,500 observations with a minimum of 500 observations containing complete data on all of the variables you will use in Study 1 or Study 2.\nIf you are using any other data source, you will need between 250 and 10,000 observations, and at least 250 with complete data on all variables you will use in Study 1 or Study 2.\nWe require that all variables treated as quantitative in Study 1 (Analyses A, B, or C) or as your quantitative outcome in Study 2 contain at least 15 unique values.\nThe data must include a unique coded identifier (SEQN in NHANES) for each row (subject.)\n\nNumber and type of variables for Study 1 (where you will do 4 of the following 5 analyses)\n\nFor Analysis A, you will need appropriate data to allow you to compare two means using paired samples. So that would require a set of paired measurements of the same quantity, perhaps measurements of the same subjects before and after the application of an exposure. Again, we require that all variables treated as quantitative in Study 1 (Analyses A, B, or C) or as your quantitative outcome in Study 2 contain at least 15 unique values.\nFor Analysis B, you will need appropriate data to allow you to compare two means using independent samples. This would require a quantitative outcome (with at least 15 unique values), and a binary categorical variable which divides the data into two subgroups, so that each subgroup has a minimum of 30 observations.\nFor Analysis C, you will need appropriate data to allow you to compare 3-6 means using independent samples. This would require a quantitative outcome (with at least 15 unique values), and a multi-categorical variable with 3-6 categories which divides the data into subgroups, so that each subgroup has a minimum of 30 observations.\nFor Analysis D, you will need appropriate data to allow you to create and analyze a 2 \\(\\times\\) 2 table. This would require two independently collected binary categorical variables, that split the data into four groups in a 2 \\(\\times\\) 2 table, each with a minimum of 30 observations.\nFor Analysis E, you will need appropriate data to allow you to create and analyze a J \\(\\times\\) K table, where \\(2 \\leq J \\leq 5\\) and \\(3 \\leq K \\leq 5\\). This would require two independently collected categorical variables (one with J groups and one with K groups), that split the data into groups in a J \\(\\times\\) K table, so that each cell within the table has a minimum of 15 observations.\nAt a bare minimum, then, you will need a quantitative outcome (for Analyses A, B and C) and two binary variables (one for B and two for D and one for E) and a multi-categorical variable with 3-5 levels (for C and E) although you are welcome to use different variables from the same data source for each of the four Study 1 analyses you complete.\n\nNumber and type of variables for Study 2\n\nYou will need a quantitative outcome. Again, we require that your quantitative outcome contains at least 15 unique values.\nYou will need a key predictor of interest (which may be either quantitative, or categorical.) If it is categorical, it must have 2-6 categories, and each category must contain at least 30 observations. Your research question will focus largely on how effectively this key predictor can be used to predict your quantitative outcome.\nYou will need to identify 3-8 additional predictors of your outcome, at least one of which must be a multi-categorical predictor with 3-6 categories, where each category contains at least 30 observations. The other predictors can be any combination of quantitative and categorical (with 2-6 categories each, with at least 30 observations in each category.)\n\nYour data for each Study must be managed, merged (if necessary) and cleaned exclusively using R to go from raw data to that Study’s final clean tibble. This data management process must include the creation of appropriately labeled (and, if necessary, collapsed) factors for all categorical variables you will use in either study, and appropriate investigation and actions regarding missing values, numbers of unique values, and impossible values.\nYou will need to generate a single clean data set which you will then use for all four of your Study 1 analyses. For Study 1, work with a data set that has complete cases only on all of the analytic variables you study in your various Study 1 analyses. Describe those data overall using a codebook and an appropriate set of numerical summaries for your variables.\nYou will need to generate a single clean data set for all of your Study 2 analyses, which you will then partition (after single imputation of all variables besides your outcome and key predictor, to deal with missing values of all of your non-key predictors, if they exist) into a model training (or development) sample containing 60-80% of the data, and a model testing (or validation) sample containing the remaining 20-40% of the data. Describe the training data overall using a codebook and an appropriate set of numerical summaries, as you did in Study 1.\n\n\n\nTips on Cleaning Your Data\n\nIf you need to merge data (for instance in NHANES) clean the data after completing the merge.\nNote that it’s only necessary to clean the variables you will actually use in your analyses below. Create an analytic data set containing only those variables.\n\nThis should include a subject identification code (the SEQN in NHANES), your outcome, your key predictor and your other predictors.\nIf you are working with NHANES 2017-March 2020 data, you must include RIDSTATR and RIDAGEYR from the P_DEMO file.\n\nInclude RIDSTATR just so that you can prove that all of its values are 2 in your sample.\nInclude RIDAGEYR even if you’re not using it in your models, so you can describe the ages of the people in your sample.\n\n\nIf you create a categorical variable from a quantitative one, do so in this section of your report, and then refer to that work in the analyses below when you use the new variable. In general, though, I wouldn’t do that except in dire circumstances. Variables that use categories to describe what were originally quantitative variables aren’t quantitative any more.\nThings I would treat as missing include responses like Refused, Don’t Know, Did Not Respond, Unknown, No response and missing.\n\nIf you have a quantitative variable that includes a code like 5555 or 9999 for “don’t know” or “missing”, you will need to identify those cases as missing when ingesting the data, just as you would if you were working with a categorical variable.\nBe sure that R recognizes things that are missing as missing.\n\nCollapse levels sensibly for multi-categorical variables with more than 6 categories. If you want to use more than 6 categories for a categorical variable in your analyses, contact Dr. Love.\n\nIf you have a categorical variable with codes like 77, 88 or 99, in addition to treating those as missing, you want to drop those levels from the factors you create. I recommend you run droplevels() on your tibble to remove all factor levels with zero subjects. That can help down the line.\n\nFor NHANES folks, a few specific things:\n\nGender vs. Sex I would treat the RIAGENDR variable as describing biological sex and would rename it as I created a factor.\nRace/Ethnicity If you want to use race/ethnicity I would prefer the use of RIDRETH3 over RIDRETH1, and I would recommend using all six categories, assuming you have at least 100 subjects at each level after whatever other pruning you do. If you want to collapse, then lumping codes 1 and 2 into “Hispanic/Latinx” is acceptable. Remember that race/ethnicity as a covariate is an attempt to understand the impact of structural racism, at least as much as it is anything else, so interpretation requires special care.\nAge Do not use a categorical version of age. Use the quantitative version, called RIDAGEYR, provided in the P_DEMO data. When you describe your subjects, you should specify the range (minimum and maximum) ages of those subjects, so you will need to capture RIDAGEYR in your final analytic data set even if you’re not including it in your regression models.\nIncome and Measurement Caps The family income ratio INDFMPIR is appealing and quantitative, but it has a pronounced ceiling effect. It is the ratio of income to the poverty level, but is capped at 5. How should you think about that? (Note that age in adults is also capped, at 80.)\nCategorical Income? As a categorical alternative, the income data in INDHHIN2 in NHANES can be tricky to use, since there are so many categories and some of them overlap. Collapse INDHHIN2 to the following four categories, which are easy to describe, and have reasonable numbers of subjects in each category. Note that this approach drops the subjects with codes 12, 77 or 99, in addition to those with missing data.\n\nLowest: Below 20,000 (includes original codes 1, 2, 3, 4 and 13)\nLow: between 20,000 and 44,999 (includes original codes 5, 6, and 7)\nHigh: between 45,000 and 74,999 (includes original codes 8, 9 and 10)\nHighest: 75,000 and above (includes original codes 14 and 15)\n\nEducation Categories If you’re working with adults (ages 20 and over), the DMDEDUC2 variable in the P_DEMO file is the set of categories to use. I would probably collapse codes 1 and 2 together to create a four-category variable with “Less than HS”, “HS Grad”, “Some College”, “College Grad”.\n\nBe sure to treat all multi-categorical variables as factors in R, and don’t treat numeric codes as meaningful numeric variables.\nMake sure that all of your quantitative variables have sensible minimum and maximum values as you’re cleaning.\nSome binary variables are coded 1 and 2. Fix that in your work, ideally by using the real names and treating the variable as a factor, or by converting the 1-2 to a proper 1-0 indicator variable.\n\nUse the formula NEWVAR = 2 - OLDVAR to turn OLDVAR: 1 = Yes, 2 = No into NEWVAR: 1 = Yes, 0 = No.\nIf you have OLDVAR: 1 = No, 2 = Yes, create a NEWVAR with 1 = Yes, 0 = No using NEWVAR = OLDVAR - 1.\n\nIn Study 1, filter to complete cases. In Study 2, You should only filter to complete cases on the outcome and key predictor in Study 2. Then, perform single (simple) imputation using the mice package for any variables that are neither your outcome or your key predictor in Study 2 with missing values.\nYou are welcome to apply janitor::clean_names at the start or end of your cleaning, if you like, but I wouldn’t otherwise change the variable names, at least for NHANES. If you do decide to change the names, that’s OK, but you will then need to specify the original names as well in the codebook.\nPlease don’t include sanity checks in your report. We’ll trust you have to have done that work on your own.\n\n\n\nTo use data from NHANES (National Health and Nutrition Examination Survey).\n\nPlease read the Data Requirements for Study 1 and Study 2 and Tips on Cleaning Your Data above, then read the additional details on what is required if you’re working with NHANES data here.\nMany people (in past years) have felt that using NHANES data was a little easier than using another data source. To encourage people to use data other than NHANES, there is a four-point bonus in the final project B grade available for all projects which use non-NHANES data.\n\n\n\nTo use data from a non-NHANES source that meets with Dr. Love’s approval.\n\nPlease read the Data Requirements for Study 1 and Study 2 and Tips on Cleaning Your Data above, then read the additional details on what is required if you’re instead working with some other data source here.\nAgain, to encourage people to use data other than NHANES, there is a three-point bonus available to all projects which use non-NHANES data."
  },
  {
    "objectID": "checklist.html",
    "href": "checklist.html",
    "title": "431 Project B Checklist",
    "section": "",
    "text": "Main Tasks\n\nComplete the Project B Registration Form to obtain my approval for your plan, let me know if you’re working with a partner, and schedule your oral presentation.\n\nThe registration deadline in mid-November is specified in the Course Calendar.\n\nYou (and your partner, if you have one) will present your project on December 6-11 to Dr. Love in his office or over Zoom. Details on the Oral Presentation are provided below.\nYou will build two Quarto and HTML reports (separate reports for Study 1 and Study 2) due at the project B portfolio deadline.\n\nIf you’re not using NHANES data, you’ll also submit your data to me at that time.\nDetails on how to submit your reports are provided below.\n\nFinally, complete the Project B Self-Evaluation form, also due at the same time as the Portfolio Reports for Study 1 and Study 2, as specified on the Course Calendar.\n\n\n\nSubmitting Your Study 1 Report\nYour Study 1 Report is to be submitted to Canvas by the deadline in the Course Calendar.\n\nThis submission should include both your Quarto and HTML results.\nBe sure that the names of your Quarto and HTML files clearly identify whose project is being submitted, and an indication that these files refer to study 1.\nIf you are working with a partner, one of you should submit both the Study 1 and Study 2 reports to Canvas, and the other person should submit a one-page note to Canvas (word or PDF is best) containing your name, and stating something like “I worked on Project B with [your partner’s name] and they will submit Project B for our group.”\n\n\n\nSubmitting Your Study 2 Report\nYour Study 2 Report is to be submitted to Canvas by the deadline in the Course Calendar.\n\nThis submission should include both your Quarto and HTML results.\nIn addition, if you worked with any data other than NHANES, your submission also needs to include your data (in the form you used to ingest the data in your Quarto file, so that we can run your Quarto code and obtain your HTML results.)\nBe sure that the names of your Quarto and HTML files clearly identify whose project is being submitted, and an indication that these files refer to study 2.\nAgain, if you are working with a partner, one of you should submit both the Study 1 and Study 2 reports to Canvas, and the other person should submit a one-page note to Canvas (word or PDF is best) containing your name, and stating something like “I worked on Project B with [your partner’s name] and they will submit Project B for our group.”\n\n\n\nOral Presentation of Results\nYour meeting time is 20 minutes long, and please arrive 5 minutes early, either in person or via Zoom. If you have an emergency on the day of your presentation, email Dr. Love as soon as possible. Zoom information will be provided to you by December 1.\nYour meeting will involve materials from each of your studies, discussed in a fairly regimented way, described below. If you are working with a partner, Dr. Love will randomly determine at the meeting who will speak and when, so you need to each be prepared to give the entire presentation. Dr. Love will keep track of time, and move you along as necessary, so you won’t have to worry about that.\n\nYou will need to share a screen to show me the key results as you describe them for each of the analyses in Study 1 and in Study 2 that you wind up discussing. It is best if one of you is prepared to share their screen for both presentations, if you’re working with a partner, and I encourage you to practice this in advance.\nYou are welcome to show me results in the context of a Powerpoint-style presentation, if you prefer to develop one, or to show me results straight from your Quarto-created HTML files in your portfolio. Whatever works for you - so long as I can see what you are talking about as you are talking, we’ll be fine. Make sure you know how to increase the size of the text in your HTML file while presenting it.\nI will NOT be able to pull up your report or other materials while we are talking. You will have to be able to do that.\n\n\nStudy 1 presentation (6-8 minutes)\nIn Study 1, you will first select your most interesting / intriguing result out of your four main analyses and present that, in about 2 minutes. In those 2 minutes, you should be showing me the highlights of that Analysis, specifically:\n\nWhich Analysis (A, B, C, D, or E) are we describing?\nWhat research question are you investigating, and what variables did you use?\nWhat conclusion did you draw about that question?\nWhat statistical method led you to that conclusion?\n\nI will then ask you to tell me which of the other analyses (meaning A, B, C, D, or E) you did. I will then ask you to present the results of one of the other analyses you did, in a similar way. You will need to come prepared to present this information for any of your Study 1 analyses at a moment’s notice, as you will not know in advance which of your other analyses you did that I will ask for.\n\n\nStudy 2 presentation (10-12 minutes)\nIn Study 2, you will start with telling me about the most important finding of your little study in 5 minutes. In these 5 minutes, you will tell me:\n\nWhat your research question was and why it was interesting to you (combined this should take no more than 30 seconds)\nWhat your better model has to say about the answer to your research question\n\nThis should include a description of the predictors that wound up in your (final) model and the direction of each of their effects on your outcome. Show me the model as you’re telling me about this.\nThis should also include a sense of how well the model predicted overall (\\(R^2\\) is one good choice.)\nThis should also include whether the posterior predictive plots show systematic discrepancies between the fitted model’s predictions and your observed data. Show me the plot as you’re telling me about this.\nThis should also include a discussion of whether residual plots for your final model fit regression assumptions. Show me the plots as you’re telling me about this.\nYour conclusions about rational next steps to learn more from these data, or what specific new data you now wish you’d had when you started the study.\n\n\nFor most of the remaining time, I will ask you about your study, and try to help you think through any problems you had in obtaining or interpreting analyses. You should come prepared to share any of the steps in your analysis at a moment’s notice, as we may want to look at any part of your work.\n\n\nFinal Questions (2-4 minutes)\nDepending on remaining time, I may ask you any of several questions at the end of our meeting. Some possibilities you should be prepared for include the following (some of which also appear in the self-evaluation)\n\nWhat percentage of your time in Project B did you spend obtaining, cleaning, merging and tidying data, as opposed to actually performing analyses on tidy data?\nTell me something useful that you learned from doing Project B.\nTell me what the hardest part of doing Project B was.\nWhat did you learn from Project A that was helpful in doing Project B?\nWhat do you know now that you wish you’d known back when you started Project B back in November? What would you tell yourself if you could go back in time?\n\n\n\n\nA Special Note\nIf you’ve read down to here before 5 PM on December 1, thanks and here’s an opportunity for a little bonus credit. Send Dr. Love an email no later than 5 PM on December 1 with the subject line 431 Favorite Song, telling him your favorite song (and providing a link to a video of the song on YouTube), and you’ll get some bonus credit.\n\n\nSelf-Evaluation for Project B\nThe Self-Evaluation for Project B Form will be available in December and should take about 15 minutes to complete. If you are working in a team, each of you need to complete the form as an individual.\nThe Form is also due when the Project B Portfolio is due, and you’ll complete it after meeting with Dr. Love for your presentation. Find the link to the Self-Evaluation Form here."
  },
  {
    "objectID": "data2.html",
    "href": "data2.html",
    "title": "Using NHANES Data",
    "section": "",
    "text": "If you select the NHANES option, you will be using data from the National Health and Nutrition Examination Survey.\nIf you decide to use some other data set instead for Project B, then you should visit this page.\nIn either case, be sure to read through and verify that your data meet all requirements described on our Data Development page."
  },
  {
    "objectID": "data2.html#about-nhanes-from-the-nhanes-website",
    "href": "data2.html#about-nhanes-from-the-nhanes-website",
    "title": "Using NHANES Data",
    "section": "About NHANES (from the NHANES website)",
    "text": "About NHANES (from the NHANES website)\n\nThe National Health and Nutrition Examination Survey (NHANES) is a program of studies designed to assess the health and nutritional status of adults and children in the United States. The survey is unique in that it combines interviews and physical examinations. NHANES is a major program of the National Center for Health Statistics (NCHS). NCHS is part of the Centers for Disease Control and Prevention (CDC) and has the responsibility for producing vital and health statistics for the Nation.\n\n\nThe NHANES program began in the early 1960s and has been conducted as a series of surveys focusing on different population groups or health topics. In 1999, the survey became a continuous program that has a changing focus on a variety of health and nutrition measurements to meet emerging needs. The survey examines a nationally representative sample of about 5,000 persons each year. These persons are located in counties across the country, 15 of which are visited each year.\n\n\nThe NHANES interview includes demographic, socioeconomic, dietary, and health-related questions. The examination component consists of medical, dental, and physiological measurements, as well as laboratory tests administered by highly trained medical personnel.\n\n\nFindings from this survey will be used to determine the prevalence of major diseases and risk factors for diseases. Information will be used to assess nutritional status and its association with health promotion and disease prevention. NHANES findings are also the basis for national standards for such measurements as height, weight, and blood pressure. Data from this survey will be used in epidemiological studies and health sciences research, which help develop sound public health policy, direct and design health programs and services, and expand the health knowledge for the Nation."
  },
  {
    "objectID": "data2.html#general-advice-for-nhanes-learning-about-the-available-data",
    "href": "data2.html#general-advice-for-nhanes-learning-about-the-available-data",
    "title": "Using NHANES Data",
    "section": "General Advice for NHANES: Learning About The Available Data",
    "text": "General Advice for NHANES: Learning About The Available Data\nThe links in this section go to the Survey Data and Documentation section of the NHANES website.\n\nWe strongly encourage the use of the NHANES 2017 - March 2020 Pre-pandemic data for Project B.\n\nThis is the most recent public data that is fairly complete.\n\nYou are required to use variables taken from at least three different NHANES data sets. This must include the Demographics data set, in addition to two other data sets taken from at least one of three other available data groups (Examination, Laboratory and Questionnaire.)\n\nThe Demographics data group should be part of all projects, and it contains a single data set.\nThe Examination data group includes 11 data sets.\nThe Laboratory data group contains 36 data sets.\nThe Questionnaire data group also contains 37 data sets.\nWe do not want you to use data from the Dietary group in Project B.\n\nYou will use the nhanesA package in R to import and work with the available data. This package is part of our list of recommended packages for installations.\nNote that none of your work will be using the sampling weights which are a key part of NHANES. Thus, none of your results from Project B will be truly representative of the national population. That’s OK for this exercise."
  },
  {
    "objectID": "data2.html#getting-the-nhanes-data",
    "href": "data2.html#getting-the-nhanes-data",
    "title": "Using NHANES Data",
    "section": "Getting the NHANES data",
    "text": "Getting the NHANES data\nVisit the NHANES website and identify the data you want to view.\n\nFor example, the Demographic Variables and Sample Weights for NHANES 2017-March 2020 are described here.\nEach NHANES data set is associated with a Doc File (which stands for Data Documentation, Codebook and Frequencies). For instance, here’s the one for Demographics in 2017-March 2020. This file can be viewed online (it’s an HTML file) and it will tell you what variables are included in that data set.\nEach NHANES data set is available as a SAS transport file. For example, it’s the P_DEMO file for Demographics in 2017-March 2020, as you can see here."
  },
  {
    "objectID": "data2.html#using-the-nhanesa-package",
    "href": "data2.html#using-the-nhanesa-package",
    "title": "Using NHANES Data",
    "section": "Using the nhanesA package",
    "text": "Using the nhanesA package\nOnce you’ve selected the data sets from NHANES that you want to use in your project (remember that you need at least 3), the nhanesA package in R can be used to obtain them.\nHere’s a little vignette introducing nhanesA from Christopher Endres, who built the package. The key functions in the nhanesA package that I think you might use are those described in that vignette, but the main one is simply called nhanes.\n\nAn Example\nFor example, suppose we want to load the Blood Pressure data from the 2017-18 Examination files at NHANES (contained in the BPX_J data file) into a tibble called bp_data in R.\n\nNote that you will instead use 2017-March 2020 data, which for Blood Pressure would be (according to this page) the P_BPXO file, rather than BPX_J.\n\nWe would use the following code, which will take a few minutes to run.\n\nlibrary(nhanesA)\nlibrary(tidyverse)\n\nbp_raw &lt;- nhanes('BPX_J') |&gt; tibble()\n\nsaveRDS(bp_raw, \"data/BPX_J.Rds\")\n\nOnce you’ve downloaded the file once, you should save it as an R data frame, and then comment out the initial code you used to pull down the data in R. Then, when you rerun, it’ll be all set. Remember to create a data sub-folder in your R Project B directory before you run this code.\nSo your final presentation in Project B should instead look like this, which will run much more quickly.\n\nlibrary(nhanesA)\nlibrary(tidyverse)\n\n# pull in data from BPX_J from NHANES and save it\n\n# bp_raw &lt;- nhanes('BPX_J') |&gt; tibble()\n\n# saveRDS(bp_raw, \"data/BPX_J.Rds\")\n\n# Now that data are saved, I can just read in the tibble\n\nbp_raw &lt;- readRDS(\"data/BPX_J.Rds\")"
  },
  {
    "objectID": "data2.html#merging-nhanes-files",
    "href": "data2.html#merging-nhanes-files",
    "title": "Using NHANES Data",
    "section": "Merging NHANES files",
    "text": "Merging NHANES files\nYou will need to include data from multiple tibbles (data sets) pulled down in your project. I suggest you first select only those variables you intend to use in your analytic data file from each individual tibble you have created. This should always include the SEQN variable in every tibble, since that is what you will use to match up responses across those tibbles.\n\nYour final analyses should be based on somewhere between 500 and 7,500 complete cases from the NHANES 2017-March 2020 data.\n\nTo merge a demographics tibble called DEMO with a BPX tibble to create a tibble called NEW that contains the variables from both DEMO and BPX for all of the subjects contained in DEMO, I’d use a left_join, as follows.\n\nNEW &lt;- left_join(DEMO, BPX, by = \"SEQN\")\n\nI’d then use another left_join to merge this NEW result with another tibble (say, the HDL_J tibble) and so on.\n\nNEW2 &lt;- left_join(NEW, HDL_J, by = \"SEQN\")\n\nThen, when I was done merging and cleaning the data I would be sure to save that result as a new Rds file, just in case I needed it again."
  },
  {
    "objectID": "data2.html#which-variables-subjects-should-i-use",
    "href": "data2.html#which-variables-subjects-should-i-use",
    "title": "Using NHANES Data",
    "section": "Which variables / subjects should I use?",
    "text": "Which variables / subjects should I use?\nThat’s up to you. Find variables of interest in the description files, and pull them out and see if they will work for you.\n\nFocus on subjects who have a RIDSTATR value of 2 (meaning they were both interviewed and examined) - this variable is part of the Demographics file.\n\nFor 2017-March 2020, there are 14,300 such subjects.\n\nI encourage you to not use subjects listed with ages of 80 (RIDAGEYR = 80) since that’s a catch-all for all subjects ages 80 and older.\n\nFor 2017-March 2020, of the 14,300 listed above, 13,724 are less than 80.\n\nYou should either use children or adults in your final analyses, and not both together.\n\nThere are 7,853 adults between the ages of 21 and 79 of the 13,724.\nSome variables are only collected on children, others only on adults.\n\nDo not filter to complete cases in creating your data. Maintain the missing values.\n\nIn many cases, you should have well over 5,000 observations in total, but depending on what you select, you may have a much smaller subset, and you should be able to explain to us why that is the case, if it is.\nFor example, if you’re studying something that is only measured in females, or in children, you’ll have a smaller sample for that reason, and you need to make that clear to us in your report. At a minimum, you will need at least 500 complete cases even if you’re using heavily filtered NHANES data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "431 Project B Instructions",
    "section": "",
    "text": "What is Project B?\nProject B is the second of two real data science projects you’ll be doing this semester. It involves the completion of four tasks, which you’ll start working on at the start of November.\n\nYou will complete a Registration Form to obtain my approval for your plan, let me know if you’re working with a partner, and schedule your oral presentation.\nYou (and your partner, if applicable) will present your project sometime between 12-06 and 12-11 to Dr. Love in his office in person or via Zoom. These will be scheduled immediately after the Project B plans have been submitted.\nYou will build Quarto and HTML reports describing your work.\nFinally, you will complete a Self-Evaluation form.\n\n\n\nWhat’s on this Website\n\nThe Data: Instructions on getting data for Project B\n\nYou’ll either use data from NHANES, or from some other source.\n\nRegistration information for your Project B plan.\n\nThis involves completing a Google Form by the deadline in mid-November specified on the Course Calendar. In this form, you will:\n\nspecify whether or not you are working with a partner\ntell us a little about the data source (NHANES or other) you plan to use\nprovide options for when you can give your oral presentation, and whether you prefer to do so in person or via Zoom\n\n\nInstructions for Study 1\n\nYou’ll find information on required Study 1 analyses\nWe also provide detailed Study 1 report specifications\nYou’ll also find a Study 1 example report\n\nInstructions for Study 2\n\nYou’ll find information on required Study 2 analyses\nWe also provide detailed Study 2 report specifications\nYou’ll also find a Study 2 example report\n\nSelf-Evaluation Form for Project B\n\nIf you work with a partner, each of you submits this form separately.\n\nA Checklist of the tasks that need to be accomplished for Project B, which also includes some details on the oral presentation you’ll give to Dr. Love in December.\nA Tip Sheet of about 20 things that have come up in the past that are worth your attention as you prepare your final materials for presentation and submission.\nThe top menu also provides links to contact us, and to the 431 home page.\n\nAll of the material you need (from a statistical and coding perspective) to do Project B has been or will be covered in our first 24 classes (i.e. immediately before the Thanksgiving Break), as well as in the Course Book Chapters 1-22 and Labs 1-6.\n\n\nProject B Deliverables\n\nYou will complete a Registration Form to obtain my approval for your plan, let me know if you’re working with a partner, and schedule your oral presentation, by the (mid-November) deadline on the Course Calendar.\nYou (and your partner, if applicable) will present your project to Dr. Love in his office. Details on the Oral Presentation are found in the Checklist menu above. Presentations will be scheduled on December 6-11 using the Registration Form.\nYou will build two Quarto and HTML reports (separate reports for Study 1 and Study 2) by the Project B Portfolio deadline in the Course Calendar.\n\nIf you’re not using NHANES data, you’ll also submit your data to Dr. Love at that time.\n\nFinally, you will complete a Self-Evaluation form, by the Project B Portfolio deadline in the Course Calendar.\n\n\n\nPartnerships?\nYou can work alone, or with one other person on this project. If you work as a pair, you will commit to that when you register for the project. Each of you will receive the team grade for the project reports, and an individual grade for the other components of the project.\n\n\nThe Data\nYou will work with the same data source for Study 1 and for Study 2, and these data will be developed either from NHANES or from another public source that you identify.\n\nYou will find detailed instructions regarding the use of NHANES data for Project B here.\nIf you want to use other data, you’ll need it to meet some specifications we’ll describe, and you’ll have to get Dr. Love’s permission when you register your project.\nSince most people consider working with NHANES data to be easier, we will award four extra points to projects which use non-NHANES data.\n\n\n\nStudy 1\n\nStudy 1 is about making descriptive and exploratory comparisons and summaries of data. It’s not about building sophisticated statistical models.\nYou will ingest, merge and clean the data in R, then select variables to complete any four out of five potential analyses, as described in these instructions.\n\nYou can do all five analyses if you like (as preparation for Quiz 2, for instance) but you will only present four in your report. No bonus credit for doing all five analyses.\n\nDr Love has developed Study 1 Report Specifications and a Study 1 Example Report which should guide your eventual submitted Study 1 report.\n\n\n\nStudy 2\n\nStudy 2 is about building a model and making predictions. You will complete all elements of a data science project designed to create a statistical model for a quantitative outcome, then use it for prediction, and assess the quality of those predictions.\nStudy 2 involves working with data from the same source that you used for Study 1. Again, you will work through all cleaning and data management requirements in your Study 2 report.\n\nStudy 2 involves the prediction of a quantitative outcome using a key predictor and some additional predictors in two linear regression models, and then comparing those two models.\nAll of the material you need (from a statistical and coding perspective) to do these analyses has been or will be covered in our first 24 classes and in the Course Notes.\n\nDr Love has developed Study 2 Report Specifications and a Study 2 Example Report which should guide your eventual submitted Study 2 report.\n\n\n\nGrading\nProject B will be graded by Dr. Love on a scale from 0-150 points.\n\nOn-time successful completion of the Registration Form is worth 15 points.\nThe two study reports (Study 1 and Study 2) due at the final Project B deadline are worth a combined 60 points.\nThe oral presentation is also worth 60 points. Details on the Oral Presentation are found in the Checklist.\nThe self-evaluation is worth 15 points.\nLate work on Project B is unacceptable. All deadlines are in the Course Calendar.\n\nDr. Love will provide no written feedback on your Project B work. The grading timeline is simply too tight on my end. I apologize in advance.\n\n\nQuestions?\nIf you have questions, let us know about them on Campuswire using the projectB folder, or speak with Dr. Love before or after class, or discuss them with the TAs during office hours."
  },
  {
    "objectID": "self_eval.html",
    "href": "self_eval.html",
    "title": "Project B Self-Evaluation",
    "section": "",
    "text": "The self-evaluation form will appear on December 1 at https://bit.ly/431-2024-projectB-self-evaluation. If it’s after December 1, and the form isn’t available to you, please contact Dr. Love via email or Campuswire to remind him to turn it on.\nYou should complete the form after you have met with Dr. Love and given your project presentation. The deadline is the same as the deadline for your Final Report, and is posted on the Course Calendar.\nThe form is the usual sort of Google Form that Dr. Love uses for lots of things, and should take less than 15 minutes to complete. The form will ask you to reflect briefly on your project report and your presentation.\nIf you are working with a partner, each of you will need to separately complete the self-evaluation."
  },
  {
    "objectID": "study1b.html",
    "href": "study1b.html",
    "title": "Study 1 Report Specifications",
    "section": "",
    "text": "Produce a beautiful HTML report containing 8 main sections, as described below. It should include:"
  },
  {
    "objectID": "study1b.html#headings-you-should-use-in-the-study-1-report",
    "href": "study1b.html#headings-you-should-use-in-the-study-1-report",
    "title": "Study 1 Report Specifications",
    "section": "Headings you should use in the Study 1 report",
    "text": "Headings you should use in the Study 1 report\nAll of your work should be done in a fresh R project in a clean directory on your computer. - If you are working with NHANES data, your directory should include a data subdirectory, in which you will probably need to place the Love-431.R script. - If you need to ingest non-NHANES data, then your data directory should also include the raw data files.\n\nSetup and Data Ingest\n\nBe sure to load all necessary packages and ingest your data, either by reading it in with nhanesA or by reading in your raw non-NHANES data. Load the tidyverse last and do not load core packages from the tidyverse separately.\n\nCleaning the Data\n\nBe sure to review the material (including the Tips on Cleaning Data) provided in the Data Development section of this website.\nNote that it’s only necessary to clean the variables you will actually use in your four analyses below. Select only those variables (including the subject identifier) here when you create your analytic tibble.\nI also suggest applying janitor::clean_names at the start, but I wouldn’t otherwise change variable names if you’re not changing the meaning of the variables. If you want to change the names, you can, but then you must indicate that in your codebook, and do the renaming before you show the codebook.\nIf you create a new categorical variable from an existing quantitative variables, do so in this section of your report, and then refer to that work in the analyses below when you use the new variable.\n\nCodebook and Data Description\n\nThe first thing that should appear in the section is a description of the subjects of your study.\n\nAs an example of what I’m looking for, suppose that you are working with NHANES data and have identified 3500 adults between the ages of 21 and 79 who have complete data on the variables in your final data set. In that case, the description I would want to see would be: “3500 adults ages 21-79 participating in NHANES 2017-2020 with complete data on the variables listed in the table below.”\n\nIn the first subsection in this section, labeled Codebook, present a codebook where you list all of the variables you will actually use in your four chosen analyses, in the format you will use in those analyses. Do not include any other variables (besides the subject identifying code) in the codebook.\nPresent your codebook in a table, with either three or four columns.\nPlace the variable name you will use in your analyses in the left-most column. The Codebook lists all of the variables you will use in your analyses (plus the subject identifying code). If you’re working with NHANES data, you should include both SEQN (subject code) in this list.\nThe type of variable should be Quant (for quantitative variables), Binary (for two-category variables), or X-cat for multi-category variables) where X should either be 3, 4, 5 or 6, to indicate the number of levels in the variable.\nIf you’ve changed a variable name (other than the obvious changes made by clean_names) from what you imported initially from your data source, add a final column where you specify the original variable name. The original name alone is sufficient here.\n\nFor those working with NHANES data, we will already be able to tell which data set in NHANES you used to obtain this variable from your initial pull of the data with the nhanesA package, so don’t specify the data set name again here.\n\n\n\nMake sure your Codebook looks nice and is easy to read in your HTML result. - If you decide to rename any of the variables from the names provided with the raw data, you should specify your new name and the original name in your codebook. - Your codebook should also describe each of the variables you are using and specify whether they are quantitative, binary or multi-categorical. - In the second subsection (called Analytic Tibble), list your clean tibble that the codebook describes, so we can see it is a tibble. Only the variables in your Codebook should appear. - In the third and final subsection here, labeled Data Summary, provide useful descriptive summaries of each variable in your codebook other than the subject identifying code. You can use describe from Hmisc or another option of your choosing to accomplish this. You needn’t provide graphical summaries here, and include only variables that are in your codebook.\nThose first three sections should then be followed by any four of the following five sections (which will be sections 4-7 in your report)…\n\nAnalysis A: Comparing 2 Means with Paired Samples\nAnalysis B: Comparing 2 Means with Independent Samples\nAnalysis C: Comparing X Means with Independent Samples (where you’d substitute in the number of means you’re comparing for X)\nAnalysis D: Analyzing a 2x2 table\nAnalysis E: Analyzing a JxK table (where you substitute in the values for J and K)\n\n\nWithin each of the four analyses you present, I’d have four (numbered) subsections:\n\nThe Question\n\nStart by describing what you want to study, and then specify a research question (which should end with a question mark and be something you can resolve with the planned analysis.)\nDon’t boil the ocean here. You’re looking for a research question that can be reasonably addressed using your data, so it has to be pretty straightforward.\nIf you have a pre-existing belief about what will happen, before you look at the data, please feel encouraged to include a statement about that belief before specifying your question.\n\nDescribing The Data\n\nThis should start with specifications of what each of the variables you are studying in this analysis actually mean.\nYour cleaning, creation of factors and other data management activities for each analysis should already have been shown in earlier sections. Please refer back to that section and don’t repeat what you’ve already done. Be sure that the Codebook you provided describes all variables you are using in your analyses here.\nProvide numerical summaries and visualizations of interest that are relevant to the analysis, and comment on any issues you observe.\n\nMain Analysis\n\nShow your work, and comment on whatever decisions you make.\nBe sure to present and justify the assumptions you are making.\n\nConclusions\n\nAnswer your research question, by clearly linking the analytic results to what you were asking at the start.\nIf you can see a logical next step for the analysis of the question you asked, specify it. Also, if you specified a pre-existing belief about what would happen, reflect on that in light of the data."
  },
  {
    "objectID": "study1b.html#and-finally",
    "href": "study1b.html#and-finally",
    "title": "Study 1 Report Specifications",
    "section": "And finally…",
    "text": "And finally…\nAs the final section of your report (which should be section 8), include the session information using session_info() from the xfun package."
  },
  {
    "objectID": "study2a.html",
    "href": "study2a.html",
    "title": "Required Study 2 Analyses",
    "section": "",
    "text": "Once you have identified an acceptable data set, you will produce a report that demonstrates that you have accomplished the following:\n\nIdentify a quantitative outcome.\n\nFor purposes of this project, we will require your quantitative outcome to contain more than 15 unique values.\n\nIdentify a key predictor (which may be either quantitative or categorical.)\n\nIf the key predictor is categorical, it must have 3-6 categories, and each category must contain at least 30 observations.\n\nIdentify 3-8 other predictors of your outcome (demonstrating that either your key predictor or at least one of the “other” predictors is multi-categorical with 3-6 categories.)\nDefine a research question related to how effectively your key predictor predicts your quantitative outcome, while (possibly) adjusting for the other predictors.\nSteps 1-3 will yield a set of 6-11 variables (an outcome, a key predictor, 3-8 other predictors, and a subject identifier). Use those selections to create your analytic data set.\n\nYou must have between (500 and 7,500 observations if you’re using NHANES; 250 and 10,000 observations if not using NHANES) with complete data on all 6-11 variables included in your Study 2 analytic tibble. No other variables should be included in your Study 2 analytic tibble.\n\nClean the data in R, and this includes the creation of appropriately labeled (and if necessary, collapsed) factors for all categorical variables, and the investigation and decision-making regarding missing values, numbers of unique values and impossible values.\nComplete any imputation required to deal with missing data. Use single (simple) imputation with the mice package to create your imputed data. Do not impute your outcome or key predictor - you should filter to complete cases on those two variables.\nUse appropriate tools to provide useful numerical summaries for all data you will study, after all cleaning, so that these results describe the exact variables you will be modeling in the remaining work. Provide a clear note describing how much imputation you did.\nPartition the clean data into a model development (also called a model training) sample (60-80% of the data) and a model testing (also called a model validation) sample (the remaining 20-40%) using the approach recommended in the data .\n\nSuppose you had a tibble called original_data which identified its subjects with a subjID variable, and you wanted to place 75% of your data for development into training_sample and the rest into test_sample. You could do that with the following code…\n\n\n\nlibrary(tidyverse)\n\nset.seed(431) # pick a different seed than this\n\ntraining_sample &lt;- original_data |&gt; slice_sample(prop = 0.75)\n\ntest_sample &lt;- \n    anti_join(original_data, training_sample, by = \"subjID\")\n\n\nProvide appropriate, well-labeled visualizations of your outcome, and investigate potential transformations of that outcome for the purpose of fitting regression models in a useful way. Whatever transformation (including no transformation at all) should be used for the steps that follow.\nProduce two competitive models fit using least squares (rather than a Bayesian approach) for predicting your outcome using your clean data that provide evidence regarding your research question.\n\nOne of these models should be the full model with all candidate predictors included.\nYour other model should be a well-motivated subset of your full model, that at least includes the key predictor. The naive strategy of using as your subset the key predictor alone is 100% appropriate.\n\nAssess the performance of your two models (full model or subset) and come to a conclusion about which is better. This assessment should includes both in-sample (predictive performance and adherence to assumptions) and holdout sample (predictive quality) assessments. Be sure to attend to back-transformation properly should that be necessary, in evaluating the quality of predictions.\nUse the results of the model you chose to answer your research question, and then describe the limitations of this study and next steps you would like to pursue."
  },
  {
    "objectID": "study2c.html",
    "href": "study2c.html",
    "title": "Study 2 Sample Report",
    "section": "",
    "text": "A Sample 2 Study Report will be posted soon."
  }
]