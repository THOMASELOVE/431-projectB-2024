[
  {
    "objectID": "tipsheet.html",
    "href": "tipsheet.html",
    "title": "431 Project B Tips",
    "section": "",
    "text": "I wanted to pass along these tips, most of which have came up in assessing last year’s projects.\n\nThis should be a good set of things to review (along with the Project B Checklist) as you’re preparing your final materials for submission."
  },
  {
    "objectID": "tipsheet.html#what-is-this",
    "href": "tipsheet.html#what-is-this",
    "title": "431 Project B Tips",
    "section": "",
    "text": "I wanted to pass along these tips, most of which have came up in assessing last year’s projects.\n\nThis should be a good set of things to review (along with the Project B Checklist) as you’re preparing your final materials for submission."
  },
  {
    "objectID": "tipsheet.html#yaml-and-setup-issues",
    "href": "tipsheet.html#yaml-and-setup-issues",
    "title": "431 Project B Tips",
    "section": "YAML and Setup issues",
    "text": "YAML and Setup issues\n\nNo hashtags preceding R results. I would like you to be sure that your R output is not preceded by hashtags. The easiest way to ensure this is to include the following code at the top of your code, where you load your R packages.\n\nknitr::opts_chunk$set(comment = NA)\n\nTheming gg-Plots. I would like you to use either theme_bw() or theme_light() globally, rather than including it in the code of every individual plot you build. So include something like\n\ntheme_set(theme_bw())\nimmediately after you load the tidyverse, and then don’t include theming of this sort in your individual plots, unless you are deliberately adding some specialized theming elements for a specific plot.\n\nClean List of R Packages. Your list of R packages should be clean for each study, which means:\n\n\ntidyverse is loaded last\nnone of the core tidyverse packages (core list is here) are loaded\nall packages you will load for this study are in one place\nno packages are loaded that you don’t use in your work."
  },
  {
    "objectID": "tipsheet.html#general-issues",
    "href": "tipsheet.html#general-issues",
    "title": "431 Project B Tips",
    "section": "General Issues",
    "text": "General Issues\n\nCheck your HTML for plot-text transition problems. One of the hardest things to get people to do is add empty lines in R Markdown after they create a plot or heading. Forgetting to do this can cause your plots to show up in the HTML with the start of the next paragraph shown to the right of the plot instead of below the plot. Make sure you avoid this mistake. Also, Hit ENTER after every pipe and + in your code so that you avoid scrollable windows for code in your HTML output.\nMissing Data Mechanism and Dealing with Missingness. You need to have an explicit statement about your assumed missing data mechanism, including either the term MCAR, MAR or MNAR, in both Study 1 and Study 2, and you have to be specific about what you’ve done. This should be part of your HTML file everywhere where you impute (as in Study 2 variables other than your outcome and key predictor) or filter to complete cases (as in Study 1 and with your Study 2 outcome and key predictor). None of your analyses (in Study 1 or Study 2) should involve missing values: either you should have imputed missing values or you should have filtered to complete cases.\nSpell check doesn’t check headings and subheadings. Using spell check in R Studio is trivial (just hit F7) and important, but be aware that you still need to read your HTML to be sure that you don’t have problems. A particular issue is that the spell check doesn’t check your headings and subheadings so you’ll want to pay especially close attention to those pieces. In particular, I’ve seen several people misspell the word “Transformations” in section 6 of Study 2.\nYour confidence level is 90%, not 95%. All of Project B uses a 90% confidence level, so the phrase “p &lt; 0.05” is 100% irrelevant to this work. If you must compare a p value to something, be sure it is 0.10. I would also strongly suggest you search through your work and eliminate the terms “statistical significance” and even “significant” unless you have a very good reason to include them.\nOrder multi-categorical factors properly. Please respect the ordering of multicategorical variables, especially in Analyses C and E for Study 1. Be sure that you adjust the levels of your factor so that they use the natural order of the variable. If you have a nominal multi-categorical variable, like race/ethnicity, in Study 2, then I suggest you order the levels of that factor variable from largest to smallest in terms of number of subjects, so that the baseline group will be the one that appears most frequently in your data.\nDon’t change numeric variables to factors. If you change a numeric variable to a factor, and then change it back into a numeric variable, that will create many, many problems. Don’t do that. Instead, create a new factor variable if you’re going to convert a numeric variable into categories."
  },
  {
    "objectID": "tipsheet.html#nhanes-issues",
    "href": "tipsheet.html#nhanes-issues",
    "title": "431 Project B Tips",
    "section": "NHANES issues",
    "text": "NHANES issues\n\nNHANES isn’t a random sample. Don’t suggest or state that it is. So the NHANES sampling procedure is a limitation in terms of you cannot really generalize to the US population with NHANES unless you use survey weighting.\nSpecify your approach if not standard. If you’re using NHANES data but either not using the 2017-March 2020 data, or not using adults ages 21-79, be sure that you’ve made that abundantly clear everywhere where it’s relevant, including at least in the Data Description section for Study 1 and Study 2."
  },
  {
    "objectID": "tipsheet.html#study-1-issues",
    "href": "tipsheet.html#study-1-issues",
    "title": "431 Project B Tips",
    "section": "Study 1 Issues",
    "text": "Study 1 Issues\n\nStudy 1 Analyses must stand on their own. Each of your four Study 1 Analyses should stand on its own, in the sense that you should specify the relevant group of subjects, the exposure and the outcome in words at the start of each of those analyses. Please label these as Analysis A, B, C, D or E, (leaving out one, of course) as I did in building the assignment.\nDescribe the direction and size of estimated effects. In Project B, you should have no statements about statistical significance or any synonym. Estimate effects whenever possible, including a confidence interval. This is easy for Study 2 and for Study 1 Analyses A, B, and D, I think, but more challenging for C and E. Be sure to carefully focus your description of your result on the direction and size of the effect you estimate, in the context of your problem.\n\n\nFor instance, a terrible sentence in Analysis B would be something like “We saw a significant difference between males and females on mean systolic blood pressure.”\nA better sentence would be something like “The mean systolic blood pressure for males was 3 mm Hg higher than that of females, with a 90% CI of (1, 5).” Notice that this better sentence includes the actual units of measurement, and not something generic like “points”.\n\n\nPaired vs. Independent Samples. In Analyses A and B for Study 1, be sure that you provide a logical argument near the top of your work for why the data you are studying use (in Analysis A, paired) (in Analysis B, independent) samples.\nSimplifying Conclusions in Analysis D. In Analysis D of Study 1, in writing up your conclusions after forming an appropriate 2x2 table, and specifying the probabilities of obtaining your outcome within each exposure group as estimated at the top of the table, it is completely sufficient to provide your interpretation of either:\n\n\nthe relative risk and the odds ratio and their confidence intervals, or\nthe relative risk and the difference in probabilities, with their confidence intervals.\n\n\nDescribe some percentages in Analysis E. In Analysis E for Study 1, you should focus your interpretation of the result from your table and chi-square test on a comparison of interesting percentages from your table, in addition to the p value and a visualization of the results."
  },
  {
    "objectID": "tipsheet.html#study-2-issues",
    "href": "tipsheet.html#study-2-issues",
    "title": "431 Project B Tips",
    "section": "Study 2 Issues",
    "text": "Study 2 Issues\n\nResidual Plots should be tall. When building residual plots, whether with check_model() or something else, make them tall, by incorporating r, fig.height = 8 into your chunk header for that code. For example, this is the default size:\n\n\nm1 &lt;- lm(mpg ~ disp + wt, data = mtcars)\ncheck_model(m1)\n\n\n\n\n\n\n\n\nand below is what you get if you add #| fig.height: 8 at the start of the code chunk.\n\nm1 &lt;- lm(mpg ~ disp + wt, data = mtcars)\ncheck_model(m1)\n\n\n\n\n\n\n\n\nThis helps us see things more effectively, especially with large sample sizes in the plots. So please do it.\n\nBox-Cox. In Study 2, in the Transformation of Outcome section, please show the Box-Cox analysis immediately after the starting graphical summary (as opposed to the strange approach I used in the template) and then either use it (which is fine) or specify why you’ve decided not to use it. Remember that a Box-Cox \\(\\lambda\\) near 0 suggests a logarithmic transformation, and that a Box-Cox \\(\\lambda\\) of 1 indicates no transformation.\nUsing Validated R-Square. In Study 2, you should use the validated R-square you develop in section 10.3.2 as part of your discussion in both Sections 10.4 and 11.1. (in addition to whatever else you decide to use) to help describe how successful your winning model is. You should also reflect in Section 11.1 (Chosen Model, within the Discussion section) on the relationship between the original training sample R-square you observed for your chosen model and the validated R-square you calculated for that model in section 10.3.2. Here, you want to assess how overconfident or underconfident your original R-square was, basically."
  },
  {
    "objectID": "tipsheet.html#and-finally",
    "href": "tipsheet.html#and-finally",
    "title": "431 Project B Tips",
    "section": "And finally…",
    "text": "And finally…\n\nThe Discussion section is important. The piece of your HTML that I guarantee I will be looking at to help me settle on your final grade is the Discussion section in Study 2. I expect to see meaningful paragraphs there in response to the required elements. So don’t neglect that material just because it comes last.\n\nDon’t forget to submit:\n\nyour Study 1 qmd and HTML, and your Study 2 qmd and HTML to Canvas no later than the deadline.\nyour data, if you’re not using NHANES, to Canvas no later than the deadline,\nyour Project B self-evaluation form after you submit your Canvas materials, and no later than the deadline.\nyour CWRU class evaluation by their deadline.\n\nThanks and good luck to you all!"
  },
  {
    "objectID": "study2b.html",
    "href": "study2b.html",
    "title": "Study 2 Report Specifications",
    "section": "",
    "text": "Produce a beautiful HTML report. It should include:"
  },
  {
    "objectID": "study2b.html#headings-you-should-use-in-the-study-2-report",
    "href": "study2b.html#headings-you-should-use-in-the-study-2-report",
    "title": "Study 2 Report Specifications",
    "section": "Headings you should use in the Study 2 report",
    "text": "Headings you should use in the Study 2 report\nAll of your work should be done in a fresh R project in a clean directory on your computer.\n\nSetup and Data Ingest\nCleaning the Data\n\nBe sure to review the material (including the Tips on Cleaning Data) provided in the Data Development section of this website, in particular regarding how to deal with missing data in Study 2.\nIf you have any missing data which you impute as part of Study 2, provide a description of that process as a subsection here, and demonstrate that imputation was needed, specify the missing data mechanism you are assuming (MAR or MCAR are the available choices) and then demonstrate that after imputation you have a complete data set.\n\nCodebook and Data Description\n\nFollow the headings and steps laid out in the Study 1 instructions for this section.\nYou should include subsections for your codebook, a listing of your analytic tibble, and a numeric description, as you did in Study 1.\nMake the word Outcome in bold the first word of the description for your outcome in your codebook.\nMake the words Key Predictor in bold the first two words of the description for your key predictor in your codebook.\n\nMy Research Question\n\nSpecify your research question, with whatever introduction and background you feel is required for Dr. Love to understand its importance. If you have a pre-analytic guess as to how this will work out in your setting, please feel encouraged to include that here. The actual question should end with a question mark, and be appropriate for the nature of the analyses to come.\n\nPartitioning the Data\n\nSplit the data into two samples (a model training sample containing 60-80% of the data, and a model test sample containing the remaining 20-40%.) Details on how to do this are available here.\nBe sure to demonstrate that each subject in the original data wound up in either your training or your test sample.\n\nTransforming the Outcome\n\nUsing your training sample, provide appropriate, well-labeled visualizations of your outcome, and investigate potential transformations of that outcome for the purpose of fitting regression models in a useful way.\nMake a clear decision about what transformation (if any) you want to use. Don’t use a transformation you cannot interpret.\nIf your outcome is symmetric but with outliers, power transformations will not be of much help.\nIf your outcome includes non-positive values, you may have to add the same value to each observation of the outcome before using power transformations. (For instance, if some of your values of your raw outcome are 0, you might add 1 to each observation before considering a transformation.)\n\nThe Big Model\n\nFit a linear regression model including all of your candidate predictors for your (possibly transformed) outcome within your training sample. Summarize its prediction equation, and the other materials available through a tidy summary of the coefficients.\nIf you want to divide this work into subsections, that’s up to you.\n\nThe Smaller Model\n\nFit a linear regression model using a subset of your predictors that is interesting, again using the training sample. Summarize its prediction equation, and the other materials available through a tidy summary of the coefficients.\nYour subset must include at least two predictors, including the key predictor, and a perfectly reasonable strategy for this project is simply to compare a “naive” model with the key predictor and one other predictor to the full model with all of the predictors you have identified.\nIf you prefer to use another subset of predictors from your big model as your smaller model, that’s fine, too. If you’d prefer to use an automated or semi-automated strategy for identifying your subset of predictors from the big model, that’s also fine, but you must have at least two predictors in your smaller model.\nIf you want to divide this work into subsections, that would be helpful.\n\nIn-Sample Comparison\n\nPresent four subsections here, as labeled below.\nIn Quality of Fit, summarize the quality of fit (focusing on \\(R^2\\), adjusted \\(R^2\\), AIC and BIC) within the training sample.\nIn Posterior Predictive Checks, comment on systematic discrepancies you observe for each model between the real and simulated data.\nIn Assessing Assumptions, create and assess residual plots (specifically you should be looking at the assumptions of linearity, constant variance and Normality) for each of the two models. Also discuss whether there are any highly influential points, and if so, identify them.\nIn Comparing the Models, comment on the relative strengths and weaknesses of the two models within your training sample. A graph of some key summaries would be appropriate, accompanied by comments on assumptions and posterior predictive checks. Which model do you prefer, based on this information?\n\nModel Validation\n\nThis should have four subsections, as labeled below.\nCalculating Prediction Errors Apply each of your models to the test sample to predict the outcome and do whatever back-transformation of predictions is necessary.\nVisualizing the Predictions Provide an appropriate visualization of the outcome predictions (after back-transformation) as compared to the actual outcome values, made by the two models in your test sample. Are they similar?\n\nSuch plots help you see the range of predicted values for each model on the X axis, and compare it to the range of observed values on the Y axis. Many models will be overly conservative, only predicting outcomes within a small range. For instance, if your big model’s range of predictions is much more in keeping with the observed range, that’s a reason to like the big model.\nSuch plots also help you see if one of the models matches the line for observed = predicted better than the other within your test sample.\n\nSummarizing the Errors Then summarize the following values, all on the scale of the original untransformed outcome, across the observations in your test sample, in an attractive table.\n\nsquare root of the mean squared prediction error (RMSPE)\nmean absolute prediction error (MAPE)\nmaximum absolute prediction error (MAE)\nsquared correlation of the actual and predicted values (validated \\(R^2\\))\n\nComparing the Models Use the results from the previous two subsections to comment on the relative strengths and weaknesses of the two models within your test sample. Which model do you prefer now?\n\nDiscussion\n\nThis should have four subsections, as labeled below.\nChosen Model\n\nSpecify which model you’ve chosen, based on your conclusions from sections 9 and 10.\n\nAnswering My Question\n\nUse the result of this model to answer your research question in a few sentences. Comment on whether your results matched up with your pre-analysis expectations, and also specify any limitations you see on this conclusion.\n\nNext Steps\n\nDiscuss an interesting next step you would like to pursue to learn more about this sort of research question or to go further with these data.\n\nReflection\n\nBriefly describe what you would have done differently in Study 2 had you known at the start of the project what you have learned by doing it.\n\n\nInclude the session information with session_info() from the xfun package as a separate section at the end of your report."
  },
  {
    "objectID": "study1c.html",
    "href": "study1c.html",
    "title": "Study 1 Sample Report",
    "section": "",
    "text": "A Study 1 Sample Report will be posted by class time on Thursday 2024-11-07."
  },
  {
    "objectID": "study1a.html",
    "href": "study1a.html",
    "title": "Required Study 1 Analyses",
    "section": "",
    "text": "In your four analyses (chosen from five possibilities), you will be doing:"
  },
  {
    "objectID": "study1a.html#data-management",
    "href": "study1a.html#data-management",
    "title": "Required Study 1 Analyses",
    "section": "Data Management",
    "text": "Data Management\n\nAll data merging and cleaning must be included in your Quarto report, starting from the raw data obtained either through the nhanesA package or via reading in your non-NHANES raw data, so that we can replicate your work.\nYou can use the data as they were collected (quantitative, binary or multi-categorical), but you can also create categorical variables from the quantitative variables provided, should that be of interest in one or more of your analyses.\n\nShould you decide a categorical variable from a quantitative one, be sure to describe that process carefully, and demonstrate that each level of your created categorical variable contains the minimum number of observations specified on the Data Development page."
  },
  {
    "objectID": "study1a.html#analyses-youll-do",
    "href": "study1a.html#analyses-youll-do",
    "title": "Required Study 1 Analyses",
    "section": "Analyses You’ll Do",
    "text": "Analyses You’ll Do\nYou will complete any four of the following five Analyses, and present these results in your Study 1 Report.\nFor each of these analyses, you will provide complete code (including whatever you did to clean the raw data for the variables you are studying), appropriate visualizations and detailed explanations of your analytic decisions, and conclusions. Use a 90% confidence level for all Study 1 work, please.\n\nAgain, if you are using NHANES data, you will need between 500 and 8,750 observations with a minimum of 500 observations containing complete data on all of the variables you will use in Study 1.\nIf you are using any other data source, you will need between 250 and 10,000 observations, and at least 250 with complete data on all variables you will use in Study 1.\n\nEach analysis should be self-contained (so that I don’t have to read Analysis A first to understand Analysis C, for example). Present each new analysis as a subsection with an appropriate heading in the table of contents.\n\nAnalysis A. Compare two means/medians using paired samples\nHere, you will need to identify two quantitative variables (outcomes) which are paired (so that they have a natural link between them, and use the same units of measurement.) You’ll analyze the results and build a confidence interval for the population mean difference with an appropriate t-based or bootstrap procedure. Again, we require that all variables treated as quantitative in Study 1 (Analyses A, B, or C) contain at least 15 unique values.\n\n\nAnalysis B. Compare two means/medians using independent samples\nHere, you will need to identify one quantitative (outcome) and one categorical variable (binary - 2 levels.) You’ll analyze the results and build a confidence interval for the difference in means with an appropriate t-based or bootstrap procedure. Note that it’s generally easier to find independent samples comparisons than paired samples comparisons in most of the data I expect you’ll be using. This would require a quantitative outcome (with at least 15 unique values), and a binary categorical variable which divides the data into two subgroups, so that each subgroup has a minimum of 30 observations.\n\n\nAnalysis C. Compare 3-6 means/medians using independent samples\nHere, you will need to identify one quantitative (outcome) and one categorical variable (multi-categorical with 3-6 levels.) Here, you should be thinking about an analysis of variance with pre-planned Tukey HSD pairwise comparisons. This would require a quantitative outcome (with at least 15 unique values), and a multi-categorical variable with 3-6 categories which divides the data into subgroups, so that each subgroup has a minimum of 30 observations.\n\n\nAnalysis D. Create and analyze a \\(2 \\times 2\\) table\nHere, you will need to identify two categorical (binary) variables. Each cell of the resulting 2 x 2 table should contain a minimum of 30 subjects. You should be focused on the relative risk, odds ratio and risk difference comparisons.\n\n\nAnalysis E. Create and analyze a \\(J \\times K\\) table, where \\(2 \\leq J \\leq 5\\) and \\(3 \\leq K \\leq 5\\)\nHere, you will need to identify two categorical variables, at least one of which should contain 3-5 levels, while the other contains 2-5 levels. Each cell in the cross-tabulation of the two variables within the table should have a minimum of 15 observations. Here, you should be providing an appropriate cross-tabulation, the results of a chi-square test, accompanied by a useful visualization and description of the nature of the observed association."
  },
  {
    "objectID": "sample-study2.html",
    "href": "sample-study2.html",
    "title": "431 Project B Sample Study 2 Report",
    "section": "",
    "text": "Remember that each subsection should include at least one complete sentence explaining what you are doing, specifying the variables you are using and how you are using them, and then conclude with at least one complete sentence of discussion of the key conclusions you draw from the current step, and a discussion of any limitations you can describe that apply to the results.\nIf you want to download the Quarto code I used to create this document, click on the Code button near the title of this Sample Study.\nFor heaven’s sake, DO NOT use my words included in this example report in your project. Rewrite everything to make it relevant to your situation. Do not repeat my instructions back to me."
  },
  {
    "objectID": "sample-study2.html#initial-setup-and-package-loads-in-r",
    "href": "sample-study2.html#initial-setup-and-package-loads-in-r",
    "title": "431 Project B Sample Study 2 Report",
    "section": "1.1 Initial Setup and Package Loads in R",
    "text": "1.1 Initial Setup and Package Loads in R\n\nlibrary(broom)\nlibrary(car)\nlibrary(GGally)\nlibrary(Hmisc)\nlibrary(janitor)\nlibrary(knitr)\nlibrary(mosaic)\nlibrary(naniar)\nlibrary(patchwork)\nlibrary(sessioninfo)\nlibrary(simputation)\nlibrary(tidyverse) \n\n## Global options\n\nopts_chunk$set(comment=NA)\n\ntheme_set(theme_bw())\noptions(dplyr.summarise.inform = FALSE)"
  },
  {
    "objectID": "sample-study2.html#loading-the-raw-data-into-r",
    "href": "sample-study2.html#loading-the-raw-data-into-r",
    "title": "431 Project B Sample Study 2 Report",
    "section": "1.2 Loading the Raw Data into R",
    "text": "1.2 Loading the Raw Data into R\nHere, we load the data using read_csv and then convert all character variables to factors in R, and then change our identifying code: subj_id back to a character variable.\n\nhbp_study &lt;- read_csv(\"data/hbp_study.csv\", show_col_types = FALSE) |&gt;\n  mutate(across(where(is.character), as.factor)) |&gt;\n  mutate(subj_id = as.character(subj_id))"
  },
  {
    "objectID": "sample-study2.html#merging-the-data",
    "href": "sample-study2.html#merging-the-data",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.1 Merging the Data",
    "text": "2.1 Merging the Data\nIn my little demonstration here, I don’t have to do any merging."
  },
  {
    "objectID": "sample-study2.html#the-raw-data",
    "href": "sample-study2.html#the-raw-data",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.2 The Raw Data",
    "text": "2.2 The Raw Data\nThe hbp_study data set includes 12 variables and 999 adult subjects. For each subject, we have gathered\n\nbaseline information on their age, and their sex,\nwhether or not they have a diabetes diagnosis,\nthe socio-economic status of their neighborhood of residence (nses),\ntheir body-mass index (bmi1) and systolic blood pressure (sbp1),\ntheir insurance type, tobacco use history, and\nwhether or not they have a prescription for a statin, or for a diuretic.\nEighteen months later, we gathered a new systolic blood pressure (sbp2) for each subject.\n\n\nglimpse(hbp_study)\n\nRows: 999\nColumns: 12\n$ subj_id   &lt;chr&gt; \"A0001\", \"A0004\", \"A0005\", \"A0013\", \"A0015\", \"A0017\", \"A0018…\n$ age       &lt;dbl&gt; 58, 65, 61, 51, 61, 45, 40, 50, 43, 46, 56, 52, 58, 59, 54, …\n$ sex       &lt;fct&gt; F, F, F, M, F, F, F, F, M, F, F, F, M, F, M, F, F, F, M, M, …\n$ diabetes  &lt;fct&gt; No, No, Yes, No, No, No, Yes, Yes, No, No, No, No, No, No, Y…\n$ nses      &lt;fct&gt; Low, Very Low, Very Low, Very Low, Very Low, Low, Very Low, …\n$ bmi1      &lt;dbl&gt; 24.41, 50.50, 29.76, 41.83, 30.95, 33.01, 36.32, 30.76, 23.1…\n$ sbp1      &lt;dbl&gt; 147, 134, 170, 118, 132, 110, 127, 152, 125, 161, 140, 136, …\n$ insurance &lt;fct&gt; Medicaid, Medicaid, Medicaid, Medicaid, Medicaid, Medicaid, …\n$ tobacco   &lt;fct&gt; never, never, current, quit, never, current, never, never, c…\n$ statin    &lt;dbl&gt; 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, …\n$ diuretic  &lt;dbl&gt; 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, …\n$ sbp2      &lt;dbl&gt; 138, 134, 140, 143, 162, 141, 101, 154, 111, 154, 154, 138, …\n\n\nNote: If you have more than 20 variables in your initial (raw) data set, prune it down to 20 as the first step before showing us the results of glimpse for your data.\nThis tibble describes twelve variables, including:\n\na character variable called subj_id not to be used in our model except for identification of subjects,\nour outcome (sbp2) and our key predictor (sbp1) that describe systolic blood pressure at two different times.\nseven categorical candidate predictors, specifically sex, diabetes, nses, insurance, tobacco, statin, and diuretic, each specified here in R as either a factor or a 1/0 numeric variable (statin and diuretic),\nthree quantitative candidate predictors, specifically age, bmi1 and sbp1."
  },
  {
    "objectID": "sample-study2.html#which-variables-should-be-included-in-the-tidy-data-set",
    "href": "sample-study2.html#which-variables-should-be-included-in-the-tidy-data-set",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.3 Which variables should be included in the tidy data set?",
    "text": "2.3 Which variables should be included in the tidy data set?\nIn fitting my models, I actually plan only to use five predictors: sbp1, age, bmi1, diabetes and tobacco to model my outcome: sbp2. Even though I’m not planning to use all of these predictors in my models, I’m going to build a tidy data set including all of them anyway, so I can demonstrate solutions to some problems you might have.\nWhen you build your tidy data set in the next section, restrict it to the variables (outcomes, predictors and subj_id) that you will actually use in your modeling.\nIn building our tidy version of these data, we must:\n\ndeal with the ordering of levels in the multi-categorical variables nses, insurance and tobacco,\nchange the name of nses to something more helpful - I’ll use nbhd_ses as the new name1."
  },
  {
    "objectID": "sample-study2.html#checking-our-outcome-and-key-predictor",
    "href": "sample-study2.html#checking-our-outcome-and-key-predictor",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.4 Checking our Outcome and Key Predictor",
    "text": "2.4 Checking our Outcome and Key Predictor\n\ndf_stats(~ sbp2 + sbp1, data = hbp_study)\n\n  response min  Q1 median  Q3 max     mean       sd   n missing\n1     sbp2  77 121    133 144 203 133.7427 17.93623 999       0\n2     sbp1  81 124    136 147 205 136.5185 18.34717 999       0\n\n\nWe have no missing values in our outcome or our key predictor, and each of the values look plausible, so we’ll move on."
  },
  {
    "objectID": "sample-study2.html#checking-the-quantitative-predictors",
    "href": "sample-study2.html#checking-the-quantitative-predictors",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.5 Checking the Quantitative Predictors",
    "text": "2.5 Checking the Quantitative Predictors\nBesides sbp1 we have two other quantitative predictor candidates, age and bmi1.\n\ndf_stats(~ age + bmi1, data = hbp_study)\n\n  response   min     Q1 median     Q3   max     mean       sd   n missing\n1      age 33.00 52.000 59.000 66.000 83.00 58.68669 10.47551 999       0\n2     bmi1 16.72 27.865 32.145 38.365 74.65 33.72258  8.36090 994       5\n\n\nWe know that all subjects in these data had to be between 33 and 83 years of age in order to be included, so we’re happy to see that they are. We have five missing values (appropriately specified with NA) and no implausible values in our BMI values (I would use 16-80 as a plausible range of BMI values for adults.) Things look OK for now, as we’ll deal with the missing values last."
  },
  {
    "objectID": "sample-study2.html#checking-the-categorical-variables",
    "href": "sample-study2.html#checking-the-categorical-variables",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.6 Checking the Categorical Variables",
    "text": "2.6 Checking the Categorical Variables\nFor categorical variables, it’s always worth it to check to see whether the existing orders of the factor levels match the inherent order of the information, as well as whether there are any levels which we might want to collapse due to insufficient data, and whether there are any missing values.\n\n2.6.1 nses: home neighborhood’s socio-economic status\n\nhbp_study |&gt; tabyl(nses)\n\n     nses   n     percent valid_percent\n     High 154 0.154154154     0.1553986\n      Low 336 0.336336336     0.3390515\n   Middle 281 0.281281281     0.2835520\n Very Low 220 0.220220220     0.2219980\n     &lt;NA&gt;   8 0.008008008            NA\n\n\n\nThe order of nses, instead of the alphabetical (“High”, “Low”, “Middle”, “Very Low”), should go from “Very Low” to “Low” to “Middle” to “High”, or perhaps its reverse.\nLet’s fix that using the fct_relevel function from the forcats package, which is part of the tidyverse. While we’re at it, we’ll rename the variable nbhd_ses which is more helpful to me.\nThen we’ll see how many subjects fall in each category.\n\n\nhbp_study &lt;- hbp_study |&gt;\n  rename(nbhd_ses = nses) |&gt;\n  mutate(nbhd_ses = fct_relevel(nbhd_ses, \"Very Low\", \"Low\", \n                            \"Middle\", \"High\"))\nhbp_study |&gt; tabyl(nbhd_ses)\n\n nbhd_ses   n     percent valid_percent\n Very Low 220 0.220220220     0.2219980\n      Low 336 0.336336336     0.3390515\n   Middle 281 0.281281281     0.2835520\n     High 154 0.154154154     0.1553986\n     &lt;NA&gt;   8 0.008008008            NA\n\n\nWe have 8 missing values of nbhd_ses. We’ll deal with that later.\n\n\n2.6.2 tobacco: tobacco use history\n\nhbp_study |&gt; tabyl(tobacco)\n\n tobacco   n    percent valid_percent\n current 295 0.29529530     0.3022541\n   never 319 0.31931932     0.3268443\n    quit 362 0.36236236     0.3709016\n    &lt;NA&gt;  23 0.02302302            NA\n\n\n\nFor tobacco, instead of (“current”, “never”, “quit”), we want a new order: (“never”, “quit”, “current”).\n\n\nhbp_study &lt;- hbp_study |&gt;\n  mutate(tobacco = fct_relevel(tobacco, \"never\", \"quit\", \n                            \"current\"))\nhbp_study |&gt; count(tobacco)\n\n# A tibble: 4 × 2\n  tobacco     n\n  &lt;fct&gt;   &lt;int&gt;\n1 never     319\n2 quit      362\n3 current   295\n4 &lt;NA&gt;       23\n\n\nWe have 23 missing values of tobacco. Again, we’ll deal with that later.\n\n\n2.6.3 insurance: primary insurance type\n\nhbp_study |&gt; tabyl(insurance)\n\n insurance   n    percent\n  Medicaid 398 0.39839840\n  Medicare 402 0.40240240\n   Private 160 0.16016016\n Uninsured  39 0.03903904\n\n\n\nFor insurance, we’ll change the order to (“Medicare”, “Private”, “Medicaid”, “Uninsured”)\n\n\nhbp_study &lt;- hbp_study |&gt;\n  mutate(insurance = fct_relevel(insurance, \"Medicare\", \n                                 \"Private\", \"Medicaid\", \n                                 \"Uninsured\"))\nhbp_study |&gt; tabyl(insurance)\n\n insurance   n    percent\n  Medicare 402 0.40240240\n   Private 160 0.16016016\n  Medicaid 398 0.39839840\n Uninsured  39 0.03903904\n\n\nNote that any levels left out of a fct_relevel statement get included in their current order, after whatever levels have been specified.\n\n\n2.6.4 What about the subjects?\nIt is important to make sure that we have a unique (distinct) code (here, subj_id) for each row in the raw data set.\n\nnrow(hbp_study)\n\n[1] 999\n\nn_distinct(hbp_study |&gt; select(subj_id))\n\n[1] 999\n\n\nOK, that’s fine."
  },
  {
    "objectID": "sample-study2.html#dealing-with-missingness",
    "href": "sample-study2.html#dealing-with-missingness",
    "title": "431 Project B Sample Study 2 Report",
    "section": "2.7 Dealing with Missingness",
    "text": "2.7 Dealing with Missingness\nNote that you will need to ensure that any missing values are appropriately specified using NA.\n\nIn this data set, we’re all set on that issue.\n\nThere are missing data in nses (8 NA), bmi1 (5 NA) and tobacco (23 NA).\n\nMissing Outcomes. In building your tidy data set, delete any subjects with missing values of your outcome variable. I’d also probably drop any subjects missing the key predictor, too.\n\nIf we needed to delete the rows with missing values of an outcome, I would use code of the form data_fixed &lt;- data_original |&gt; filter(complete.cases(outcomevariablename)) to accomplish that.\nThe elements (sbp1 and sbp2) that form our outcome and key predictor have no missing values, though, so we’ll be OK in that regard.\n\n\nIn building the tidy data set, leave all missing values for candidate predictors as NA.\n\n2.7.1 Assume MCAR and Build Tibble of Complete Cases\nFor your project, I expect a complete case analysis, where you drop all observations with missing data from your data set before creating your codebook. Let’s do that here.\n\n\n2.7.2 Identifying Missing Data\nThere are 23 subjects missing tobacco, 8 missing nbhd_ses and 5 missing bmi1.\n\nmiss_var_summary(hbp_study)\n\n# A tibble: 12 × 3\n   variable  n_miss pct_miss\n   &lt;chr&gt;      &lt;int&gt;    &lt;num&gt;\n 1 tobacco       23    2.30 \n 2 nbhd_ses       8    0.801\n 3 bmi1           5    0.501\n 4 subj_id        0    0    \n 5 age            0    0    \n 6 sex            0    0    \n 7 diabetes       0    0    \n 8 sbp1           0    0    \n 9 insurance      0    0    \n10 statin         0    0    \n11 diuretic       0    0    \n12 sbp2           0    0    \n\n\nNo subject is missing more than one variable, as we can tell from the table below, sorted by n_miss.\n\nmiss_case_summary(hbp_study)\n\n# A tibble: 999 × 3\n    case n_miss pct_miss\n   &lt;int&gt;  &lt;int&gt;    &lt;dbl&gt;\n 1    10      1     8.33\n 2    26      1     8.33\n 3    31      1     8.33\n 4    33      1     8.33\n 5    42      1     8.33\n 6    66      1     8.33\n 7    67      1     8.33\n 8    77      1     8.33\n 9    85      1     8.33\n10   161      1     8.33\n# ℹ 989 more rows\n\n\nSo we’ll lose 23 + 8 + 5 = 36 observations from our sample of 999 in dropping all cases with missing values, leaving us with a complete cases tibble of 963 rows.\n\n\n2.7.3 The Complete Cases Tibble\nMy complete case data set would then be something like this:\n\nhbp_cc &lt;- hbp_study |&gt;\n  select(subj_id, sbp2, sbp1, age, sex, \n         diabetes, nbhd_ses, bmi1, insurance, \n         tobacco, statin, diuretic) |&gt;\n  drop_na()\n\nhbp_cc\n\n# A tibble: 963 × 12\n   subj_id  sbp2  sbp1   age sex   diabetes nbhd_ses  bmi1 insurance tobacco\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt; &lt;fct&gt;    &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;     &lt;fct&gt;  \n 1 A0001     138   147    58 F     No       Low       24.4 Medicaid  never  \n 2 A0004     134   134    65 F     No       Very Low  50.5 Medicaid  never  \n 3 A0005     140   170    61 F     Yes      Very Low  29.8 Medicaid  current\n 4 A0013     143   118    51 M     No       Very Low  41.8 Medicaid  quit   \n 5 A0015     162   132    61 F     No       Very Low  31.0 Medicaid  never  \n 6 A0017     141   110    45 F     No       Low       33.0 Medicaid  current\n 7 A0018     101   127    40 F     Yes      Very Low  36.3 Medicaid  never  \n 8 A0019     154   152    50 F     Yes      Middle    30.8 Medicaid  never  \n 9 A0020     111   125    43 M     No       Low       23.1 Medicaid  current\n10 A0028     154   140    56 F     No       Low       36.5 Medicaid  quit   \n# ℹ 953 more rows\n# ℹ 2 more variables: statin &lt;dbl&gt;, diuretic &lt;dbl&gt;\n\n\nThat’s fine for Project B.\n\n\n2.7.4 What if we instead did imputation?\nAs an alternative (NOT expected in any way for Project B), we could use the simputation package to impute missing values of tobacco, bmi1 and nbhd_ses. For each of these, we need to specify the approach we will use to do the imputation, and the variables we plan to use as predictors in our imputation model (the variables we plan to use to help predict the missing values). Some of these choices will be a little arbitrary, but I’m mostly demonstrating options here.\n\n\n\n\n\n\n\n\n\n\nVariable\nNAs\nClass\nImputation Approach\nImputation Model Predictors\n\n\n\n\nnbhd_ses\n8\nfactor\nCART (decision tree)\nage, sex, insurance\n\n\ntobacco\n23\nfactor\nCART (decision tree)\nage, sex, insurance, nbhd_ses\n\n\nbmi1\n5\nnumeric\nRobust Linear Model\nage, sex, diabetes, sbp1\n\n\n\nHere’s the actual set of imputation commands, to create an imputed data set named hbp_imputed.\n\nhbp_imputed &lt;- hbp_study |&gt;\n  impute_cart(nbhd_ses ~ age + sex + insurance) |&gt;\n  impute_cart(tobacco ~ age + sex + insurance + nbhd_ses) |&gt;\n  impute_rlm(bmi1 ~ age + sex + diabetes + sbp1)\n\nsummary(hbp_imputed)\n\n   subj_id               age        sex     diabetes      nbhd_ses  \n Length:999         Min.   :33.00   F:655   No :668   Very Low:220  \n Class :character   1st Qu.:52.00   M:344   Yes:331   Low     :343  \n Mode  :character   Median :59.00                     Middle  :282  \n                    Mean   :58.69                     High    :154  \n                    3rd Qu.:66.00                                   \n                    Max.   :83.00                                   \n      bmi1            sbp1           insurance      tobacco        statin      \n Min.   :16.72   Min.   : 81.0   Medicare :402   never  :319   Min.   :0.0000  \n 1st Qu.:27.91   1st Qu.:124.0   Private  :160   quit   :374   1st Qu.:0.0000  \n Median :32.18   Median :136.0   Medicaid :398   current:306   Median :1.0000  \n Mean   :33.74   Mean   :136.5   Uninsured: 39                 Mean   :0.5566  \n 3rd Qu.:38.33   3rd Qu.:147.0                                 3rd Qu.:1.0000  \n Max.   :74.65   Max.   :205.0                                 Max.   :1.0000  \n    diuretic           sbp2      \n Min.   :0.0000   Min.   : 77.0  \n 1st Qu.:0.0000   1st Qu.:121.0  \n Median :1.0000   Median :133.0  \n Mean   :0.6657   Mean   :133.7  \n 3rd Qu.:1.0000   3rd Qu.:144.0  \n Max.   :1.0000   Max.   :203.0  \n\n\nNote that I imputed tobacco after nbhd_ses largely because I wanted to use the nbhd_ses results to aid in my imputation of tobacco."
  },
  {
    "objectID": "sample-study2.html#the-codebook",
    "href": "sample-study2.html#the-codebook",
    "title": "431 Project B Sample Study 2 Report",
    "section": "3.1 The Codebook",
    "text": "3.1 The Codebook\nThe 12 variables in the hbp_cc tidy data set for this demonstration are as follows.\n\n\n\n\n\n\n\n\nVariable\nType\nDescription / Levels\n\n\n\n\nsubj_id\nCharacter\nsubject code (A001-A999)\n\n\nsbp2\nQuantitative\noutcome variable, SBP after 18 months, in mm Hg\n\n\nsbp1\nQuantitative\nkey predictor baseline SBP (systolic blood pressure), in mm Hg\n\n\nage\nQuantitative\nage of subject at baseline, in years\n\n\nsex\nBinary\nMale or Female\n\n\ndiabetes\nBinary\nDoes subject have a diabetes diagnosis: No or Yes\n\n\nnbhd_ses\n4 level Cat.\nSocio-economic status of subject’s home neighborhood: Very Low, Low, Middle and High\n\n\nbmi1\nQuantitative\nsubject’s body-mass index at baseline\n\n\ninsurance\n4 level Cat.\nsubject’s insurance status at baseline: Medicare, Private, Medicaid, Uninsured\n\n\ntobacco\n3 level Cat.\nsubject’s tobacco use at baseline: never, quit (former), current\n\n\nstatin\nBinary\n1 = statin prescription at baseline, else 0\n\n\ndiuretic\nBinary\n1 = diuretic prescription at baseline, else 0\n\n\n\nNote: I’ve demonstrated this task for a larger set of predictors than I actually intend to use. In fitting my models, I actually plan only to use five predictors: sbp1, age, bmi1, diabetes and tobacco to model my outcome: sbp2.\nFor what follows, I’ll focus only on the variables I actually will use in the analyses.\n\nhbp_analytic &lt;- hbp_cc |&gt;\n  select(subj_id, sbp2, sbp1, age, bmi1, diabetes, tobacco)"
  },
  {
    "objectID": "sample-study2.html#analytic-tibble",
    "href": "sample-study2.html#analytic-tibble",
    "title": "431 Project B Sample Study 2 Report",
    "section": "3.2 Analytic Tibble",
    "text": "3.2 Analytic Tibble\nFirst, we’ll provide a printout of the tibble, which will confirm that we have one.\n\nhbp_analytic\n\n# A tibble: 963 × 7\n   subj_id  sbp2  sbp1   age  bmi1 diabetes tobacco\n   &lt;chr&gt;   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n 1 A0001     138   147    58  24.4 No       never  \n 2 A0004     134   134    65  50.5 No       never  \n 3 A0005     140   170    61  29.8 Yes      current\n 4 A0013     143   118    51  41.8 No       quit   \n 5 A0015     162   132    61  31.0 No       never  \n 6 A0017     141   110    45  33.0 No       current\n 7 A0018     101   127    40  36.3 Yes      never  \n 8 A0019     154   152    50  30.8 Yes      never  \n 9 A0020     111   125    43  23.1 No       current\n10 A0028     154   140    56  36.5 No       quit   \n# ℹ 953 more rows\n\n\nSince we’re using df_print: paged in our YAML, we need also to demonstrate that we have a tibble.\n\nis_tibble(hbp_analytic)\n\n[1] TRUE\n\n\nOK. All set."
  },
  {
    "objectID": "sample-study2.html#numerical-data-description",
    "href": "sample-study2.html#numerical-data-description",
    "title": "431 Project B Sample Study 2 Report",
    "section": "3.3 Numerical Data Description",
    "text": "3.3 Numerical Data Description\n\ndescribe(hbp_analytic |&gt; select(-subj_id)) |&gt; html()\n\n\n\n\n\nselect(hbp_analytic, -subj_id) Descriptives\nselect(hbp_analytic, -subj_id)  6  Variables   963  Observations\n\nsbp2\n\n \n nmissingdistinctInfoMeanpMedianGmd.05.10.25.50.75.90.95\n 9630951133.8133.520.1106.0111.0121.0133.0144.0156.0165.8\n \n\nlowest :  77  90  91  94  95 ,  highest: 186 190 196 200 203\n\nsbp1\n\n \n nmissingdistinctInfoMeanpMedianGmd.05.10.25.50.75.90.95\n 96301001136.513620.43108115124136147160168\n \n\nlowest :  81  83  91  92  93 ,  highest: 198 201 202 203 205\n\nage\n\n \n nmissingdistinctInfoMeanpMedianGmd.05.10.25.50.75.90.95\n 9630510.99958.7558.511.9740.145.052.059.066.074.076.0\n \n\nlowest : 33 34 35 36 37 ,  highest: 79 80 81 82 83\n\nbmi1\n\n \n nmissingdistinctInfoMeanpMedianGmd.05.10.25.50.75.90.95\n 9630807133.6832.989.06522.7624.5127.9132.1338.3044.8649.88\n \n\nlowest : 16.72 17.79 18    18.44 18.54 ,  highest: 64.3  65.43 65.46 65.95 74.65\n\ndiabetes\n\n \n nmissingdistinct\n 96302\n \n\n Value         No   Yes\n Frequency    644   319\n Proportion 0.669 0.331 \n\n\ntobacco\n\n \n nmissingdistinct\n 96303\n \n\n Value        never    quit current\n Frequency      316     356     291\n Proportion   0.328   0.370   0.302 \n\n\n\n\nWe should (and do) see no missing or implausible values here, and our categorical variables are treated as factors with a rational ordering for the levels."
  },
  {
    "objectID": "sample-study2.html#visualizing-the-outcome-distribution",
    "href": "sample-study2.html#visualizing-the-outcome-distribution",
    "title": "431 Project B Sample Study 2 Report",
    "section": "6.1 Visualizing the Outcome Distribution",
    "text": "6.1 Visualizing the Outcome Distribution\nI see at least three potential graphs to use to describe the distribution of our outcome variable, sbp2. Again, remember we’re using only the training sample here.\n\nA boxplot, probably accompanied by a violin plot to show the shape of the distribution more honestly.\nA histogram, which could perhaps be presented as a density plot with a Normal distribution superimposed.\nA Normal Q-Q plot to directly assess Normality.\n\nI expect you to show at least two of these three, but I will display all three here. Should we see substantial skew in the outcome data, we will want to consider an appropriate transformation, and then display the results of that transformation, as well.\nWARNING: Please note that I am deliberately showing you plots that are less finished than I hope you will provide.\n\nThe coloring is dull or non-existent.\nThe theme is the default gray and white grid that lots of people dislike.\nThere are no meaningful titles or subtitles.\nThe axis labels select the default settings, and use incomprehensible variable names.\nThe coordinates aren’t flipped when that might be appropriate.\nI expect a much nicer presentation in your final work. Use the class slides and Lab answer sketches as a model for better plotting.\n\n\nviz1 &lt;- ggplot(hbp_training, aes(x = \"\", y = sbp2)) +\n  geom_violin() +\n  geom_boxplot(width = 0.25)\n\nviz2 &lt;- ggplot(hbp_training, aes(x = sbp2)) +\n  geom_histogram(bins = 30, col = \"white\")\n\nviz3 &lt;- ggplot(hbp_training, aes(sample = sbp2)) +\n  geom_qq() + geom_qq_line()\n\nviz1 + viz2 + viz3 +\n  plot_annotation(title = \"Less-Than-Great Plots of My Outcome's Distribution\",\n                  subtitle = \"complete with a rotten title, default axis labels and bad captions\")\n\n\n\n\n\n\n\n\nLater, we’ll augment this initial look at the outcome data with a Box-Cox plot to suggest a potential transformation. Should you decide to make such a transformation, remember to return here to plot the results for your new and transformed outcome."
  },
  {
    "objectID": "sample-study2.html#numerical-summary-of-the-outcome",
    "href": "sample-study2.html#numerical-summary-of-the-outcome",
    "title": "431 Project B Sample Study 2 Report",
    "section": "6.2 Numerical Summary of the Outcome",
    "text": "6.2 Numerical Summary of the Outcome\nAssuming you plan no transformation of the outcome (and in our case, I am happy that the outcome data appear reasonably well-modeled by the Normal distribution) then you should just summarize the training data, with your favorite tool for that task. That might be:\n\nfavstats from the mosaic package, as shown below, or\ndescribe from the Hmisc package, or\nsomething else, I guess.\n\nBut show ONE of these choices, and not all of them. Make a decision and go with it!\n\nfavstats(~ sbp2, data = hbp_training)\n\n min  Q1 median  Q3 max     mean       sd   n missing\n  90 122    134 144 203 133.9852 17.83888 674       0"
  },
  {
    "objectID": "sample-study2.html#numerical-summaries-of-the-predictors",
    "href": "sample-study2.html#numerical-summaries-of-the-predictors",
    "title": "431 Project B Sample Study 2 Report",
    "section": "6.3 Numerical Summaries of the Predictors",
    "text": "6.3 Numerical Summaries of the Predictors\nWe also need an appropriate set of numerical summaries of each predictor variable, in the training data. I see at least two potential options here:\n\nUse inspect from the mosaic package to describe the predictors of interest briefly.\nUse describe from the Hmisc package for a more detailed description of the entire data set.\n\nAgain, DO NOT do all of these. Pick one that works for you. I’m just demonstrating possible choices here.\n\n6.3.1 Using the inspect function from mosaic\nThe inspect function provides a way to get results like favstats, but for an entire data frame.\n\nhbp_training |&gt; select(-subj_id, -sbp2) |&gt; \n  inspect()\n\n\ncategorical variables:  \n      name  class levels   n missing\n1 diabetes factor      2 674       0\n2  tobacco factor      3 674       0\n                                   distribution\n1 No (69%), Yes (31%)                          \n2 quit (38.4%), never (32.9%) ...              \n\nquantitative variables:  \n  name   class   min     Q1  median      Q3    max      mean        sd   n\n1 sbp1 numeric 91.00 124.00 135.000 146.000 205.00 136.02226 18.059200 674\n2  age numeric 33.00  52.00  59.000  66.000  82.00  58.70030 10.836723 674\n3 bmi1 numeric 16.72  27.69  31.915  38.365  74.65  33.57628  8.318113 674\n  missing\n1       0\n2       0\n3       0\n\n\nNext, we will build and interpret a scatterplot matrix to describe the associations (both numerically and graphically) between the outcome and all predictors.\n\nWe’ll also use a Box-Cox plot to investigate whether a transformation of our outcome is suggested, and\ndescribe what a correlation matrix suggests about collinearity between candidate predictors."
  },
  {
    "objectID": "sample-study2.html#scatterplot-matrix",
    "href": "sample-study2.html#scatterplot-matrix",
    "title": "431 Project B Sample Study 2 Report",
    "section": "6.4 Scatterplot Matrix",
    "text": "6.4 Scatterplot Matrix\nHere, we will build a scatterplot matrix (or two) to show the relationship between our outcome and the predictors. I’ll demonstrate the use of ggpairs from the GGally package.\n\nIf you have more than five predictors (as we do in our case) you should build two scatterplot matrices, each ending with the outcome. Anything more than one outcome and five predictors becomes unreadable in Professor Love’s view.\nIf you have a multi-categorical predictor with more than four categories, that predictor will be very difficult to see and explore in the scatterplot matrix produced.\n\n\ntemp &lt;- hbp_training |&gt; \n  select(sbp1, age, bmi1, diabetes, tobacco, sbp2) \n\nggpairs(temp, title = \"Scatterplot Matrix\",\n        lower = list(combo = wrap(\"facethist\", bins = 20)))\n\n\n\n\n\n\n\n\nAt the end of this section, you should provide some discussion of the distribution of any key predictors, and their relationship to the outcome (all of that is provided in the bottom row if you place the outcome last, as you should, in selecting variables for the plot.)\nHINT: For categorical variables, your efforts in this regard to summarize the relationships you see may be challenging. Your comments would be aided by the judicious use of numerical summaries. For example, suppose you want to study the relationship between tobacco use and sbp2, then you probably want to run and discuss the following results, in addition to the scatterplot matrix above.\n\nfavstats(sbp2 ~ tobacco, data = hbp_training)\n\n  tobacco min  Q1 median     Q3 max     mean       sd   n missing\n1   never  95 126    135 145.75 180 135.5405 17.02980 222       0\n2    quit  91 120    132 142.00 182 132.3359 16.62022 259       0\n3 current  90 120    135 147.00 203 134.4093 20.09465 193       0"
  },
  {
    "objectID": "sample-study2.html#collinearity-checking",
    "href": "sample-study2.html#collinearity-checking",
    "title": "431 Project B Sample Study 2 Report",
    "section": "6.5 Collinearity Checking",
    "text": "6.5 Collinearity Checking\nNext, we’ll take a brief look at potential collinearity. Remember that we want to see strong correlations between our outcome and the predictors, but relatively modest correlations between the predictors.\nNone of the numeric candidate predictors show any substantial correlation with each other. The largest Pearson correlation (in absolute value) between predictors is (-0.239) for age and bmi1, and that’s not strong. If we did see signs of meaningful collinearity, we might rethink our selected set of predictors.\nI’ll recommend later that you run a generalized VIF (variance inflation factor) calculation2 after fitting your kitchen sink model just to see if anything pops up (in my case, it won’t.)"
  },
  {
    "objectID": "sample-study2.html#boxcox-function-to-assess-need-for-transformation-of-our-outcome",
    "href": "sample-study2.html#boxcox-function-to-assess-need-for-transformation-of-our-outcome",
    "title": "431 Project B Sample Study 2 Report",
    "section": "6.6 boxCox function to assess need for transformation of our outcome",
    "text": "6.6 boxCox function to assess need for transformation of our outcome\nTo use the boxCox approach here, we need to ensure that the distribution of our outcome, sbp2, includes strictly positive values. We can see from our numerical summary earlier that the minimum sbp2 in our hbp_training sample is 90, so we’re OK.\n\nNote that I am restricting myself here to the five predictors I actually intend to use in building models.\nAlthough we’re generally using a 90% confidence interval in this project, we won’t worry about that issue in the boxCox plot, and instead just look at the point estimate from powerTransform.\nThese commands (boxCox and powerTransform) come from the car package.\n\n\nmodel_temp &lt;- lm(sbp2 ~ sbp1 + age + bmi1 + diabetes + tobacco,\n                 data = hbp_training)\n\nboxCox(model_temp)\n\n\n\n\n\n\n\npowerTransform(model_temp)\n\nEstimated transformation parameter \n       Y1 \n0.4913275 \n\n\nThe estimated power transformation is about 0.5, which looks like a square root transformation of sbp2 is useful. Given that I’m using another measure of sbp, specifically, sbp1 to predict sbp2, perhaps I want to transform that, too?\n\np1 &lt;- ggplot(hbp_training, aes(x = sbp1, y = sqrt(sbp2))) +\n  geom_point() +\n  geom_smooth(method = \"loess\", formula = y ~ x, se = FALSE) + \n  geom_smooth(method = \"lm\", col = \"red\", formula = y ~ x, se = FALSE) +\n  labs(title = \"SQRT(sbp2) vs. SBP1\")\n\np2 &lt;- ggplot(hbp_training, aes(x = sqrt(sbp1), y = sqrt(sbp2))) +\n  geom_point() +\n  geom_smooth(method = \"loess\", formula = y ~ x, se = FALSE) + \n  geom_smooth(method = \"lm\", col = \"red\", formula = y ~ x, se = FALSE) + \n  labs(title = \"SQRT(sbp2) vs. SQRT(sbp1)\")\n\np1 + p2\n\n\n\n\n\n\n\n\nI don’t see an especially large difference between these two plots. It is up to you to decide whether a transformation suggested by boxCox should be applied to your data.\n\nFor the purposes of this project, you should stick to transformations of strictly positive outcomes, and to the square root (power = 0.5), square (power = 2), logarithm (power = 0) and inverse (power = -1) transformations. Don’t make the transformation without being able to interpret the result well.\nIf you do decide to include a transformation of your outcome in fitting models, be sure to back-transform any predictions you make at the end of the study so that we can understand the prediction error results.\nIf your outcome data are substantially multimodal, I wouldn’t treat the boxCox results as meaningful.\n\nI’m going to use the square root transformation for both my outcome and for the key predictor, but I don’t think it makes a big difference. I’m doing it mostly so that I can show you how to back-transform later."
  },
  {
    "objectID": "sample-study2.html#fittingsummarizing-the-kitchen-sink-model",
    "href": "sample-study2.html#fittingsummarizing-the-kitchen-sink-model",
    "title": "431 Project B Sample Study 2 Report",
    "section": "7.1 Fitting/Summarizing the Kitchen Sink model",
    "text": "7.1 Fitting/Summarizing the Kitchen Sink model\nOur “kitchen sink” or “big” model predicts the square root of sbp2 using the predictors (square root of sbp1), age, bmi1, diabetes and tobacco.\n\nmodel_big &lt;- lm(sqrt(sbp2) ~ sqrt(sbp1) + age + bmi1 + diabetes + tobacco, \n                data = hbp_training)\n\n\nsummary(model_big)\n\n\nCall:\nlm(formula = sqrt(sbp2) ~ sqrt(sbp1) + age + bmi1 + diabetes + \n    tobacco, data = hbp_training)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.13388 -0.45071 -0.00603  0.45391  2.28459 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     6.917075   0.466656  14.823   &lt;2e-16 ***\nsqrt(sbp1)      0.367990   0.036014  10.218   &lt;2e-16 ***\nage             0.004754   0.002731   1.741   0.0822 .  \nbmi1            0.002874   0.003571   0.805   0.4211    \ndiabetesYes     0.052141   0.060626   0.860   0.3901    \ntobaccoquit    -0.119091   0.065962  -1.805   0.0715 .  \ntobaccocurrent  0.014155   0.073194   0.193   0.8467    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7136 on 667 degrees of freedom\nMultiple R-squared:  0.1478,    Adjusted R-squared:  0.1402 \nF-statistic: 19.29 on 6 and 667 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "sample-study2.html#effect-sizes-coefficient-estimates",
    "href": "sample-study2.html#effect-sizes-coefficient-estimates",
    "title": "431 Project B Sample Study 2 Report",
    "section": "7.2 Effect Sizes: Coefficient Estimates",
    "text": "7.2 Effect Sizes: Coefficient Estimates\nSpecify the size and magnitude of all coefficients, providing estimated effect sizes with 90% confidence intervals.\n\ntidy(model_big, conf.int = TRUE, conf.level = 0.90) |&gt; \n  select(term, estimate, std.error, conf.low, conf.high, p.value) |&gt; \n  kable(dig = 4)\n\n\n\n\nterm\nestimate\nstd.error\nconf.low\nconf.high\np.value\n\n\n\n\n(Intercept)\n6.9171\n0.4667\n6.1484\n7.6857\n0.0000\n\n\nsqrt(sbp1)\n0.3680\n0.0360\n0.3087\n0.4273\n0.0000\n\n\nage\n0.0048\n0.0027\n0.0003\n0.0093\n0.0822\n\n\nbmi1\n0.0029\n0.0036\n-0.0030\n0.0088\n0.4211\n\n\ndiabetesYes\n0.0521\n0.0606\n-0.0477\n0.1520\n0.3901\n\n\ntobaccoquit\n-0.1191\n0.0660\n-0.2277\n-0.0104\n0.0715\n\n\ntobaccocurrent\n0.0142\n0.0732\n-0.1064\n0.1347\n0.8467\n\n\n\n\n\nI wanted to get at least two significant figures in my coefficient and standard error estimates for all of the predictors in this model, so that’s why I had to go out to 4 decimal places."
  },
  {
    "objectID": "sample-study2.html#describing-the-equation",
    "href": "sample-study2.html#describing-the-equation",
    "title": "431 Project B Sample Study 2 Report",
    "section": "7.3 Describing the Equation",
    "text": "7.3 Describing the Equation\nThis model implies for the key predictor that:\n\nfor every increase of one point in the square root of sbp1, we anticipate an increase in the outcome (square root of sbp2) of 0.37 mm Hg (90% confidence interval: 0.31, 0.43). If we had two subjects with the same values of all other variables, but A had a baseline square root of SBP of 12 (so an SBP at baseline of 144) and B had a baseline square root of SBP of 11 (so an SBP at baseline of 121) then if all other variables are kept at the same value, our model predicts that the square root of subject A’s SBP at 18 months will be 0.37 points higher (90% CI: 0.31, 0.43) than that of subject B.\n\nYou should provide a (briefer) description of the meaning (especially the direction) of the other coefficients in your model being sure only to interpret the coefficients as having meaning holding all other predictors constant, but I’ll skip that in the demo."
  },
  {
    "objectID": "sample-study2.html#backwards-stepwise-elimination",
    "href": "sample-study2.html#backwards-stepwise-elimination",
    "title": "431 Project B Sample Study 2 Report",
    "section": "8.1 Backwards Stepwise Elimination",
    "text": "8.1 Backwards Stepwise Elimination\n\nstep(model_big)\n\nStart:  AIC=-447.95\nsqrt(sbp2) ~ sqrt(sbp1) + age + bmi1 + diabetes + tobacco\n\n             Df Sum of Sq    RSS     AIC\n- bmi1        1     0.330 339.96 -449.30\n- diabetes    1     0.377 340.00 -449.20\n&lt;none&gt;                    339.63 -447.95\n- tobacco     2     2.406 342.03 -447.19\n- age         1     1.543 341.17 -446.89\n- sqrt(sbp1)  1    53.163 392.79 -351.93\n\nStep:  AIC=-449.3\nsqrt(sbp2) ~ sqrt(sbp1) + age + diabetes + tobacco\n\n             Df Sum of Sq    RSS     AIC\n- diabetes    1     0.521 340.48 -450.26\n&lt;none&gt;                    339.96 -449.30\n- age         1     1.267 341.22 -448.79\n- tobacco     2     2.344 342.30 -448.66\n- sqrt(sbp1)  1    54.053 394.01 -351.84\n\nStep:  AIC=-450.26\nsqrt(sbp2) ~ sqrt(sbp1) + age + tobacco\n\n             Df Sum of Sq    RSS     AIC\n&lt;none&gt;                    340.48 -450.26\n- tobacco     2     2.191 342.67 -449.94\n- age         1     1.238 341.71 -449.82\n- sqrt(sbp1)  1    53.805 394.28 -353.37\n\n\n\nCall:\nlm(formula = sqrt(sbp2) ~ sqrt(sbp1) + age + tobacco, data = hbp_training)\n\nCoefficients:\n   (Intercept)      sqrt(sbp1)             age     tobaccoquit  tobaccocurrent  \n      7.062241        0.369099        0.004084       -0.121333       -0.004054  \n\n\nThe backwards selection stepwise approach suggests a model with sqrt(sbp1) and age and tobacco, but not bmi1 or diabetes.\n\nIf stepwise regression retains the kitchen sink model or if you don’t want to use stepwise regression, develop an alternate model by selecting a subset of the Big model predictors (including the key predictor) on your own. A simple regression on the key predictor is a perfectly reasonable choice.\nIf stepwise regression throws out the key predictor in your kitchen sink model, then I suggest not using stepwise regression.\nWe will learn several other methods for variable selection in 432. If you want to use one of them (for instance, a C_p_ plot) here, that’s OK, but I will hold you to high expectations for getting that done correctly, and it’s worth remembering that none of them work very well at identifying the “best” model."
  },
  {
    "objectID": "sample-study2.html#fitting-the-small-model",
    "href": "sample-study2.html#fitting-the-small-model",
    "title": "431 Project B Sample Study 2 Report",
    "section": "8.2 Fitting the “small” model",
    "text": "8.2 Fitting the “small” model\n\nmodel_small &lt;- lm(sqrt(sbp2) ~ sqrt(sbp1) + age + tobacco, data = hbp_training)\n\nsummary(model_small)\n\n\nCall:\nlm(formula = sqrt(sbp2) ~ sqrt(sbp1) + age + tobacco, data = hbp_training)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.15438 -0.46050  0.00618  0.45691  2.26418 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     7.062241   0.444201  15.899   &lt;2e-16 ***\nsqrt(sbp1)      0.369099   0.035897  10.282   &lt;2e-16 ***\nage             0.004084   0.002618   1.560    0.119    \ntobaccoquit    -0.121333   0.065641  -1.848    0.065 .  \ntobaccocurrent -0.004054   0.071059  -0.057    0.955    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.7134 on 669 degrees of freedom\nMultiple R-squared:  0.1457,    Adjusted R-squared:  0.1406 \nF-statistic: 28.53 on 4 and 669 DF,  p-value: &lt; 2.2e-16"
  },
  {
    "objectID": "sample-study2.html#effect-sizes-coefficient-estimates-1",
    "href": "sample-study2.html#effect-sizes-coefficient-estimates-1",
    "title": "431 Project B Sample Study 2 Report",
    "section": "8.3 Effect Sizes: Coefficient Estimates",
    "text": "8.3 Effect Sizes: Coefficient Estimates\nHere, we specify the size and magnitude of all coefficients, providing estimated effect sizes with 90% confidence intervals.\n\ntidy(model_small, conf.int = TRUE, conf.level = 0.90) |&gt; \n  select(term, estimate, std.error, conf.low, conf.high, p.value) |&gt; \n  kable(dig = 4)\n\n\n\n\nterm\nestimate\nstd.error\nconf.low\nconf.high\np.value\n\n\n\n\n(Intercept)\n7.0622\n0.4442\n6.3306\n7.7939\n0.0000\n\n\nsqrt(sbp1)\n0.3691\n0.0359\n0.3100\n0.4282\n0.0000\n\n\nage\n0.0041\n0.0026\n-0.0002\n0.0084\n0.1193\n\n\ntobaccoquit\n-0.1213\n0.0656\n-0.2295\n-0.0132\n0.0650\n\n\ntobaccocurrent\n-0.0041\n0.0711\n-0.1211\n0.1130\n0.9545"
  },
  {
    "objectID": "sample-study2.html#interpreting-the-small-model-regression-equation",
    "href": "sample-study2.html#interpreting-the-small-model-regression-equation",
    "title": "431 Project B Sample Study 2 Report",
    "section": "8.4 Interpreting the Small Model Regression Equation",
    "text": "8.4 Interpreting the Small Model Regression Equation\nI’ll skip the necessary English sentences here in the demo that explain the meaning of the estimates in our model."
  },
  {
    "objectID": "sample-study2.html#quality-of-fit",
    "href": "sample-study2.html#quality-of-fit",
    "title": "431 Project B Sample Study 2 Report",
    "section": "9.1 Quality of Fit",
    "text": "9.1 Quality of Fit\nWe will compare the small model to the big model in our training sample using adjusted R2, the residual standard error, AIC and BIC. We’ll be a little bit slick here.\n\nFirst, we’ll use glance to build a tibble of key results for the kitchen sink model, and append to that a description of the model. We’ll toss that in a temporary tibble called temp_a.\nNext we do the same for the smaller model, and put that in temp_b.\nFinally, we put the temp files together into a new tibble, called training_comp, and examine that.\n\n\ntemp_a &lt;- glance(model_big) |&gt; \n  select(-logLik, -deviance) |&gt;\n  round(digits = 3) |&gt;\n  mutate(modelname = \"big\")\n\ntemp_b &lt;- glance(model_small) |&gt;\n  select(-logLik, -deviance) |&gt;\n  round(digits = 3) |&gt;\n  mutate(modelname = \"small\")\n\ntraining_comp &lt;- bind_rows(temp_a, temp_b) |&gt;\n  select(modelname, nobs, df, AIC, BIC, everything())\n\n\ntraining_comp\n\n# A tibble: 2 × 11\n  modelname  nobs    df   AIC   BIC r.squared adj.r.squared sigma statistic\n  &lt;chr&gt;     &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 big         674     6 1467. 1503.     0.148         0.14  0.714      19.3\n2 small       674     4 1464. 1492.     0.146         0.141 0.713      28.5\n# ℹ 2 more variables: p.value &lt;dbl&gt;, df.residual &lt;dbl&gt;\n\n\nIt looks like the smaller model with 3 predictors: sqrt(sbp1), age and tobacco, performs slightly better in the training sample.\n\nThe AIC and BIC for the smaller model are each a little smaller than for the big model.\nThe adjusted R2 and residual standard deviation (sigma) is essentially identical in the two models."
  },
  {
    "objectID": "sample-study2.html#assessing-assumptions",
    "href": "sample-study2.html#assessing-assumptions",
    "title": "431 Project B Sample Study 2 Report",
    "section": "9.2 Assessing Assumptions",
    "text": "9.2 Assessing Assumptions\nHere, we should run a set of residual plots for each model. If you want to impress me a little, you’ll use the ggplot versions I introduced in the slides for Classes 22-24. Otherwise, it’s perfectly fine just to show the plots available in base R.\n\n9.2.1 Residual Plots for the Big Model\n\npar(mfrow = c(2,2)); plot(model_big); par(mfrow = c(1,1))\n\n\n\n\n\n\n\n\nI see no serious problems with the assumptions of linearity, Normality and constant variance, nor do I see any highly influential points in our big model.\n\n\n9.2.2 Residual Plots for the Small Model\n\npar(mfrow = c(2,2)); plot(model_small); par(mfrow = c(1,1))\n\n\n\n\n\n\n\n\nI see no serious problems with the assumptions of linearity, Normality and constant variance, nor do I see any highly influential points in our small model.\n\n\n9.2.3 Does collinearity have a meaningful impact?\nIf we fit models with multiple predictors, then we might want to assess the potential impact of collinearity.\n\ncar::vif(model_big)\n\n               GVIF Df GVIF^(1/(2*Df))\nsqrt(sbp1) 1.010439  1        1.005206\nage        1.157633  1        1.075934\nbmi1       1.166054  1        1.079840\ndiabetes   1.040850  1        1.020221\ntobacco    1.138000  2        1.032846\n\n\nWe’d need to see a generalized variance inflation factor above 5 for collinearity to be a meaningful concern, so we should be fine in our big model. Our small model also has multiple predictors, but it cannot be an issue, since it’s just a subset of our big model, which didn’t have a collinearity problem."
  },
  {
    "objectID": "sample-study2.html#comparing-the-models",
    "href": "sample-study2.html#comparing-the-models",
    "title": "431 Project B Sample Study 2 Report",
    "section": "9.3 Comparing the Models",
    "text": "9.3 Comparing the Models\nBased on the training sample, my conclusions so far is to support the smaller model. It has (slightly) better performance on the fit quality measures, and each model shows no serious problems with regression assumptions."
  },
  {
    "objectID": "sample-study2.html#calculating-prediction-errors",
    "href": "sample-study2.html#calculating-prediction-errors",
    "title": "431 Project B Sample Study 2 Report",
    "section": "10.1 Calculating Prediction Errors",
    "text": "10.1 Calculating Prediction Errors\n\n10.1.1 Big Model: Back-Transformation and Calculating Fits/Residuals\nWe’ll use the augment function from the broom package to help us here, and create sbp2_fit to hold the fitted values on the original sbp2 scale after back-transformation (by squaring the predictions on the square root scale) and then sbp2_res to hold the residuals (prediction errors) we observe using the big model on the hbp_test data.\n\naug_big &lt;- augment(model_big, newdata = hbp_test) |&gt; \n  mutate(mod_name = \"big\",\n         sbp2_fit = .fitted^2,\n         sbp2_res = sbp2 - sbp2_fit) |&gt;\n  select(subj_id, mod_name, sbp2, sbp2_fit, sbp2_res, everything())\n\nhead(aug_big,3)\n\n# A tibble: 3 × 12\n  subj_id mod_name  sbp2 sbp2_fit sbp2_res  sbp1   age  bmi1 diabetes tobacco\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n1 A0004   big        134     135.    -1.28   134    65  50.5 No       never  \n2 A0015   big        162     133.    29.2    132    61  31.0 No       never  \n3 A0020   big        111     128.   -17.1    125    43  23.1 No       current\n# ℹ 2 more variables: .fitted &lt;dbl&gt;, .resid &lt;dbl&gt;\n\n\n\n\n10.1.2 Small Model: Back-Transformation and Calculating Fits/Residuals\nWe’ll do the same thing, but using the small model in the hbp_test data.\n\naug_small &lt;- augment(model_small, newdata = hbp_test) |&gt; \n  mutate(mod_name = \"small\",\n         sbp2_fit = .fitted^2,\n         sbp2_res = sbp2 - sbp2_fit) |&gt;\n  select(subj_id, mod_name, sbp2, sbp2_fit, sbp2_res, everything())\n\nhead(aug_small,3)\n\n# A tibble: 3 × 12\n  subj_id mod_name  sbp2 sbp2_fit sbp2_res  sbp1   age  bmi1 diabetes tobacco\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n1 A0004   small      134     135.   -0.568   134    65  50.5 No       never  \n2 A0015   small      162     133.   28.6     132    61  31.0 No       never  \n3 A0020   small      111     129.  -18.1     125    43  23.1 No       current\n# ℹ 2 more variables: .fitted &lt;dbl&gt;, .resid &lt;dbl&gt;\n\n\n\n\n10.1.3 Combining the Results\n\ntest_comp &lt;- union(aug_big, aug_small) |&gt;\n  arrange(subj_id, mod_name)\n\ntest_comp |&gt; head()\n\n# A tibble: 6 × 12\n  subj_id mod_name  sbp2 sbp2_fit sbp2_res  sbp1   age  bmi1 diabetes tobacco\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n1 A0004   big        134     135.   -1.28    134    65  50.5 No       never  \n2 A0004   small      134     135.   -0.568   134    65  50.5 No       never  \n3 A0009   big        139     133.    5.94    133    57  31.0 No       current\n4 A0009   small      139     133.    5.65    133    57  31.0 No       current\n5 A0010   big        134     138.   -3.86    150    72  32.8 No       quit   \n6 A0010   small      134     138.   -4.19    150    72  32.8 No       quit   \n# ℹ 2 more variables: .fitted &lt;dbl&gt;, .resid &lt;dbl&gt;\n\n\nGiven this test_comp tibble, including predictions and residuals from the kitchen sink model on our test data, we can now:\n\nVisualize the prediction errors from each model.\nSummarize those errors across each model.\nIdentify the “worst fitting” subject for each model in the test sample.\n\nThe next few subsections actually do these things."
  },
  {
    "objectID": "sample-study2.html#visualizing-the-predictions",
    "href": "sample-study2.html#visualizing-the-predictions",
    "title": "431 Project B Sample Study 2 Report",
    "section": "10.2 Visualizing the Predictions",
    "text": "10.2 Visualizing the Predictions\n\nggplot(test_comp, aes(x = sbp2_fit, y = sbp2)) +\n  geom_point() +\n  geom_abline(slope = 1, intercept = 0, lty = \"dashed\") + \n  geom_smooth(method = \"loess\", col = \"blue\", se = FALSE, formula = y ~ x) +\n  facet_wrap( ~ mod_name, labeller = \"label_both\") +\n  labs(x = \"Predicted sbp2\",\n       y = \"Observed sbp2\",\n       title = \"Observed vs. Predicted sbp2\",\n       subtitle = \"Comparing Big to Small Model in Test Sample\",\n       caption = \"Dashed line is where Observed = Predicted\")\n\n\n\n\n\n\n\n\nI’m not seeing a lot of difference between the models in terms of the adherence of the points to the dashed line. The models seem to be making fairly similar errors."
  },
  {
    "objectID": "sample-study2.html#summarizing-the-errors",
    "href": "sample-study2.html#summarizing-the-errors",
    "title": "431 Project B Sample Study 2 Report",
    "section": "10.3 Summarizing the Errors",
    "text": "10.3 Summarizing the Errors\nCalculate the mean absolute prediction error (MAPE), the root mean squared prediction error (RMSPE) and the maximum absolute error across the predictions made by each model.\n\ntest_comp |&gt;\n  group_by(mod_name) |&gt;\n  summarise(n = n(),\n            MAPE = mean(abs(sbp2_res)), \n            RMSPE = sqrt(mean(sbp2_res^2)),\n            max_error = max(abs(sbp2_res)))\n\n# A tibble: 2 × 5\n  mod_name     n  MAPE RMSPE max_error\n  &lt;chr&gt;    &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 big        289  13.7  17.4      53.6\n2 small      289  13.7  17.4      52.9\n\n\nThis is a table Dr. Love will definitely need to see during your presentation.\nIn this case, two of these summaries are better (smaller) for the small model (RMSPE and max_error), suggesting (gently) that it is the better choice. The MAPE is the exception.\nThese models suggest an average error in predicting systolic blood pressure (using MAPE) of more than 13 mm Hg. That’s not great on the scale of systolic blood pressure, I think.\n\n10.3.1 Identify the largest errors\nIdentify the subject(s) where that maximum prediction error was made by each model, and the observed and model-fitted values of sbp_diff for that subject in each case.\n\ntemp1 &lt;- aug_big |&gt;\n  filter(abs(sbp2_res) == max(abs(sbp2_res)))\n\ntemp2 &lt;- aug_small |&gt;\n  filter(abs(sbp2_res) == max(abs(sbp2_res)))\n\nbind_rows(temp1, temp2)\n\n# A tibble: 2 × 12\n  subj_id mod_name  sbp2 sbp2_fit sbp2_res  sbp1   age  bmi1 diabetes tobacco\n  &lt;chr&gt;   &lt;chr&gt;    &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n1 A0513   big        200     146.     53.6   170    63  24.9 No       current\n2 A0513   small      200     147.     52.9   170    63  24.9 No       current\n# ℹ 2 more variables: .fitted &lt;dbl&gt;, .resid &lt;dbl&gt;\n\n\n\nIn our case, the same subject (A0513) was most poorly fit by each model.\n\n\n\n10.3.2 Validated R-square values\nHere’s the squared correlation between our predicted sbp2 and our actual sbp2 in the test sample, using the big model.\n\ncor(aug_big$sbp2, aug_big$sbp2_fit)^2\n\n[1] 0.1106822\n\n\nand here’s the R-square we obtained within the test sample for the small model.\n\ncor(aug_small$sbp2, aug_small$sbp2_fit)^2\n\n[1] 0.1110652\n\n\nNot really much of a difference. Note that either of these results suggest our training sample \\(R^2\\) (and even adjusted \\(R^2\\) values) were a bit optimistic."
  },
  {
    "objectID": "sample-study2.html#comparing-the-models-1",
    "href": "sample-study2.html#comparing-the-models-1",
    "title": "431 Project B Sample Study 2 Report",
    "section": "10.4 Comparing the Models",
    "text": "10.4 Comparing the Models\nI would select the smaller model here, on the basis of the similar performance in terms of the visualization of errors, and the small improvements in RMSPE and maximum prediction error, as well as validated \\(R^2\\)."
  },
  {
    "objectID": "sample-study2.html#chosen-model",
    "href": "sample-study2.html#chosen-model",
    "title": "431 Project B Sample Study 2 Report",
    "section": "11.1 Chosen Model",
    "text": "11.1 Chosen Model\nI chose the Small model. You’ll want to reiterate the reasons why in this subsection."
  },
  {
    "objectID": "sample-study2.html#answering-my-question",
    "href": "sample-study2.html#answering-my-question",
    "title": "431 Project B Sample Study 2 Report",
    "section": "11.2 Answering My Question",
    "text": "11.2 Answering My Question\nNow use the Small model to answer the research question, in a complete sentence of two."
  },
  {
    "objectID": "sample-study2.html#next-steps",
    "href": "sample-study2.html#next-steps",
    "title": "431 Project B Sample Study 2 Report",
    "section": "11.3 Next Steps",
    "text": "11.3 Next Steps\nDescribe an interesting next step, which might involve fitting a new model not available with your current cleaned data, or dealing with missing values differently, or obtaining new or better data, or something else. You should be able to describe why this might help."
  },
  {
    "objectID": "sample-study2.html#reflection",
    "href": "sample-study2.html#reflection",
    "title": "431 Project B Sample Study 2 Report",
    "section": "11.4 Reflection",
    "text": "11.4 Reflection\nTell us what you know now that would have changed your approach to Study 2 had you known it at the start."
  },
  {
    "objectID": "sample-study2.html#footnotes",
    "href": "sample-study2.html#footnotes",
    "title": "431 Project B Sample Study 2 Report",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAdmittedly, that’s not much better.↩︎\nAs we’ll see in that setting, none of the generalized variance inflation factors will exceed 1.1, let alone the 5 or so that would cause us to be seriously concerned about collinearity.↩︎"
  },
  {
    "objectID": "register.html",
    "href": "register.html",
    "title": "Registration for Project B",
    "section": "",
    "text": "You will use this Google Form to register for Project B. The deadline (for Project B Registration) is specified on the Course Calendar (it is in mid-November.)\n\nThe form is now open.\nYour response will be automatically emailed to your CWRU email once you submit the form. If you need to edit your submission, you can do so with the link included in that email.\nIf you are working with a partner, there will be an opportunity to indicate that on this form, and only one of you (you or your partner) should complete the whole thing, while the other person needs to only complete a few of the items, as you’ll see.\n\nOnce your form is complete, Dr. Love will review your submission and get back to you to tell you whether your proposed approach is approved or not. If not, you’ll have to edit your submission and resubmit the form."
  },
  {
    "objectID": "register.html#the-registration-form",
    "href": "register.html#the-registration-form",
    "title": "Registration for Project B",
    "section": "",
    "text": "You will use this Google Form to register for Project B. The deadline (for Project B Registration) is specified on the Course Calendar (it is in mid-November.)\n\nThe form is now open.\nYour response will be automatically emailed to your CWRU email once you submit the form. If you need to edit your submission, you can do so with the link included in that email.\nIf you are working with a partner, there will be an opportunity to indicate that on this form, and only one of you (you or your partner) should complete the whole thing, while the other person needs to only complete a few of the items, as you’ll see.\n\nOnce your form is complete, Dr. Love will review your submission and get back to you to tell you whether your proposed approach is approved or not. If not, you’ll have to edit your submission and resubmit the form."
  },
  {
    "objectID": "register.html#what-do-you-need-to-do-before-filling-out-the-form",
    "href": "register.html#what-do-you-need-to-do-before-filling-out-the-form",
    "title": "Registration for Project B",
    "section": "What Do You Need To Do Before Filling Out the Form?",
    "text": "What Do You Need To Do Before Filling Out the Form?\nFive things.\n\nDetermine whether or not you will work with a partner, and coordinate with that person to get all necessary tasks completed.\nIdentify whether you will use NHANES data or something else.\nObtain the data and figure out which variables you will use in Study 1 and in Study 2, making sure to meet the specifications for each study specified in the data development instructions.\nWithin your Study 2 variables, identify the number of observations in your data set with complete data on your variables (including your study ID code, your outcome, your key predictor and your 3-8 additional predictors).\nIdentify which times on December 6-11 work for you (and your partner) among those that are available (see below.) You’ll need to select at least five of the 20 available 75-minute periods in total, and this must include times on at least two different dates. The time slots are specified below.\n\n\nTime Periods for Presentations\nYour actual presentation time will be 20 minutes, but we have divided the schedule into 75 minute blocks below. During each block, we will schedule 3 presentations. On site means Dr. Love’s office at the School of Medicine at CWRU, and Zoom means via Zoom. Note that December 9 is a reading day, and the last day of class (for all classes) is December 6. Regardless of when you give your presentation, your final report is due at the deadline (December 11 at noon) in the course calendar.\nNote that you will need to select at least 5 of the available 20 time periods, and that those selections cannot all be on the same date.\n\nFriday December 6 (Zoom only) - last day of classes\n\n9:00 AM - 10:15 AM\n2:00 PM - 3:15 PM\n3:15 PM - 4:30 PM\n\n\n\nMonday December 9 (either On Site or Zoom) - Reading Day\n\n8:30 - 9:45 AM\n9:45 - 11:00 AM\n11:00 AM - 12:15 PM\n12:15 PM - 1:30 PM\n1:30 PM - 2:45 PM\n2:45 PM - 4:00 PM\n4:00 PM - 5:15 PM\n\n\n\nTuesday December 10 (Zoom only)\n\n8:30 - 9:45 AM\n9:45 - 11:00 AM\n11:00 AM - 12:15 PM\n12:15 PM - 1:30 PM\n1:30 PM - 2:45 PM\n2:45 PM - 4:00 PM\n5:00 PM - 6:15 PM\n\n\n\nWednesday December 11 (Zoom only)\n\n8:00 - 9:15 AM\n9:15 - 10:30 AM\n10:30 - 11:45 AM\n\nAll Project B Portfolios are due at Noon Wednesday 2024-12-11."
  },
  {
    "objectID": "data3.html",
    "href": "data3.html",
    "title": "Using Something other than NHANES",
    "section": "",
    "text": "This page describes what to do if you want to use something other than NHANES data for Project B. If you want to use NHANES data, then you should visit this page instead.\nIn either case, be sure to read through and verify that your data meet the Data Requirements for Study 1 and Study 2 described on our Data Development page.\nTo encourage people to use data other than NHANES, there is a four-point bonus in the final project B grade available for all projects which use non-NHANES data."
  },
  {
    "objectID": "data3.html#if-youre-using-data-from-another-source",
    "href": "data3.html#if-youre-using-data-from-another-source",
    "title": "Using Something other than NHANES",
    "section": "If you’re using data from another source",
    "text": "If you’re using data from another source\nIf you don’t want to use NHANES data, you will need to obtain Dr. Love’s approval through the registration form. Here are the data specifications.\n\nThe data must be freely available to all, and there must be no risk associated with your using the data for this project of any kind. Your use of the data for this project must not be subject to IRB approval, or the approval of anyone other than you (so, for example, if you would also need the approval of a principal investigator to use the data, that won’t work for Project B.)\n\nThere can be no protected health information or protected information or privacy risk of any kind involved with the data.\n\nDr. Love will need to see your source for the data in its entirety. You will need to be able to provide a link to a web page from which you (and Dr. Love and anyone else) can download the raw data as part of your registration for the project in mid-November.\nThe data must be cross-sectional, rather than longitudinal.\n\nThe only exception to this rule would be data where a baseline set of predictors is measured, which might include the baseline measure of the outcome, and then the outcome (and only the outcome) is measured at a later time.\n\nThe data must not be hierarchical, so everything must be measured at the subject level.\n\nWe cannot have subjects nested in states, for instance, with some variables measured only at the state level included in your set of variables.\nThe data you select must in all ways be suitable for the analyses required in Project B.\n\nThe data must not be from County Health Rankings, nor can they appear in any teaching repository of data (including the ones at Cleveland Clinic), nor can they be data from our 431 materials, including Lab assignments, Course Notes or Class Slides.\nThe data must not be pre-compiled as part of an R package, but rather available in raw form and ingested into R by you.\nDr. Love has a strong preference for data that describe individual people or animals, as opposed to other types of “subjects”. Who the subjects (rows) of your data are must be completely clear. No genomics data, either, in Project B - Dr. Love is insufficiently familiar with that sort of data.\nDr. Love can refuse to let you use a data set for any reason at all, and this includes the reason that he’s tired of the data set.\n\nPlease visit the Data Requirements for Study 1 and Study 2 on the Data Development page to ensure that your data will meet all necessary requirements."
  },
  {
    "objectID": "data1.html",
    "href": "data1.html",
    "title": "Data Development",
    "section": "",
    "text": "You must use the same data source for Study 1 and Study 2 in Project B. That data source must either be:\n\nNHANES data, as discussed here.\nsomething else, as discussed here.\n\nTo encourage people to use data other than NHANES, there is a four-point bonus in the final project B grade available for all projects which use non-NHANES data.\n\n\n\nData Requirements for Study 1 and Study 2\n\nNumber of observations\n\nIf you are using NHANES data, you will need between 500 and 7,500 observations with a minimum of 500 observations containing complete data on all of the variables you will use in Study 1 or Study 2.\nIf you are using any other data source, you will need between 250 and 10,000 observations, and at least 250 with complete data on all variables you will use in Study 1 or Study 2.\nWe require that all variables treated as quantitative in Study 1 (Analyses A, B, or C) or as your quantitative outcome in Study 2 contain at least 15 unique values.\nThe data must include a unique coded identifier (SEQN in NHANES) for each row (subject.)\n\nNumber and type of variables for Study 1 (where you will do 4 of the following 5 analyses)\n\nFor Analysis A, you will need appropriate data to allow you to compare two means using paired samples. So that would require a set of paired measurements of the same quantity, perhaps measurements of the same subjects before and after the application of an exposure. Again, we require that all variables treated as quantitative in Study 1 (Analyses A, B, or C) or as your quantitative outcome in Study 2 contain at least 15 unique values.\nFor Analysis B, you will need appropriate data to allow you to compare two means using independent samples. This would require a quantitative outcome (with at least 15 unique values), and a binary categorical variable which divides the data into two subgroups, so that each subgroup has a minimum of 30 observations.\nFor Analysis C, you will need appropriate data to allow you to compare 3-6 means using independent samples. This would require a quantitative outcome (with at least 15 unique values), and a multi-categorical variable with 3-6 categories which divides the data into subgroups, so that each subgroup has a minimum of 30 observations.\nFor Analysis D, you will need appropriate data to allow you to create and analyze a 2 \\(\\times\\) 2 table. This would require two independently collected binary categorical variables, that split the data into four groups in a 2 \\(\\times\\) 2 table, each with a minimum of 30 observations.\nFor Analysis E, you will need appropriate data to allow you to create and analyze a J \\(\\times\\) K table, where \\(2 \\leq J \\leq 5\\) and \\(3 \\leq K \\leq 5\\). This would require two independently collected categorical variables (one with J groups and one with K groups), that split the data into groups in a J \\(\\times\\) K table, so that each cell within the table has a minimum of 15 observations.\nAt a bare minimum, then, you will need a quantitative outcome (for Analyses A, B and C) and two binary variables (one for B and two for D and one for E) and a multi-categorical variable with 3-5 levels (for C and E) although you are welcome to use different variables from the same data source for each of the four Study 1 analyses you complete.\n\nNumber and type of variables for Study 2\n\nYou will need a quantitative outcome. Again, we require that your quantitative outcome contains at least 15 unique values.\nYou will need a key predictor of interest (which may be either quantitative, or categorical.) If it is categorical, it must have 2-6 categories, and each category must contain at least 30 observations. Your research question will focus largely on how effectively this key predictor can be used to predict your quantitative outcome.\nYou will need to identify 3-8 additional predictors of your outcome, at least one of which must be a multi-categorical predictor with 3-6 categories, where each category contains at least 30 observations. The other predictors can be any combination of quantitative and categorical (with 2-6 categories each, with at least 30 observations in each category.)\n\nYour data for each Study must be managed, merged (if necessary) and cleaned exclusively using R to go from raw data to that Study’s final clean tibble. This data management process must include the creation of appropriately labeled (and, if necessary, collapsed) factors for all categorical variables you will use in either study, and appropriate investigation and actions regarding missing values, numbers of unique values, and impossible values.\nYou will need to generate a single clean data set which you will then use for all four of your Study 1 analyses. For Study 1, work with a data set that has complete cases only on all of the analytic variables you study in your various Study 1 analyses. Describe those data overall using a codebook and an appropriate set of numerical summaries for your variables.\nYou will need to generate a single clean data set for all of your Study 2 analyses, which you will then partition (after single imputation of all variables besides your outcome and key predictor, to deal with missing values of all of your non-key predictors, if they exist) into a model training (or development) sample containing 60-80% of the data, and a model testing (or validation) sample containing the remaining 20-40% of the data. Describe the training data overall using a codebook and an appropriate set of numerical summaries, as you did in Study 1.\n\n\n\nTips on Cleaning Your Data\n\nIf you need to merge data (for instance in NHANES) clean the data after completing the merge.\nNote that it’s only necessary to clean the variables you will actually use in your analyses below. Create an analytic data set containing only those variables.\n\nThis should include a subject identification code (the SEQN in NHANES), your outcome, your key predictor and your other predictors.\nIf you are working with NHANES 2017-March 2020 data, you must include RIDSTATR and RIDAGEYR from the P_DEMO file.\n\nInclude RIDSTATR just so that you can prove that all of its values are 2 in your sample.\nInclude RIDAGEYR even if you’re not using it in your models, so you can describe the ages of the people in your sample.\n\n\nIf you create a categorical variable from a quantitative one, do so in this section of your report, and then refer to that work in the analyses below when you use the new variable. In general, though, I wouldn’t do that except in dire circumstances. Variables that use categories to describe what were originally quantitative variables aren’t quantitative any more.\nThings I would treat as missing include responses like Refused, Don’t Know, Did Not Respond, Unknown, No response and missing.\n\nIf you have a quantitative variable that includes a code like 5555 or 9999 for “don’t know” or “missing”, you will need to identify those cases as missing when ingesting the data, just as you would if you were working with a categorical variable.\nBe sure that R recognizes things that are missing as missing.\n\nCollapse levels sensibly for multi-categorical variables with more than 6 categories. If you want to use more than 6 categories for a categorical variable in your analyses, contact Dr. Love.\n\nIf you have a categorical variable with codes like 77, 88 or 99, in addition to treating those as missing, you want to drop those levels from the factors you create. I recommend you run droplevels() on your tibble to remove all factor levels with zero subjects. That can help down the line.\n\nFor NHANES folks, a few specific things:\n\nGender vs. Sex I would treat the RIAGENDR variable as describing biological sex and would rename it as I created a factor.\nRace/Ethnicity If you want to use race/ethnicity I would prefer the use of RIDRETH3 over RIDRETH1, and I would recommend using all six categories, assuming you have at least 100 subjects at each level after whatever other pruning you do. If you want to collapse, then lumping codes 1 and 2 into “Hispanic/Latinx” is acceptable. Remember that race/ethnicity as a covariate is an attempt to understand the impact of structural racism, at least as much as it is anything else, so interpretation requires special care.\nAge Do not use a categorical version of age. Use the quantitative version, called RIDAGEYR, provided in the P_DEMO data. When you describe your subjects, you should specify the range (minimum and maximum) ages of those subjects, so you will need to capture RIDAGEYR in your final analytic data set even if you’re not including it in your regression models.\nIncome and Measurement Caps The family income ratio INDFMPIR is appealing and quantitative, but it has a pronounced ceiling effect. It is the ratio of income to the poverty level, but is capped at 5. How should you think about that? (Note that age in adults is also capped, at 80.)\nCategorical Income? As a categorical alternative, the income data in INDHHIN2 in NHANES can be tricky to use, since there are so many categories and some of them overlap. Collapse INDHHIN2 to the following four categories, which are easy to describe, and have reasonable numbers of subjects in each category. Note that this approach drops the subjects with codes 12, 77 or 99, in addition to those with missing data.\n\nLowest: Below 20,000 (includes original codes 1, 2, 3, 4 and 13)\nLow: between 20,000 and 44,999 (includes original codes 5, 6, and 7)\nHigh: between 45,000 and 74,999 (includes original codes 8, 9 and 10)\nHighest: 75,000 and above (includes original codes 14 and 15)\n\nEducation Categories If you’re working with adults (ages 20 and over), the DMDEDUC2 variable in the P_DEMO file is the set of categories to use. I would probably collapse codes 1 and 2 together to create a four-category variable with “Less than HS”, “HS Grad”, “Some College”, “College Grad”.\n\nBe sure to treat all multi-categorical variables as factors in R, and don’t treat numeric codes as meaningful numeric variables.\nMake sure that all of your quantitative variables have sensible minimum and maximum values as you’re cleaning.\nSome binary variables are coded 1 and 2. Fix that in your work, ideally by using the real names and treating the variable as a factor, or by converting the 1-2 to a proper 1-0 indicator variable.\n\nUse the formula NEWVAR = 2 - OLDVAR to turn OLDVAR: 1 = Yes, 2 = No into NEWVAR: 1 = Yes, 0 = No.\nIf you have OLDVAR: 1 = No, 2 = Yes, create a NEWVAR with 1 = Yes, 0 = No using NEWVAR = OLDVAR - 1.\n\nIn Study 1, filter to complete cases. In Study 2, You should only filter to complete cases on the outcome and key predictor in Study 2. Then, perform single (simple) imputation using the mice package for any variables that are neither your outcome or your key predictor in Study 2 with missing values.\nYou are welcome to apply janitor::clean_names at the start or end of your cleaning, if you like. If you do decide to change the names as well (and that’s a good idea if a name is long or confusing, especially with NHANES), that’s great, but be sure to specify the original names as well in the codebook.\nPlease don’t include sanity checks in your report. We’ll trust you have to have done that work on your own.\n\n\n\nTo use data from NHANES (National Health and Nutrition Examination Survey).\n\nPlease read the Data Requirements for Study 1 and Study 2 and Tips on Cleaning Your Data above, then read the additional details on what is required if you’re working with NHANES data here.\nMany people (in past years) have felt that using NHANES data was a little easier than using another data source. To encourage people to use data other than NHANES, there is a four-point bonus in the final project B grade available for all projects which use non-NHANES data.\n\n\n\nTo use data from a non-NHANES source that meets with Dr. Love’s approval.\n\nPlease read the Data Requirements for Study 1 and Study 2 and Tips on Cleaning Your Data above, then read the additional details on what is required if you’re instead working with some other data source here.\nAgain, to encourage people to use data other than NHANES, there is a three-point bonus available to all projects which use non-NHANES data."
  },
  {
    "objectID": "checklist.html",
    "href": "checklist.html",
    "title": "431 Project B Checklist",
    "section": "",
    "text": "Main Tasks\n\nComplete the Project B Registration Form to obtain my approval for your plan, let me know if you’re working with a partner, and schedule your oral presentation.\n\nThe registration deadline in mid-November is specified in the Course Calendar.\n\nYou (and your partner, if you have one) will present your project on December 6-11 to Dr. Love in his office or over Zoom. Details on the Oral Presentation are provided below.\nYou will build two Quarto and HTML reports (separate reports for Study 1 and Study 2) due at the project B portfolio deadline.\n\nIf you’re not using NHANES data, you’ll also submit your data to me at that time.\nDetails on how to submit your reports are provided below.\n\nFinally, complete the Project B Self-Evaluation form, also due at the same time as the Portfolio Reports for Study 1 and Study 2, as specified on the Course Calendar.\n\n\n\nSubmitting Your Study 1 Report\nYour Study 1 Report is to be submitted to Canvas by the deadline in the Course Calendar.\n\nThis submission should include both your Quarto and HTML results.\nBe sure that the names of your Quarto and HTML files clearly identify whose project is being submitted, and an indication that these files refer to study 1.\nIf you are working with a partner, one of you should submit both the Study 1 and Study 2 reports to Canvas, and the other person should submit a one-page note to Canvas (word or PDF is best) containing your name, and stating something like “I worked on Project B with [your partner’s name] and they will submit Project B for our group.”\n\n\n\nSubmitting Your Study 2 Report\nYour Study 2 Report is to be submitted to Canvas by the deadline in the Course Calendar.\n\nThis submission should include both your Quarto and HTML results.\nIn addition, if you worked with any data other than NHANES, your submission also needs to include your data (in the form you used to ingest the data in your Quarto file, so that we can run your Quarto code and obtain your HTML results.)\nBe sure that the names of your Quarto and HTML files clearly identify whose project is being submitted, and an indication that these files refer to study 2.\nAgain, if you are working with a partner, one of you should submit both the Study 1 and Study 2 reports to Canvas, and the other person should submit a one-page note to Canvas (word or PDF is best) containing your name, and stating something like “I worked on Project B with [your partner’s name] and they will submit Project B for our group.”\n\n\n\nOral Presentation of Results\nYour meeting time is 20 minutes long, and please arrive 5 minutes early, either in person or via Zoom. If you have an emergency on the day of your presentation, email Dr. Love as soon as possible. Zoom information will be provided to you by December 1.\nYour meeting will involve materials from each of your studies, discussed in a fairly regimented way, described below. If you are working with a partner, Dr. Love will randomly determine at the meeting who will speak and when, so you need to each be prepared to give the entire presentation. Dr. Love will keep track of time, and move you along as necessary, so you won’t have to worry about that.\n\nYou will need to share a screen to show me the key results as you describe them for each of the analyses in Study 1 and in Study 2 that you wind up discussing. It is best if one of you is prepared to share their screen for both presentations, if you’re working with a partner, and I encourage you to practice this in advance.\nYou are welcome to show me results in the context of a Powerpoint-style presentation, if you prefer to develop one, or to show me results straight from your Quarto-created HTML files in your portfolio. Whatever works for you - so long as I can see what you are talking about as you are talking, we’ll be fine. Make sure you know how to increase the size of the text in your HTML file while presenting it.\nI will NOT be able to pull up your report or other materials while we are talking. You will have to be able to do that.\n\n\nStudy 1 presentation (6-8 minutes)\nIn Study 1, you will first select your most interesting / intriguing result out of your four main analyses and present that, in about 2 minutes. In those 2 minutes, you should be showing me the highlights of that Analysis, specifically:\n\nWhich Analysis (A, B, C, D, or E) are we describing?\nWhat research question are you investigating, and what variables did you use?\nWhat conclusion did you draw about that question?\nWhat statistical method led you to that conclusion?\n\nI will then ask you to tell me which of the other analyses (meaning A, B, C, D, or E) you did. I will then ask you to present the results of one of the other analyses you did, in a similar way. You will need to come prepared to present this information for any of your Study 1 analyses at a moment’s notice, as you will not know in advance which of your other analyses you did that I will ask for.\n\n\nStudy 2 presentation (10-12 minutes)\nIn Study 2, you will start with telling me about the most important finding of your little study in 5 minutes. In these 5 minutes, you will tell me:\n\nWhat your research question was and why it was interesting to you (combined this should take no more than 30 seconds)\nWhat your better model has to say about the answer to your research question\n\nThis should include a description of the predictors that wound up in your (final) model and the direction of each of their effects on your outcome. Show me the model as you’re telling me about this.\nThis should also include a sense of how well the model predicted overall (\\(R^2\\) is one good choice.)\nThis should also include whether the posterior predictive plots show systematic discrepancies between the fitted model’s predictions and your observed data. Show me the plot as you’re telling me about this.\nThis should also include a discussion of whether residual plots for your final model fit regression assumptions. Show me the plots as you’re telling me about this.\nYour conclusions about rational next steps to learn more from these data, or what specific new data you now wish you’d had when you started the study.\n\n\nFor most of the remaining time, I will ask you about your study, and try to help you think through any problems you had in obtaining or interpreting analyses. You should come prepared to share any of the steps in your analysis at a moment’s notice, as we may want to look at any part of your work.\n\n\nFinal Questions (2-4 minutes)\nDepending on remaining time, I may ask you any of several questions at the end of our meeting. Some possibilities you should be prepared for include the following (some of which also appear in the self-evaluation)\n\nWhat percentage of your time in Project B did you spend obtaining, cleaning, merging and tidying data, as opposed to actually performing analyses on tidy data?\nTell me something useful that you learned from doing Project B.\nTell me what the hardest part of doing Project B was.\nWhat did you learn from Project A that was helpful in doing Project B?\nWhat do you know now that you wish you’d known back when you started Project B back in November? What would you tell yourself if you could go back in time?\n\n\n\n\nA Special Note\nIf you’ve read down to here before 5 PM on December 1, thanks and here’s an opportunity for a little bonus credit. Send Dr. Love an email no later than 5 PM on December 1 with the subject line 431 Favorite Song, telling him your favorite song (and providing a link to a video of the song on YouTube), and you’ll get some bonus credit.\n\n\nSelf-Evaluation for Project B\nThe Self-Evaluation for Project B Form will be available in December and should take about 15 minutes to complete. If you are working in a team, each of you need to complete the form as an individual.\nThe Form is also due when the Project B Portfolio is due, and you’ll complete it after meeting with Dr. Love for your presentation. Find the link to the Self-Evaluation Form here."
  },
  {
    "objectID": "data2.html",
    "href": "data2.html",
    "title": "Using NHANES Data",
    "section": "",
    "text": "If you select the NHANES option, you will be using data from the National Health and Nutrition Examination Survey.\nIf you decide to use some other data set instead for Project B, then you should visit this page.\nIn either case, be sure to read through and verify that your data meet all requirements described on our Data Development page."
  },
  {
    "objectID": "data2.html#about-nhanes-from-the-nhanes-website",
    "href": "data2.html#about-nhanes-from-the-nhanes-website",
    "title": "Using NHANES Data",
    "section": "About NHANES (from the NHANES website)",
    "text": "About NHANES (from the NHANES website)\n\nThe National Health and Nutrition Examination Survey (NHANES) is a program of studies designed to assess the health and nutritional status of adults and children in the United States. The survey is unique in that it combines interviews and physical examinations. NHANES is a major program of the National Center for Health Statistics (NCHS). NCHS is part of the Centers for Disease Control and Prevention (CDC) and has the responsibility for producing vital and health statistics for the Nation.\n\n\nThe NHANES program began in the early 1960s and has been conducted as a series of surveys focusing on different population groups or health topics. In 1999, the survey became a continuous program that has a changing focus on a variety of health and nutrition measurements to meet emerging needs. The survey examines a nationally representative sample of about 5,000 persons each year. These persons are located in counties across the country, 15 of which are visited each year.\n\n\nThe NHANES interview includes demographic, socioeconomic, dietary, and health-related questions. The examination component consists of medical, dental, and physiological measurements, as well as laboratory tests administered by highly trained medical personnel.\n\n\nFindings from this survey will be used to determine the prevalence of major diseases and risk factors for diseases. Information will be used to assess nutritional status and its association with health promotion and disease prevention. NHANES findings are also the basis for national standards for such measurements as height, weight, and blood pressure. Data from this survey will be used in epidemiological studies and health sciences research, which help develop sound public health policy, direct and design health programs and services, and expand the health knowledge for the Nation."
  },
  {
    "objectID": "data2.html#general-advice-for-nhanes-learning-about-the-available-data",
    "href": "data2.html#general-advice-for-nhanes-learning-about-the-available-data",
    "title": "Using NHANES Data",
    "section": "General Advice for NHANES: Learning About The Available Data",
    "text": "General Advice for NHANES: Learning About The Available Data\nThe links in this section go to the Survey Data and Documentation section of the NHANES website.\n\nWe strongly encourage the use of the NHANES 2017 - March 2020 Pre-pandemic data for Project B.\n\nThis is the most recent public data that is fairly complete.\n\nYou are required to use variables taken from at least three different NHANES data sets. This must include the Demographics data set, in addition to two other data sets taken from at least one of three other available data groups (Examination, Laboratory and Questionnaire.)\n\nThe Demographics data group should be part of all projects, and it contains a single data set.\nThe Examination data group includes 11 data sets.\nThe Laboratory data group contains 36 data sets.\nThe Questionnaire data group also contains 37 data sets.\nWe do not want you to use data from the Dietary group in Project B.\n\nYou will use the nhanesA package in R to import and work with the available data. This package is part of our list of recommended packages for installations.\nNote that none of your work will be using the sampling weights which are a key part of NHANES. Thus, none of your results from Project B will be truly representative of the national population. That’s OK for this exercise."
  },
  {
    "objectID": "data2.html#getting-the-nhanes-data",
    "href": "data2.html#getting-the-nhanes-data",
    "title": "Using NHANES Data",
    "section": "Getting the NHANES data",
    "text": "Getting the NHANES data\nVisit the NHANES website and identify the data you want to view.\n\nFor example, the Demographic Variables and Sample Weights for NHANES 2017-March 2020 are described here.\nEach NHANES data set is associated with a Doc File (which stands for Data Documentation, Codebook and Frequencies). For instance, here’s the one for Demographics in 2017-March 2020. This file can be viewed online (it’s an HTML file) and it will tell you what variables are included in that data set.\nEach NHANES data set is available as a SAS transport file. For example, it’s the P_DEMO file for Demographics in 2017-March 2020, as you can see here."
  },
  {
    "objectID": "data2.html#using-the-nhanesa-package",
    "href": "data2.html#using-the-nhanesa-package",
    "title": "Using NHANES Data",
    "section": "Using the nhanesA package",
    "text": "Using the nhanesA package\nOnce you’ve selected the data sets from NHANES that you want to use in your project (remember that you need at least 3), the nhanesA package in R can be used to obtain them.\nHere’s a little vignette introducing nhanesA from Christopher Endres, who built the package. The key functions in the nhanesA package that I think you might use are those described in that vignette, but the main one is simply called nhanes.\n\nAn Example\nFor example, suppose we want to load the Blood Pressure data from the 2017-18 Examination files at NHANES (contained in the BPX_J data file) into a tibble called bp_data in R.\n\nNote that you will instead use 2017-March 2020 data, which for Blood Pressure would be (according to this page) the P_BPXO file, rather than BPX_J.\n\nWe would use the following code, which will take a few minutes to run.\n\nlibrary(nhanesA)\nlibrary(tidyverse)\n\nbp_raw &lt;- nhanes('BPX_J') |&gt; tibble()\n\nsaveRDS(bp_raw, \"data/BPX_J.Rds\")\n\nOnce you’ve downloaded the file once, you should save it as an R data frame, and then comment out the initial code you used to pull down the data in R. Then, when you rerun, it’ll be all set. Remember to create a data sub-folder in your R Project B directory before you run this code.\nSo your final presentation in Project B should instead look like this, which will run much more quickly.\n\nlibrary(nhanesA)\nlibrary(tidyverse)\n\n# pull in data from BPX_J from NHANES and save it\n\n# bp_raw &lt;- nhanes('BPX_J') |&gt; tibble()\n\n# saveRDS(bp_raw, \"data/BPX_J.Rds\")\n\n# Now that data are saved, I can just read in the tibble\n\nbp_raw &lt;- readRDS(\"data/BPX_J.Rds\")"
  },
  {
    "objectID": "data2.html#merging-nhanes-files",
    "href": "data2.html#merging-nhanes-files",
    "title": "Using NHANES Data",
    "section": "Merging NHANES files",
    "text": "Merging NHANES files\nYou will need to include data from multiple tibbles (data sets) pulled down in your project. I suggest you first select only those variables you intend to use in your analytic data file from each individual tibble you have created. This should always include the SEQN variable in every tibble, since that is what you will use to match up responses across those tibbles.\n\nYour final analyses should be based on somewhere between 500 and 7,500 complete cases from the NHANES 2017-March 2020 data.\n\nTo merge a demographics tibble called DEMO with a BPX tibble to create a tibble called NEW that contains the variables from both DEMO and BPX for all of the subjects contained in DEMO, I’d use a left_join, as follows.\n\nNEW &lt;- left_join(DEMO, BPX, by = \"SEQN\")\n\nI’d then use another left_join to merge this NEW result with another tibble (say, the HDL_J tibble) and so on.\n\nNEW2 &lt;- left_join(NEW, HDL_J, by = \"SEQN\")\n\nThen, when I was done merging and cleaning the data I would be sure to save that result as a new Rds file, just in case I needed it again."
  },
  {
    "objectID": "data2.html#which-variables-subjects-should-i-use",
    "href": "data2.html#which-variables-subjects-should-i-use",
    "title": "Using NHANES Data",
    "section": "Which variables / subjects should I use?",
    "text": "Which variables / subjects should I use?\nThat’s up to you. Find variables of interest in the description files, and pull them out and see if they will work for you.\n\nFocus on subjects who have a RIDSTATR value of 2 (meaning they were both interviewed and examined) - this variable is part of the Demographics file.\n\nFor 2017-March 2020, there are 14,300 such subjects.\n\nI encourage you to not use subjects listed with ages of 80 (RIDAGEYR = 80) since that’s a catch-all for all subjects ages 80 and older.\n\nFor 2017-March 2020, of the 14,300 listed above, 13,724 are less than 80.\n\nYou should either use children or adults in your final analyses, and not both together.\n\nThere are 7,853 adults between the ages of 21 and 79 of the 13,724.\nSome variables are only collected on children, others only on adults.\n\nDo not filter to complete cases in creating your data. Maintain the missing values.\n\nIn many cases, you should have well over 5,000 observations in total, but depending on what you select, you may have a much smaller subset, and you should be able to explain to us why that is the case, if it is.\nFor example, if you’re studying something that is only measured in females, or in children, you’ll have a smaller sample for that reason, and you need to make that clear to us in your report. At a minimum, you will need at least 500 complete cases even if you’re using heavily filtered NHANES data."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "431 Project B Instructions",
    "section": "",
    "text": "What is Project B?\nProject B is the second of two real data science projects you’ll be doing this semester. It involves the completion of four tasks, which you’ll start working on at the start of November.\n\nYou will complete a Registration Form to obtain my approval for what you propose, let me know if you’re working with a partner, and schedule your oral presentation.\nYou will build Quarto and HTML reports describing your work.\nYou (and your partner, if applicable) will present your project sometime between 12-06 and 12-11 to Dr. Love in his office in person or via Zoom. These will be scheduled immediately after the Project B Registration Forms have been submitted.\nFinally, you will complete a Self-Evaluation form.\n\n\n\nWhat’s on this Website\n\nThe Data: Instructions on getting data for Project B\n\nYou’ll either use data from NHANES, or from some other source.\n\nRegistration information proposing your Project B.\n\nThis involves completing a Google Form by the deadline in mid-November specified on the Course Calendar. In this form, you will:\n\nspecify whether or not you are working with a partner\ntell us a little about the data source (NHANES or other) you intend to use\nprovide options for when you can give your oral presentation, and whether you prefer to do so in person or via Zoom\n\n\nInstructions for Study 1\n\nYou’ll find information on required Study 1 analyses\nWe also provide detailed Study 1 report specifications\nYou’ll also find a Study 1 sample report\n\nInstructions for Study 2\n\nYou’ll find information on required Study 2 analyses\nWe also provide detailed Study 2 report specifications\nYou’ll also find a Study 2 sample report\n\nSelf-Evaluation Form for Project B\n\nIf you work with a partner, each of you submits this form separately.\n\nA Checklist of the tasks that need to be accomplished for Project B, which also includes some details on the oral presentation you’ll give to Dr. Love in December.\nA Tip Sheet of about 20 things that have come up in the past that are worth your attention as you prepare your final materials for presentation and submission.\nThe top menu also provides links to contact us, and to the 431 home page.\n\nAll of the material you need (from a statistical and coding perspective) to do Project B has been or will be covered in our first 24 classes (i.e. immediately before the Thanksgiving Break), as well as in the Course Book Chapters 1-22 and Labs 1-6.\n\n\nProject B Deliverables\n\nYou will complete a Registration Form to obtain my approval for your proposed work, let me know if you’re working with a partner, and schedule your oral presentation, by the (mid-November) deadline on the Course Calendar.\nYou (and your partner, if applicable) will present your project to Dr. Love in his office. Details on the Oral Presentation are found in the Checklist menu above. Presentations will be scheduled on December 6-11 using the Registration Form.\nYou will build two Quarto and HTML reports (separate reports for Study 1 and Study 2) by the Project B Portfolio deadline in the Course Calendar.\n\nIf you’re not using NHANES data, you’ll also submit your data to Dr. Love at that time.\n\nFinally, you will complete a Self-Evaluation form, by the Project B Portfolio deadline in the Course Calendar.\n\n\n\nPartnerships?\nYou can work alone, or with one other person on this project. If you work as a pair, you will commit to that when you register for the project. Each of you will receive the team grade for the project reports, and an individual grade for the other components of the project.\n\n\nThe Data\nYou will work with the same data source for Study 1 and for Study 2, and these data will be developed either from NHANES or from another public source that you identify.\n\nYou will find detailed instructions regarding the use of NHANES data for Project B here.\nIf you want to use other data, you’ll need it to meet some specifications we’ll describe, and you’ll have to get Dr. Love’s permission when you register your project.\nSince most people consider working with NHANES data to be easier, we will award four extra points to projects which use non-NHANES data.\n\n\n\nStudy 1\n\nStudy 1 is about making descriptive and exploratory comparisons and summaries of data. It’s not about building sophisticated statistical models.\nYou will ingest, merge and clean the data in R, then select variables to complete any four out of five potential analyses, as described in these instructions.\n\nYou can do all five analyses if you like (as preparation for Quiz 2, for instance) but you will only present four in your report. No bonus credit for doing all five analyses.\n\nDr Love has developed Study 1 Report Specifications and a Study 1 Sample Report which should guide your eventual submitted Study 1 report.\n\n\n\nStudy 2\n\nStudy 2 is about building a model and making predictions. You will complete all elements of a data science project designed to create a statistical model for a quantitative outcome, then use it for prediction, and assess the quality of those predictions.\nStudy 2 involves working with data from the same source that you used for Study 1. Again, you will work through all cleaning and data management requirements in your Study 2 report.\n\nStudy 2 involves the prediction of a quantitative outcome using a key predictor and some additional predictors in two linear regression models, and then comparing those two models.\nAll of the material you need (from a statistical and coding perspective) to do these analyses has been or will be covered in our first 24 classes and in the Course Notes.\n\nDr Love has developed Study 2 Report Specifications and a Study 2 Sample Report which should guide your eventual submitted Study 2 report.\n\n\n\nGrading\nProject B will be graded by Dr. Love on a scale from 0-150 points.\n\nOn-time successful completion of the Registration Form is worth 15 points.\nThe two study reports (Study 1 and Study 2) due at the final Project B deadline are worth a combined 60 points.\nThe oral presentation is also worth 60 points. Details on the Oral Presentation are found in the Checklist.\nThe self-evaluation is worth 15 points.\nLate work on Project B is unacceptable. All deadlines are in the Course Calendar.\n\nDr. Love will provide no written feedback on your Project B work. The grading timeline is simply too tight on my end. I apologize in advance.\n\n\nQuestions?\nIf you have questions, let us know about them on Campuswire using the projectB folder, or speak with Dr. Love before or after class, or discuss them with the TAs during office hours."
  },
  {
    "objectID": "sample-study1.html",
    "href": "sample-study1.html",
    "title": "431 Project B Sample Study 1 Report",
    "section": "",
    "text": "Reminders from Dr. Love\n\n\n\n\nRemember that each subsection should include at least one complete sentence explaining what you are doing, specifying the variables you are using and how you are using them, and then conclude with at least one complete sentence of discussion of the key conclusions you draw from the current step, and a discussion of any limitations you can describe that apply to the results.\nIf you want to download the Quarto code I used to create this document, click on the Code button near the title of this Sample Study.\nDO NOT use my words (other than the section and subsection headings) included in this sample report in your project. Rewrite everything to make it relevant to your situation. Do not repeat my instructions back to me."
  },
  {
    "objectID": "sample-study1.html#initial-setup-and-package-loads",
    "href": "sample-study1.html#initial-setup-and-package-loads",
    "title": "431 Project B Sample Study 1 Report",
    "section": "1.1 Initial Setup and Package Loads",
    "text": "1.1 Initial Setup and Package Loads\n\nlibrary(broom)\nlibrary(Epi)\nlibrary(Hmisc)\nlibrary(knitr)\nlibrary(janitor)\nlibrary(mosaic)\nlibrary(naniar)\nlibrary(patchwork)\nlibrary(readxl)\nlibrary(xfun)\nlibrary(easystats)\nlibrary(tidyverse) \n\n## Load Love-431 script \nsource(\"data/Love-431.R\")\n\n## Global options\nopts_chunk$set(comment=NA)\n\ntheme_set(theme_bw())"
  },
  {
    "objectID": "sample-study1.html#loading-the-raw-data-into-r",
    "href": "sample-study1.html#loading-the-raw-data-into-r",
    "title": "431 Project B Sample Study 1 Report",
    "section": "1.2 Loading the Raw Data into R",
    "text": "1.2 Loading the Raw Data into R\nThis document demonstrates a variety of things required in your Project B Study 1. We will demonstrate ideas using data from a 2015 class survey, gathered in three data files available on the 431-data website. The files are called:\n\nprojectB-study1-demo-survey-2015a.xlsx\nprojectB-study1-demo-survey-2015b.csv\nprojectB-study1-demo-survey-2015c.csv\n\nAfter merging, the complete data set should include data on 21 variables for 53 subjects.\n\nI’m going to use clean_names() from the janitor package before I do the merging. It would also be OK to do this after the merge is complete.\nI’m also going to tell R to interpret both a blank “” and an “NA” in a cell of the Excel sheet as indicating a missing value, since that’s what I need, and since that’s what read_csv already does, by default.\n\n\nsur15_raw_a &lt;- read_excel(\"data/projectB-study1-demo-survey-2015a.xlsx\", \n                      na = c(\"\", \"NA\")) |&gt;\n  janitor::clean_names()\n\nsur15_raw_b &lt;- read_csv(\"data/projectB-study1-demo-survey-2015b.csv\") |&gt;\n  janitor::clean_names()\n\nsur15_raw_c &lt;- read_csv(\"data/projectB-study1-demo-survey-2015c.csv\") |&gt;\n  janitor::clean_names()"
  },
  {
    "objectID": "sample-study1.html#contents-of-the-raw-tibbles",
    "href": "sample-study1.html#contents-of-the-raw-tibbles",
    "title": "431 Project B Sample Study 1 Report",
    "section": "1.3 Contents of the Raw Tibbles",
    "text": "1.3 Contents of the Raw Tibbles\nWe have three tibbles now, which (once we have merged them together) will contain complete data on all 53 subjects for all 21 variables.\n\nsur15_raw_a contains data on all 21 variables for the first 20 subjects.\n\n\ndim(sur15_raw_a)\n\n[1] 20 21\n\n\n\nsur15_raw_b contains data on 9 of the variables (including the subject ID code: s.id) for the other 33 subjects.\n\n\ndim(sur15_raw_b)\n\n[1] 33  9\n\n\n\nsur15_raw_c contains data on 13 of the variables (also including the subject ID code: s.id) for the same 33 subjects that are in sur15_raw_b.\n\n\ndim(sur15_raw_c)\n\n[1] 33 13"
  },
  {
    "objectID": "sample-study1.html#two-merging-steps",
    "href": "sample-study1.html#two-merging-steps",
    "title": "431 Project B Sample Study 1 Report",
    "section": "1.4 Two Merging Steps",
    "text": "1.4 Two Merging Steps\n\nJoin the columns in sur15_raw_b and in sur15_raw_c to obtain a new tibble, which I’ll call sur15_last33, holding information on all 21 variables for the last 33 subjects.\n\n\nsur15_last33 &lt;- inner_join(sur15_raw_b, sur15_raw_c, by = \"s_id\")\n\ndim(sur15_last33)\n\n[1] 33 21\n\n\n\nCombine the rows together from sur15_raw_a (which has the first 20 subjects) and sur15_last33 (which has the other 33 subjects) to create a tibble called sur15_merged which has all 21 variables for all 53 subjects.\n\n\nsur15_merge &lt;- bind_rows(sur15_raw_a, sur15_last33)\n\ndim(sur15_merge)\n\n[1] 53 21\n\n\nOK. We have 53 subjects and 21 variables, as expected."
  },
  {
    "objectID": "sample-study1.html#checking-the-merge",
    "href": "sample-study1.html#checking-the-merge",
    "title": "431 Project B Sample Study 1 Report",
    "section": "1.5 Checking the Merge",
    "text": "1.5 Checking the Merge\nWe need to perform two checks here.\n\nFirst, we should check to ensure that the number of distinct (unique) subject identification codes (shown below) matches the number of rows. Those two values should be identical. Are they?\n\n\nidentical(n_distinct(sur15_merge$s_id), \n          sur15_merge |&gt; nrow())\n\n[1] TRUE\n\n\nExcellent.\n\nSecond, we should also check that we haven’t added any new variables. The sur15_raw_a tibble included all of the variable names we should have in the final result. Do the names in sur15_raw_a match the names in our merged tibble exactly?\n\n\nidentical(names(sur15_merge), \n          names(sur15_raw_a))\n\n[1] TRUE\n\n\nAll right. Our merge was successful."
  },
  {
    "objectID": "sample-study1.html#selecting-only-the-variables-well-use",
    "href": "sample-study1.html#selecting-only-the-variables-well-use",
    "title": "431 Project B Sample Study 1 Report",
    "section": "1.6 Selecting only the variables we’ll use",
    "text": "1.6 Selecting only the variables we’ll use\nThe sur15_merge data includes some variables we don’t need, so we’ll prune down to the 11 variables we’ll actually use in the analyses we’ll do. This should certainly include the subject identification code, so we’ll include that, and also switch it to a character representation instead of numeric.\n\nsur15_m &lt;- sur15_merge |&gt;\n  mutate(s_id = as.character(s_id)) |&gt;\n  select(s_id, r_pre, r_now, height, weight, \n         comfort_431, grades, r_before, english, \n         medium, fiction)"
  },
  {
    "objectID": "sample-study1.html#our-survey-items",
    "href": "sample-study1.html#our-survey-items",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.1 Our Survey Items",
    "text": "2.1 Our Survey Items\nThe 10 survey items that we will actually use in this demonstration are listed below.\n\n2.1.1 Rating Variables\nFor each of these, subjects gave a response between 0 and 100 indicating their agreement with the statement as presented. The scale was 0 = Strongly disagree, 100 = Strongly agree.\n\nr_pre: Prior to taking 431, I was totally confident and comfortable with using R. (0 = Strongly Disagree, 100 = Strongly Agree)\nr_now: Right now, I am totally confident and comfortable with using R. (0 = Strongly Disagree, 100 = Strongly Agree)\ncomfort_431: I am very comfortable with my understanding of the material discussed so far in 431.\n\n\n\n2.1.2 Other Quantitative Variables\n\nheight: What is your height, in inches?\nweight: What is your weight, in pounds?\n\n\n\n2.1.3 Binary Variables\n\nr_before: Before taking 431, had you ever used R before? (Yes, No)\nenglish: Is English the language you speak better than any other? (Yes, No)\n\n\n\n2.1.4 Multi-Categorical Variables\n\ngrades: In your graduate and undergraduate educational experience, which of the following types of assignments have you received the HIGHEST grades for?\n\nAvailable responses were “A. Individual Assignments”, “B. Partner Assignments (you and 1 other student)”, and “C. Group Assignments (you and 2 or more others)”.\n\nmedium: Which medium do you use most to get your fictional stories (containing plot)?\n\nAvailable Responses: “A. Movies”, “B. Television”, “C. Print (including books, comics, etc.)”, and “D. Other”.\n\nfiction: Which type of fictional stories do you consume most?\n\nAvailable Responses: “A. Comedy”, “B. Drama”, “C. Action”, “D. Horror / Thriller”, and “E. Fantasy / Science Fiction”.\n\n\nOur analytic tibble will be called sur15 for this demonstration.\n\nThis tibble will need to contain information developed from the variables listed above, plus the subject identifying code s_id.\nAs we add variables to the analytic tibble, we’ll also check to see that all of the values fall in a reasonable range (with no results that fall outside of the parameters of how we are measuring the results) and we’ll identify whether there are any missing values.\n\nNote that we’ve already checked our subject identification codes to ensure that we have no missing values there and that we have a unique identifier for each row in the data back when we did the merge."
  },
  {
    "objectID": "sample-study1.html#checking-our-quantitative-variables",
    "href": "sample-study1.html#checking-our-quantitative-variables",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.2 Checking our Quantitative Variables",
    "text": "2.2 Checking our Quantitative Variables\nWe have five quantitative variables. We want to check the range (minimum and maximum) plus for each, to ensure that we have no impossible or missing values.\n\nsur15_m |&gt;\n  select(r_pre, r_now, comfort_431, height, weight) |&gt;\n  data_codebook()\n\nselect(sur15_m, r_pre, r_now, comfort_431, height, weight) (53 rows and 5 variables, 5 shown)\n\nID | Name        | Type    | Missings |       Values |  N\n---+-------------+---------+----------+--------------+---\n1  | r_pre       | numeric | 0 (0.0%) |      [0, 90] | 53\n---+-------------+---------+----------+--------------+---\n2  | r_now       | numeric | 0 (0.0%) |      [0, 95] | 53\n---+-------------+---------+----------+--------------+---\n3  | comfort_431 | numeric | 0 (0.0%) |    [15, 100] | 53\n---+-------------+---------+----------+--------------+---\n4  | height      | numeric | 0 (0.0%) | [22.83, 217] | 53\n---+-------------+---------+----------+--------------+---\n5  | weight      | numeric | 0 (0.0%) |     [1, 320] | 53\n---------------------------------------------------------\n\n\n\nFor the three rating variables, all values are in the range [0, 100], as they must be.\nHowever, the height range doesn’t seem reasonable. With height measured in inches, do we really think there should be a height as small as 22.83 inches?\nThe weight minimum is also a problem. Is 1 pound a reasonable value?\nWe also want to create a body mass index from the height and weight data\n\n\n2.2.1 Combining height and weight into bmi and Specifying NA for Implausible Values\nWe will calculate bmi (body-mass index) from the available height (inches) and weight (pounds) data. The BMI formula for inches and pounds is available at http://www.bmi-calculator.net/bmi-formula.php. A reasonable range for BMI values is probably about 15 to 50.\n\nsur15_m &lt;- sur15_m |&gt;\n    mutate(bmi = 703 * weight / height^2)\n\nsur15_m |&gt; reframe(lovedist(bmi))\n\n# A tibble: 1 × 10\n      n  miss  mean    sd   med   mad   min   q25   q75   max\n  &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    53     0  26.2  23.5  23.2  3.25 0.159  21.2  25.5  189.\n\n\nThe minimum calculated bmi value seems impossibly low, and the highest bmi seems impossibly high. Let’s look at the heights and weights involved.\n\nsur15_m |&gt; select(s_id, height, weight) |&gt; arrange(height) |&gt; head()\n\n# A tibble: 6 × 3\n  s_id  height weight\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 504     22.8    140\n2 530     61      140\n3 513     61.4    112\n4 519     62      126\n5 528     62      155\n6 540     62      140\n\n\n\nsur15_m |&gt; select(s_id, height, weight) |&gt; arrange(height) |&gt; tail()\n\n# A tibble: 6 × 3\n  s_id  height weight\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 532       72    160\n2 549       72    220\n3 506       73    145\n4 507       74    320\n5 535       74    172\n6 529      217    165\n\n\n\nsur15_m |&gt; select(s_id, height, weight) |&gt; arrange(weight) |&gt; head()\n\n# A tibble: 6 × 3\n  s_id  height weight\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 550     66.5      1\n2 521     63      107\n3 512     65      112\n4 513     61.4    112\n5 552     65      120\n6 526     64      121\n\n\n\nsur15_m |&gt; select(s_id, height, weight) |&gt; arrange(weight) |&gt; tail()\n\n# A tibble: 6 × 3\n  s_id  height weight\n  &lt;chr&gt;  &lt;dbl&gt;  &lt;dbl&gt;\n1 505       70    178\n2 516       71    200\n3 511       65    202\n4 546       69    210\n5 549       72    220\n6 507       74    320\n\n\nThe subjects with heights of 22.83 inches and 217 inches are implausible, and the subject with weight 1 pound is also not reasonable. We want to focus on actually plausible results.\n\nA reasonable guess is that no one in the class was less than about 122 centimeters, or 4 feet tall (48 inches) nor were they greater than about 213 centimeters, or 7 feet tall (84 inches) so we’re going to change any values outside that range to NA.\nSimilarly, it seems reasonable to assume that no one in the class was below 80 pounds (36.3 kg) or above 400 pounds (181.4 kg) so again, we’ll regard any values we see outside that range is implausible and change them to NA.\n\nI’ll do this by creating new variables height_r and weight_r where the _r (meaning “revised”) indicates to me that I’ve revised the original variable in some way without adding a lot of characters to its name.\n\nsur15_m &lt;- sur15_m |&gt;\n    mutate(height_r = replace(height, height &lt; 48 | height &gt; 84, NA),\n           weight_r = replace(weight, weight &lt; 80 | weight &gt; 400, NA)) |&gt;\n    mutate(bmi = 703 * weight_r / height_r ^2)\n\nsur15_m |&gt; select(height_r, weight_r, bmi) |&gt;\n  data_codebook()\n\nselect(sur15_m, height_r, weight_r, bmi) (53 rows and 3 variables, 3 shown)\n\nID | Name     | Type    | Missings |         Values |  N\n---+----------+---------+----------+----------------+---\n1  | height_r | numeric | 2 (3.8%) |       [61, 74] | 51\n---+----------+---------+----------+----------------+---\n2  | weight_r | numeric | 1 (1.9%) |     [107, 320] | 52\n---+----------+---------+----------+----------------+---\n3  | bmi      | numeric | 3 (5.7%) | [18.64, 41.08] | 50\n--------------------------------------------------------\n\n\nSo now, we have 2 missing values of height_r, 1 missing value of weight_r and we have calculated BMI results, with 3 missing values, and our ranges (minimum and maximum) for each of these variables now look OK."
  },
  {
    "objectID": "sample-study1.html#checking-our-binary-variables",
    "href": "sample-study1.html#checking-our-binary-variables",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.3 Checking our Binary Variables",
    "text": "2.3 Checking our Binary Variables\nWe have two binary variables.\n\nsur15_m |&gt; select(english, r_before) |&gt; glimpse()\n\nRows: 53\nColumns: 2\n$ english  &lt;chr&gt; \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"…\n$ r_before &lt;chr&gt; \"Yes\", \"No\", \"No\", \"Yes\", \"Yes\", \"No\", \"Yes\", \"Yes\", \"No\", \"N…\n\n\nI’d like those to be factors in R, rather than characters.\n\nsur15_m &lt;- sur15_m |&gt;\n    mutate(r_before = factor(r_before),\n           english = factor(english))\n\nsur15_m |&gt; count(r_before, english)\n\n# A tibble: 4 × 3\n  r_before english     n\n  &lt;fct&gt;    &lt;fct&gt;   &lt;int&gt;\n1 No       No         10\n2 No       Yes        18\n3 Yes      No          8\n4 Yes      Yes        17\n\n\nOK. No missingness, and no values out of the range of our expectations. Good."
  },
  {
    "objectID": "sample-study1.html#checking-our-multi-category-variables",
    "href": "sample-study1.html#checking-our-multi-category-variables",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.4 Checking our Multi-Category Variables",
    "text": "2.4 Checking our Multi-Category Variables\nFor each of our multi-categorical variables, I’ll run a quick tabyl to see if we have any surprising results or missing values. Then I’ll revise each of them (as needed) to have more suitable (mostly, shorter) level names. In addition to checking for missingness and inappropriate values, we want to collapse some categories, or adjust names or labeling to mirror what we need in our analyses.\n\n2.4.1 The grades variable\n\nsur15_m |&gt;\n  tabyl(grades)\n\n                                           grades  n    percent valid_percent\n                        A. Individual Assignments 40 0.75471698     0.7692308\n B. Partner Assignments (you and 1 other student)  6 0.11320755     0.1153846\n  C. Group Assignments (you and 2 or more others)  6 0.11320755     0.1153846\n                                             &lt;NA&gt;  1 0.01886792            NA\n\n\nFor grades, we want to create a new factor called grades_r which is a factor and which has shorter level names, specifically: Individual, Partner and Group, in that order. We’ll use the fct_recode function from forcats:\n\nsur15_m &lt;- sur15_m |&gt; \n    mutate(grades_r = fct_recode(factor(grades), \n        \"Individual\" = \"A. Individual Assignments\",\n        \"Partner\" = \"B. Partner Assignments (you and 1 other student)\",\n        \"Group\" = \"C. Group Assignments (you and 2 or more others)\"))\n\n# sanity check to ensure we coded correctly\nsur15_m |&gt; count(grades, grades_r)\n\n# A tibble: 4 × 3\n  grades                                           grades_r       n\n  &lt;chr&gt;                                            &lt;fct&gt;      &lt;int&gt;\n1 A. Individual Assignments                        Individual    40\n2 B. Partner Assignments (you and 1 other student) Partner        6\n3 C. Group Assignments (you and 2 or more others)  Group          6\n4 &lt;NA&gt;                                             &lt;NA&gt;           1\n\n\n\nThat looks like we’ve correctly renamed the values.\nFor this demonstration, we’ll allow counts as low as 5 for individual levels of a categorical variable, because of the small sample size, so I won’t collapse the levels at all.\nWe have a missing value here, so we’ll need to deal with that later.\n\n\n\n2.4.2 The medium variable\n\nsur15_m |&gt;\n  tabyl(medium)\n\n                                   medium  n    percent\n                                A. Movies 17 0.32075472\n                            B. Television 22 0.41509434\n C. Print (including books, comics, etc.)  9 0.16981132\n                                 D. Other  5 0.09433962\n\n\n\nWe have no missing values, so that’s good.\nIn this demonstration, we will require that each category have at least 5 responses, so while this just barely meets that standard, I think I will go ahead and collapse the variable down to just three categories.\n\nFor the medium variable, we want to collapse the Print and Other levels to form a three category variable (with levels Movies, TV and Other) called medium_r.\n\nsur15_m &lt;- sur15_m |&gt;\n    mutate(medium_r = fct_recode(factor(medium), \n                                 \"Movies\" = \"A. Movies\",\n                                 \"TV\" = \"B. Television\",\n                                 \"Other\" = \"C. Print (including books, comics, etc.)\",\n                                 \"Other\" = \"D. Other\"))\n\nsur15_m |&gt; count(medium, medium_r) # sanity check\n\n# A tibble: 4 × 3\n  medium                                   medium_r     n\n  &lt;chr&gt;                                    &lt;fct&gt;    &lt;int&gt;\n1 A. Movies                                Movies      17\n2 B. Television                            TV          22\n3 C. Print (including books, comics, etc.) Other        9\n4 D. Other                                 Other        5\n\n\nOK. Looks good now.\n\n\n2.4.3 The fiction variable\n\nsur15_m |&gt;\n  tabyl(fiction)\n\n                      fiction  n    percent\n                    A. Comedy 18 0.33962264\n                     B. Drama 15 0.28301887\n                    C. Action  5 0.09433962\n         D. Horror / Thriller  1 0.01886792\n E. Fantasy / Science Fiction 14 0.26415094\n\n\n\nNo signs of missing values, so that’s good.\nWith only one value in category D and only 5 in category C, we will need to do some collapsing to use this variable later.\n\n\n\n2.4.4 Collapsing and recoding levels of fiction\nFor the fiction variable, we want to form a four category variable (with levels Comedy, Drama, Fantasy/SF, Other) called fiction_r.\n\nsur15_m &lt;- sur15_m |&gt;\n    mutate(fiction_r = fct_recode(factor(fiction), \n                                 \"Comedy\" = \"A. Comedy\",\n                               \"Drama\" = \"B. Drama\",\n                               \"Fantasy/SF\" = \"E. Fantasy / Science Fiction\",\n                               \"Other\" = \"C. Action\",\n                               \"Other\" = \"D. Horror / Thriller\"))\n\nsur15_m |&gt; count(fiction, fiction_r) # sanity check\n\n# A tibble: 5 × 3\n  fiction                      fiction_r      n\n  &lt;chr&gt;                        &lt;fct&gt;      &lt;int&gt;\n1 A. Comedy                    Comedy        18\n2 B. Drama                     Drama         15\n3 C. Action                    Other          5\n4 D. Horror / Thriller         Other          1\n5 E. Fantasy / Science Fiction Fantasy/SF    14\n\n\nActually, I’d like to reorder fiction_r to put Other last.\n\nsur15_m &lt;- sur15_m |&gt;\n    mutate(fiction_r = fct_relevel(fiction_r, \n                                   \"Comedy\", \"Drama\",\n                                   \"Fantasy/SF\", \"Other\"))\n\nOK. Let’s see what we have now…\n\nsur15_m |&gt;\n    tabyl(medium_r, fiction_r) |&gt;\n    kable()\n\n\n\n\nmedium_r\nComedy\nDrama\nFantasy/SF\nOther\n\n\n\n\nMovies\n4\n5\n6\n2\n\n\nTV\n11\n5\n2\n4\n\n\nOther\n3\n5\n6\n0\n\n\n\n\n\nOK. I wish we didn’t have that zero cell in the cross-tabulation, but we’ll leave it alone, rather than collapsing further, given our small number of observations in this demonstration."
  },
  {
    "objectID": "sample-study1.html#creating-our-analytic-tibble",
    "href": "sample-study1.html#creating-our-analytic-tibble",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.5 Creating our Analytic Tibble",
    "text": "2.5 Creating our Analytic Tibble\nSo our analytic tibble, which I’ll call sur15 should contains only the twelve variables that appear in our code book.\n\nsur15 &lt;- sur15_m |&gt;\n    select(s_id, r_pre, r_now, comfort_431, \n           height_r, weight_r, bmi, \n           r_before, english,\n           grades_r, medium_r, fiction_r)"
  },
  {
    "objectID": "sample-study1.html#list-of-missing-values",
    "href": "sample-study1.html#list-of-missing-values",
    "title": "431 Project B Sample Study 1 Report",
    "section": "2.6 List of Missing Values",
    "text": "2.6 List of Missing Values\nWe can count the number of missing observations in each variable, with …\n\nmiss_var_summary(sur15)\n\n# A tibble: 12 × 3\n   variable    n_miss pct_miss\n   &lt;chr&gt;        &lt;int&gt;    &lt;num&gt;\n 1 bmi              3     5.66\n 2 height_r         2     3.77\n 3 weight_r         1     1.89\n 4 grades_r         1     1.89\n 5 s_id             0     0   \n 6 r_pre            0     0   \n 7 r_now            0     0   \n 8 comfort_431      0     0   \n 9 r_before         0     0   \n10 english          0     0   \n11 medium_r         0     0   \n12 fiction_r        0     0   \n\n\nWe can see the subjects who have missing values in several ways, including…\n\nmiss_case_summary(sur15)\n\n# A tibble: 53 × 3\n    case n_miss pct_miss\n   &lt;int&gt;  &lt;int&gt;    &lt;dbl&gt;\n 1     4      2    16.7 \n 2    29      2    16.7 \n 3    50      2    16.7 \n 4    16      1     8.33\n 5     1      0     0   \n 6     2      0     0   \n 7     3      0     0   \n 8     5      0     0   \n 9     6      0     0   \n10     7      0     0   \n# ℹ 43 more rows\n\n\n\nsur15[which(!complete.cases(sur15)),]\n\n# A tibble: 4 × 12\n  s_id  r_pre r_now comfort_431 height_r weight_r   bmi r_before english\n  &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n1 504      20    80          50     NA        140  NA   Yes      No     \n2 516       0    50          70     71        200  27.9 No       Yes    \n3 529      25    75          85     NA        165  NA   No       Yes    \n4 550       0     0          15     66.5       NA  NA   No       No     \n# ℹ 3 more variables: grades_r &lt;fct&gt;, medium_r &lt;fct&gt;, fiction_r &lt;fct&gt;\n\n\nIn our sample of respondents, we have:\n\n49 subjects with no missing values,\n1 subject (s_id = 516) who is missing grades_r,\n2 subjects (s_id = 504 and 529) who are missing height_r and bmi, and\n1 subject (s_id = 550) who is missing weight_r and bmi.\n\nSo we’ll have to keep that missingness in mind when we do work with bmi or grades_r in the analyses that follow."
  },
  {
    "objectID": "sample-study1.html#variable-descriptions",
    "href": "sample-study1.html#variable-descriptions",
    "title": "431 Project B Sample Study 1 Report",
    "section": "3.1 Variable Descriptions",
    "text": "3.1 Variable Descriptions\nThe 12 variables in our tidy data set sur15 for this demonstration are as follows. The Type column indicates the number of levels in each categorical (factor) variable. Recall that we have missing data in height_r, weight_r, bmi and grades_r and I’ve indicated this in the codebook table below. As for the Type information, I’m using Quant to indicate quantitative variables, and Cat-x indicates a categorical variable (factor) with x levels.\n\n\n\n\n\n\n\n\nVariable\nType\nDescription / Levels\n\n\n\n\ns_id\nID\nsubject code (501-533)\n\n\nr_pre\nQuant\n0 (SD) - 100 (SA) with Prior to taking 431, I was totally confident and comfortable with using R.\n\n\nr_now\nQuant\n0 (SD) - 100 (SA) with Right now, I am totally confident and comfortable with using R.\n\n\ncomfort_431\nQuant\n0 (SD) - 100 (SA) with I am very comfortable with my understanding of the material discussed so far in 431.\n\n\nheight_r\nQuant\nWhat is your height, in inches [2 NA]\n\n\nweight_r\nQuant\nWhat is your weight, in pounds [1 NA]\n\n\nbmi\nQuant\n703 x weight/(height squared) [3 NA]\n\n\nr_before\nCat-2\nyes, no: Before taking 431, had you ever used R before?\n\n\nenglish\nCat-2\nyes, no: Is English the language you speak better than any other?\n\n\ngrades_r\nCat-3\nIndividual, Partner, Group: In your graduate and undergraduate educational experience, which of the following types of assignments have you received the HIGHEST grades for? [1 NA]\n\n\nmedium_r\nCat-3\nMovies, TV, Other: Which medium do you use most to get your fictional stories (containing plot)?\n\n\nfiction_r\nCat-4\nComedy, Drama, Fantasy/SF, Other: Which type of fictional stories do you consume most?"
  },
  {
    "objectID": "sample-study1.html#analytic-tibble",
    "href": "sample-study1.html#analytic-tibble",
    "title": "431 Project B Sample Study 1 Report",
    "section": "3.2 Analytic Tibble",
    "text": "3.2 Analytic Tibble\nNow, I’ll prove that sur15 is a tibble by printing it.\n\nsur15\n\n# A tibble: 53 × 12\n   s_id  r_pre r_now comfort_431 height_r weight_r   bmi r_before english\n   &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;fct&gt;    &lt;fct&gt;  \n 1 501       0    70          90     68.1      162  24.6 Yes      No     \n 2 502       0    70          50     67        151  23.6 No       Yes    \n 3 503       0    10          70     62.5      127  22.9 No       Yes    \n 4 504      20    80          50     NA        140  NA   Yes      No     \n 5 505      80    90          85     70        178  25.5 Yes      Yes    \n 6 506       0    50          80     73        145  19.1 No       Yes    \n 7 507      50    50          50     74        320  41.1 Yes      Yes    \n 8 508      60    75          80     70        165  23.7 Yes      No     \n 9 509       0    50          75     64        135  23.2 No       Yes    \n10 510      30    30          50     69        155  22.9 No       Yes    \n# ℹ 43 more rows\n# ℹ 3 more variables: grades_r &lt;fct&gt;, medium_r &lt;fct&gt;, fiction_r &lt;fct&gt;"
  },
  {
    "objectID": "sample-study1.html#data-summary",
    "href": "sample-study1.html#data-summary",
    "title": "431 Project B Sample Study 1 Report",
    "section": "3.3 Data Summary",
    "text": "3.3 Data Summary\n\n3.3.1 data_description()\nHere’s a data_description() result to show some information about the distribution of each quantitative variables in the sur15 tibble.\n\ndescribe_distribution(sur15 |&gt; select(-s_id))\n\nVariable    |   Mean |    SD |   IQR |            Range | Skewness | Kurtosis |  n | n_Missing\n----------------------------------------------------------------------------------------------\nr_pre       |  21.13 | 30.38 | 50.00 |    [0.00, 90.00] |     1.11 |    -0.29 | 53 |         0\nr_now       |  56.58 | 26.84 | 38.00 |    [0.00, 95.00] |    -0.66 |    -0.52 | 53 |         0\ncomfort_431 |  75.94 | 18.37 | 20.00 |  [15.00, 100.00] |    -1.32 |     1.66 | 53 |         0\nheight_r    |  67.47 |  3.46 |  5.00 |   [61.00, 74.00] |    -0.05 |    -0.85 | 51 |         2\nweight_r    | 155.74 | 33.97 | 35.00 | [107.00, 320.00] |     2.36 |     9.81 | 52 |         1\nbmi         |  23.94 |  4.11 |  4.39 |   [18.64, 41.08] |     1.87 |     5.30 | 50 |         3\n\n\n\n\n3.3.2 data_codebook()\nAnd here’s the data_codebook() result, which adds in tabulations of the categorical variables.\n\ndata_codebook(sur15 |&gt; select(-s_id))\n\nselect(sur15, -s_id) (53 rows and 11 variables, 11 shown)\n\nID | Name        | Type        | Missings |         Values |          N\n---+-------------+-------------+----------+----------------+-----------\n1  | r_pre       | numeric     | 0 (0.0%) |        [0, 90] |         53\n---+-------------+-------------+----------+----------------+-----------\n2  | r_now       | numeric     | 0 (0.0%) |        [0, 95] |         53\n---+-------------+-------------+----------+----------------+-----------\n3  | comfort_431 | numeric     | 0 (0.0%) |      [15, 100] |         53\n---+-------------+-------------+----------+----------------+-----------\n4  | height_r    | numeric     | 2 (3.8%) |       [61, 74] |         51\n---+-------------+-------------+----------+----------------+-----------\n5  | weight_r    | numeric     | 1 (1.9%) |     [107, 320] |         52\n---+-------------+-------------+----------+----------------+-----------\n6  | bmi         | numeric     | 3 (5.7%) | [18.64, 41.08] |         50\n---+-------------+-------------+----------+----------------+-----------\n7  | r_before    | categorical | 0 (0.0%) |             No | 28 (52.8%)\n   |             |             |          |            Yes | 25 (47.2%)\n---+-------------+-------------+----------+----------------+-----------\n8  | english     | categorical | 0 (0.0%) |             No | 18 (34.0%)\n   |             |             |          |            Yes | 35 (66.0%)\n---+-------------+-------------+----------+----------------+-----------\n9  | grades_r    | categorical | 1 (1.9%) |     Individual | 40 (76.9%)\n   |             |             |          |        Partner |  6 (11.5%)\n   |             |             |          |          Group |  6 (11.5%)\n---+-------------+-------------+----------+----------------+-----------\n10 | medium_r    | categorical | 0 (0.0%) |         Movies | 17 (32.1%)\n   |             |             |          |             TV | 22 (41.5%)\n   |             |             |          |          Other | 14 (26.4%)\n---+-------------+-------------+----------+----------------+-----------\n11 | fiction_r   | categorical | 0 (0.0%) |         Comedy | 18 (34.0%)\n   |             |             |          |          Drama | 15 (28.3%)\n   |             |             |          |     Fantasy/SF | 14 (26.4%)\n   |             |             |          |          Other |  6 (11.3%)\n-----------------------------------------------------------------------"
  },
  {
    "objectID": "sample-study1.html#the-question",
    "href": "sample-study1.html#the-question",
    "title": "431 Project B Sample Study 1 Report",
    "section": "4.1 The Question",
    "text": "4.1 The Question\nWe’ll compare the r_now scores to r_pre scores. The scores are paired by subject, as each subject gives us both a r_pre and r_now score, and computing and assessing within-subject differences in comfort with R makes sense, because we are interested in the change in each person’s comfort level. We’ll generally use r_now - r_pre in our calculations, so that positive numbers indicate improvements in confidence. Note that we’ll use a 90% confidence level throughout this demonstration project for all analyses, and I encourage you to do this in your actual Project B Study 1 work, as well.\nSo, our research question might be something like:\nWhat is a typical change in comfort with R experienced by students in 431 through the first couple of months in the course?"
  },
  {
    "objectID": "sample-study1.html#describing-the-data",
    "href": "sample-study1.html#describing-the-data",
    "title": "431 Project B Sample Study 1 Report",
    "section": "4.2 Describing the Data",
    "text": "4.2 Describing the Data\n\n4.2.1 Compute and summarize the paired differences\nThe natural first step is to compute paired differences between the r_now and r_pre samples, and then use graphical and numerical summaries to assess whether the sample (of differences) can be assumed to follow a Normal distribution. First, we’ll calculate the paired differences.\n\nsur15 &lt;- sur15 |&gt;\n    mutate(r_diff = r_now - r_pre)\n\nsur15 |&gt; reframe(lovedist(r_diff))\n\n# A tibble: 1 × 10\n      n  miss  mean    sd   med   mad   min   q25   q75   max\n  &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1    53     0  35.5  28.7    30  37.1     0    10    60    95\n\n\nOK. It appears that we have successfully subtracted the PRE data from the NOW data, and everyone has a difference of at least zero. But we have a lot of people (8) who have a value of 0. Now, we’ll assess whether or not a Normal distribution might be a reasonable model for the data.\n\n\n4.2.2 Graphical Summaries to Assess Normality\nWe should start by looking at the distribution of these 53 values of r_diff. As we’ve seen, there’s a floor effect at zero.\nA histogram with 53 values won’t give us a lot of information. Perhaps we should focus instead on a Normal Q-Q plot and boxplot with violin? We’ll draw all three here.\n\np1 &lt;- ggplot(sur15, aes(x = r_diff)) +\n    geom_histogram(fill = \"slateblue\", col = \"white\", \n                   binwidth = 10) + \n    labs(x = \"R Comfort Rating Difference\") \n\np2 &lt;- ggplot(sur15, aes(sample = r_diff)) +\n    geom_qq(col = \"slateblue\") + geom_qq_line(col = \"red\") + \n    labs(y = \"Rating Difference\") \n\np3 &lt;- ggplot(sur15, aes(x = \"n = 53\", y = r_diff)) +\n    geom_violin() + \n    geom_boxplot(fill = \"slateblue\", width = 0.3, notch = TRUE) + \n    labs(y = \"Current - PreClass Difference in R Comfort Rating\",\n         x = \"\") +\n    coord_flip()\n\np1 + p2 - p3 +\n  plot_layout(ncol = 1, height = c(3, 2)) +\n  plot_annotation(title = \"Most Students Improved R Comfort Ratings during 431\")\n\n\n\n\n\n\n\n\nWith just 53 observations, it will be a little difficult to get a clear picture of whether a Normal approximation is reasonable or not. I would conclude that a bootstrap approach would be a better choice here than a Normal model for the paired differences, owing to the floor effect (many zeros) in the paired differences. The data are a bit skewed, although they don’t quite sneak over the 0.2 cutoff for skew1.\n\n\n4.2.3 Did Pairing Help Reduce Nuisance Variation?\nWe would expect a strong correlation between the r_pre and r_now scores in this repeated measures analysis where each subject is assessing both their confidence before the class and then again during the class. To assess whether pairing helped reduce nuisance variation, I’ll build a scatterplot of the r_pre and r_now scores, supplemented by a Pearson correlation coefficient. Since we have so many ties in the data, with two or more points in the same place, I’ll use geom_jitter rather than geom_point to plot the points. The larger the correlation, the more that pairing will help reduce the impact of differences between subjects on the r_pre score on the comparison we’re trying to make.\n\nggplot(sur15, aes(x = r_pre, y = r_now)) +\n    geom_jitter(col = \"slateblue\") +\n    geom_smooth(formula = y ~ x, method = \"lm\", col = \"red\") +\n    labs(title = \"Jittered Scatterplot shows moderately strong relationship\",\n         subtitle = \"especially for those starting above 0\")\n\n\n\n\n\n\n\n\nFor people with a r_pre score greater than zero, we see a pretty strong linear relationship between r_pre and r_now.\n\nsur15 |&gt; select(r_pre, r_now) |&gt; cor() |&gt; \n    round_half_up(digits = 3) |&gt; kable()\n\n\n\n\n\nr_pre\nr_now\n\n\n\n\nr_pre\n1.000\n0.503\n\n\nr_now\n0.503\n1.000\n\n\n\n\n\nThe Pearson correlation is quite strong at 0.503 so that a linear model using the r_pre score accounts for a reasonably large fraction (25.3%) of the variation in r_now scores.\n\nIf the Pearson correlation had been small but still positive (perhaps less than 0.2), we might conclude that pairing wouldn’t be exceptionally helpful, but if the samples are meant to be paired, we should still do a paired samples analysis, but such a small correlation would imply that an independent samples comparison would come to about the same conclusion."
  },
  {
    "objectID": "sample-study1.html#main-analysis",
    "href": "sample-study1.html#main-analysis",
    "title": "431 Project B Sample Study 1 Report",
    "section": "4.3 Main Analysis",
    "text": "4.3 Main Analysis\nAs you’ll recall, we have two main methods for building confidence intervals in a paired samples analysis:\n\nThe Paired t test\nThe Bootstrap, using smean.cl.boot\n\nLet’s run each in this demonstration just so you have the code, even though, as mentioned, I’d be most interested in what the bootstrap approach suggests, owing to the modest non-Normality we see in the sample of differences. I’ll even throw in a Wilcoxon signed rank test approach here, even though I wouldn’t recommend you include that in Project B. In each case, we’ll build a 90% confidence interval for the population mean (or pseudo-median, in the case of the signed rank test) of the r_now - r_pre differences.\n\n4.3.1 The Paired t test approach\nHere is a 90% confidence interval for the population mean of the paired r_now - r_pre differences.\n\nt.test(sur15$r_diff, conf.level = .90) |&gt; \n  tidy() |&gt;\n  select(estimate, conf.low, conf.high)\n\n# A tibble: 1 × 3\n  estimate conf.low conf.high\n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     35.5     28.9      42.1\n\n\n\nThe point estimate for the population mean of the differences is 35.45, indicating that the average subject rated agreement with the statement about confidence in R 35 points higher now than when they started the class.\nOur 90% confidence interval for the population mean of the differences is (28.9, 42.1)\nHere, I’ve assumed a two-sided confidence interval procedure. We conclude from the confidence interval (which does not contain zero) that there is some evidence of a difference between the r_pre and r_now scores.\nThe assumptions of the paired t procedure are\n\nthat the matched differences are independent of each other,\nthat the matched differences represent a random sample of the population of possible matched differences,\nand that the matched differences are drawn from a Normally distributed population. - The last of these assumptions is hard to justify given these data.\n\n\n\n\n4.3.2 The Wilcoxon signed rank test approach\nHere is a 90% confidence interval for the population pseudo-median of the paired r_now - r_pre differences, as estimated by the Wilcoxon signed rank approach.\n\nwilcox.test(sur15$r_diff, conf.level = .90, conf.int = TRUE, exact = FALSE) |&gt;\n  tidy() |&gt;\n  select(estimate, conf.low, conf.high)\n\n# A tibble: 1 × 3\n  estimate conf.low conf.high\n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1     40.0     35.0      47.5\n\n\n\nThe point estimate for the population pseudo-median of the differences is 40, indicating that the average subject rated agreement with the statement about confidence in R 40 points higher now than when they started the class. Note that this is meaningfully different from the sample median difference, which was 30, and that’s because there was some skew in the sample data. The interpretation of the Wilcoxon approach is easiest for data that are light-tailed or heavy-tailed, but still generally symmetric.\nOur 90% confidence interval for the population pseudo-median of the differences is (35, 47.5)\nHere, I’ve assumed a two-sided confidence interval and testing procedure. We conclude from the confidence interval (which does not contain zero) that there is some evidence of a meaningful difference between r_pre and r_now scores.\nThe assumptions of the Wilcoxon signed rank procedure are\n\nthat the matched differences are independent of each other,\nthat the matched differences represent a random sample of the population of possible matched differences,\nand that the matched differences are drawn from a population that is symmetric, but potentially light-tailed, or even outlier-prone\nThe last of these assumptions is hard to justify given these data.\n\n\n\n\n4.3.3 The Bootstrap approach for the mean from paired samples\nHere is a 90% confidence interval for the population mean of the paired r_now - r_pre differences, as estimated by a bootstrap approach using a random seed of 431. (Note: when you set a seed for this or other analyses in the project, pick something other than 431.)\n\nset.seed(431)\nsmean.cl.boot(sur15$r_diff, conf.int = 0.90)\n\n    Mean    Lower    Upper \n35.45283 28.90566 42.09623 \n\n\n\nThe point estimate for the population mean of the differences is 35.45, indicating that the average subject rated agreement with the statement about confidence in R 35 points higher now than when they started the class.\nOur 90% confidence interval for the population mean of the differences is fairly close to what we got from the paired t test, as it turns out.\nHere, I’ve assumed a two-sided confidence interval procedure, and so we can discuss a range of reasonable estimates for the true difference in r_pre and r_now scores.\nThe assumptions of this bootstrap procedure are\n\nthat the matched differences are independent of each other, and\nthat the matched differences represent a random sample of the population of possible matched differences,"
  },
  {
    "objectID": "sample-study1.html#conclusions",
    "href": "sample-study1.html#conclusions",
    "title": "431 Project B Sample Study 1 Report",
    "section": "4.4 Conclusions",
    "text": "4.4 Conclusions\nSubjects appear to improve in their comfort with R an average of 35.45 points on the 0-100 scale, with a 90% confidence interval for that average improvement of (28.9, 42.1) points. This conclusion is motivated by a bootstrap estimate to compare paired responses from students before and after the first couple of months of the course, and I feel this is the most justified approach based on my assessment of Normality in the data from these 53 students.\nA natural next step would be to look at values of something like this over multiple years, or perhaps comparing students at more than just two stages. It would also be appealing to measure comfort with R at the earlier time, and then return to the students later, rather than asking them to remember where they were at the start a couple of months later. There are several other possible next steps here, too, depending on what population you might decide to target."
  },
  {
    "objectID": "sample-study1.html#the-question-1",
    "href": "sample-study1.html#the-question-1",
    "title": "431 Project B Sample Study 1 Report",
    "section": "5.1 The Question",
    "text": "5.1 The Question\nWe’ll compare bmi by english in this analysis using independent samples. We’re comparing the mean bmi of the population represented by respondents who speak English best to the mean bmi of the population represented by the respondents who speak some other language better. There is nothing to suggest that the two samples (English bmi and non-English bmi values) are paired or matched in any way. Plus, as we’ll see, there are different numbers of English and non-English preferring subjects, so there’s no way their bmi values could be paired. As a result, we’re going to be interested in looking at the two samples separately to help us understand issues related to hypothesis testing assumptions. Note that we’ll use a 90% confidence level throughout this demonstration project for all analyses, and I encourage you to do this in your actual Project Study B work, as well.\nOur research question is:\nDid students who speak English best have meaningfully different average body mass index values than students who speak some other language better than they speak English?"
  },
  {
    "objectID": "sample-study1.html#describing-the-data-1",
    "href": "sample-study1.html#describing-the-data-1",
    "title": "431 Project B Sample Study 1 Report",
    "section": "5.2 Describing the Data",
    "text": "5.2 Describing the Data\nI’ll start by looking at the range of the bmi data within each language group\n\nsur15 |&gt; group_by(english) |&gt; \n  reframe(lovedist(bmi))\n\n# A tibble: 2 × 11\n  english     n  miss  mean    sd   med   mad   min   q25   q75   max\n  &lt;fct&gt;   &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 No         18     2  23.5  2.97  23.3  2.41  20.0  21.3  24.4  30.3\n2 Yes        35     1  24.1  4.58  23.2  3.38  18.6  21.2  26.1  41.1\n\n\nAs we have previously seen, we have three missing BMI values. We could either impute these values, or remove those cases for this analysis. In this case, I’ll assume missingness completely at random, and simply remove the three missing values.\nSo for this analysis, I’ll create a new data set called sur15_B that contains only the variables I will use in Analysis B, and only the cases where bmi is available.\n\n5.2.1 A New Data Set including only those with bmi data\n\nsur15_B &lt;- sur15 |&gt;\n  filter(complete.cases(bmi)) |&gt;\n  select(s_id, english, bmi)\n\nsur15 |&gt; group_by(english) |&gt; \n  reframe(lovedist(bmi))\n\n# A tibble: 2 × 11\n  english     n  miss  mean    sd   med   mad   min   q25   q75   max\n  &lt;fct&gt;   &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 No         18     2  23.5  2.97  23.3  2.41  20.0  21.3  24.4  30.3\n2 Yes        35     1  24.1  4.58  23.2  3.38  18.6  21.2  26.1  41.1\n\n\nNext, we’ll use graphical and numerical summaries to assess whether the samples (of Yes and No respondents, separately) can each be modeled appropriately by a Normal distribution.\n\n\n5.2.2 Graphical Summaries\nLet’s build a comparison boxplot (with notches and violins) to start. This will give me a message (which I’ll suppress here with #| message: false in the code chunk) about the notch exceeding the third quartile in the No group.\n\nggplot(sur15_B, aes(x = english, y = bmi, fill = english)) + \n  geom_violin(alpha = 0.3) +\n  geom_boxplot(width = 0.3, notch = TRUE) +\n  guides(fill = \"none\") +\n  labs(title = \"BMI data somewhat right skewed in each group\",\n       subtitle = \"n = 50 Students in 431: Fall 2015\",\n       x = \"Speaks English better than all other languages?\", y = \"Body Mass Index\") \n\n\n\n\n\n\n\n\nThere are at least a couple of candidate outliers in each group on the high end, which suggest some potential for meaningful skew.\nWe could also build a pair of Normal Q-Q plots.\n\nggplot(sur15_B, aes(sample = bmi, col = english)) +\n  geom_qq() + geom_qq_line() +\n  facet_wrap(~ english, labeller = \"label_both\") +\n  guides(col = \"none\") +\n  labs(y = \"Observed BMI values\",\n       title = \"BMI isn't well fit by a Normal model in either group\")\n\n\n\n\n\n\n\n\nThere’s room for concern about whether a test that requires Normal distributions in the populations is a good choice here. With these small sample sizes, we’d probably be better off not making too many strong assumptions.\n\n\n5.2.3 Numerical Summaries\nWe have 16 No and 34 Yes respondents to the English language question who have known BMI values.\n\nsur15_B |&gt; group_by(english) |&gt; reframe(lovedist(bmi))\n\n# A tibble: 2 × 11\n  english     n  miss  mean    sd   med   mad   min   q25   q75   max\n  &lt;fct&gt;   &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 No         16     0  23.5  2.97  23.3  2.41  20.0  21.3  24.4  30.3\n2 Yes        34     0  24.1  4.58  23.2  3.38  18.6  21.2  26.1  41.1\n\n\nIt looks like the right skew is large enough, at least in the Yes (speaks English best) group to warrant avoiding tests that require Normality. So again it looks like it’s not reasonable to assume Normality here, or even symmetry."
  },
  {
    "objectID": "sample-study1.html#main-analysis-1",
    "href": "sample-study1.html#main-analysis-1",
    "title": "431 Project B Sample Study 1 Report",
    "section": "5.3 Main Analysis",
    "text": "5.3 Main Analysis\nAs you’ll recall, we have three main methods for building confidence intervals in an independent samples analysis:\n\nWelch’s t test (t test without assuming equal variances)\nThe Pooled t test (t test with equal variances assumed)\nThe Bootstrap, using bootdif\n\nLet’s run each here just so you have the code, even though, as mentioned, I’d be most interested in what the bootstrap approach suggests, owing to the fact that the samples aren’t well described by Normal models or even symmetric ones. I’ll even throw in a Wilcoxon Rank Sum approach here, even though I wouldn’t recommend you include that in Project B.In each case, we’ll build a 90% confidence interval for the population mean (or another measure of central tendency, in the case of the Rank Sum test) comparing bmi for people who answered Yes and No to the question about English being the language they speak best.\n\n5.3.1 The Welch’s t test approach\nWith a somewhat unbalanced design (16 No and 34 Yes), the assumption of equal population variances will probably require us to look at the sample variances.\n\nsur15_B |&gt; group_by(english) |&gt;\n  summarise(n = n(), mean = mean(bmi), variance = var(bmi))\n\n# A tibble: 2 × 4\n  english     n  mean variance\n  &lt;fct&gt;   &lt;int&gt; &lt;dbl&gt;    &lt;dbl&gt;\n1 No         16  23.5     8.83\n2 Yes        34  24.1    21.0 \n\n\nThat’s a pretty substantial difference in variance with the Yes group a good deal more than 50% larger than the No group, so we might expect the Welch t test and pooled t test to look fairly different, and that would motivate me to focus on the Welch approach over the pooled t test. Of course, neither is a great choice here, due to the samples showing some non-Normality. Regardless, here is a 90% confidence interval for the difference between the “No” group and the “Yes” group population mean bmi based on Welch’s test.\n\nt.test(bmi ~ english, data = sur15_B, conf.level = 0.90) |&gt;\n  tidy() |&gt;\n  select(estimate, conf.low, conf.high)\n\n# A tibble: 1 × 3\n  estimate conf.low conf.high\n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1   -0.617    -2.43      1.20\n\n\n\nThe point estimates for the two population bmi means are 23.52 for No and 24.14 for Yes, so the average student who speaks English best has a BMI estimated to be about 0.62 points higher than the average for a student who speaks another language better than English, based on our samples.\nOur 90% confidence interval for the difference (English - non-English) of the population means is (-1.2, 2.4).\nHere, I’ve assumed a two-sided confidence interval procedure. We conclude from the confidence interval (which contains zero) only that the difference between the true means of the English and non-English bmi levels is neither clearly positive nor negative.\nThe assumptions of the Welch’s t test are\n\nthat the samples in each group are drawn independently of each other,\nthat the samples in each group represent a random sample of the population of interest,\nand that the samples in each group are drawn from a Normally distributed population.\n\nThe last of these assumptions is hard to justify given these data.\n\n\n\n5.3.2 The Pooled t test (t test with equal variances)\nThe pooled t test, of course, actually adds an assumption (that either the sample sizes or the population variances are equal) to the assumptions of the Welch test. As mentioned above, the large difference in the sample variances and sample sizes makes this test unattractive, in addition to the problems with assuming Normality. Regardless, here is a 90% confidence interval for the difference between the non-English and English population mean bmi based on the pooled t test.\n\nt.test(bmi ~ english, data = sur15_B, conf.level = .90, var.equal = TRUE) |&gt;\n  tidy() |&gt;\n  mutate(estimate = estimate1 - estimate2) |&gt;\n  select(estimate, conf.low, conf.high)\n\n# A tibble: 1 × 3\n  estimate conf.low conf.high\n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1   -0.617    -2.72      1.49\n\n\n\nThe point estimates for the two population bmi means are still 23.52 for No and 24.14 for Yes, so the average student who speaks English best has a BMI estimated to be about 0.62 points higher than the average for a student who speaks another language better than English, based on our samples.\nOur 90% confidence interval for the difference (English - non-English) of the population means is now (-1.5, 2.7) based on the pooled t procedure.\nHere, I’ve assumed a two-sided confidence interval procedure. We conclude again that there is no strong evidence to conclude a meaningful difference between the true means of the English and non-English bmi levels.\nThe assumptions of the pooled t test are\n\nthat the samples in each group are drawn independently of each other,\nthat the samples in each group represent a random sample of the population of interest,\nthe samples in each group are drawn from a Normally distributed population,\nand that either the sample sizes or the population variances are equal.\n\nThe Normality assumption remains hard to justify given these data, so we should look at alternatives.\n\n\n\n5.3.3 The Wilcoxon-Mann-Whitney rank sum test\nThe first test we’ll look that doesn’t require Normality is the Wilcoxon-Mann-Whitney rank sum test. The main problem with this approach is that it doesn’t estimate the difference in population means, but rather it estimates a location shift for the distribution as a whole. Here is a 90% confidence interval for the difference between the non-English and English population bmi distributions based on the rank sum approach.\n\nwilcox.test(bmi ~ english, data = sur15_B,\n            conf.level = .90, conf.int = TRUE, \n            exact = FALSE) |&gt;\n  tidy() |&gt;\n  select(estimate, conf.low, conf.high)\n\n# A tibble: 1 × 3\n  estimate conf.low conf.high\n     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1   -0.126    -1.89      1.41\n\n\n\nThe estimated location shift in population bmi across the two language groups is 0.13.\nOur 90% confidence interval for the location shift (English - non-English) of the populations is (-1.4, 1.9).\nHere, I’ve assumed a two-sided confidence interval procedure. We see potential true locations of the difference between English and non-English bmi levels that include both positive and negative values.\n\nThe assumptions of the rank sum test are\n\nthat the samples in each group are drawn independently of each other,\nand that the samples in each group represent a random sample of the population of interest,\nand that the data in each population (English and non-English) are symmetric.\n\n\n\nThat last assumption is difficult to justify.\n\n\n5.3.4 The Bootstrap for comparing means from two independent samples\nThe other approach we have for independent samples comparisons that doesn’t require Normality is the bootstrap, and specifically, the bootdif function. This approach returns to estimating the difference in population means, but gives a different answer depending on the choice of random number seed. Here is a 90% confidence interval for the difference between the English and non-English population bmi distributions based on the bootstrap using a seed of 431. (Note: when you set a seed for this or other analyses in the project, pick something other than 431.)\n\nset.seed(431) \nbootdif(sur15_B$bmi, sur15_B$english, conf.level = 0.90)\n\n\nThe population mean BMI in those who said Yes is estimated to be about 0.62 points higher than the population mean BMI for those who said No, based on our samples. So the mean differences’ point estimate is 0.62\nOur 90% confidence interval for the difference (Yes - No) of the population means is (-1.12, 2.34).\nHere, I’ve assumed a two-sided confidence interval procedure. We conclude from the confidence interval that the difference between the true means of the English and non-English bmi levels could be either positive or negative, according to our analysis.\nThe assumptions of this bootstrap procedure are:\n\nthat the samples in each group are drawn independently of each other,\nand that the samples in each group represent a random sample of the population of interest.\n\n\nSo, I think the bootstrap procedure would be most appropriate here, due to the non-Normality (and in particular the asymmetry) in the samples."
  },
  {
    "objectID": "sample-study1.html#conclusions-1",
    "href": "sample-study1.html#conclusions-1",
    "title": "431 Project B Sample Study 1 Report",
    "section": "5.4 Conclusions",
    "text": "5.4 Conclusions\nWe find a range of possible values which crosses zero for the difference between the population mean BMI for those who speak English best and those who speak another language best, based on our sample of respondents with complete data on BMI. This conclusion is motivated by a bootstrap estimate to compare the two groups (English and non-English) with complete data on BMI. I feel this is the most justified approach based on the apparent skew in the data (particularly among those who speak English best) in these students.\nThen, if this were an actual Project B Study 1, I’d discuss the other issues that go into a conclusion, including limitations of this study and suggestions about logical next steps. But I’ll be lazy and skip that for now."
  },
  {
    "objectID": "sample-study1.html#the-question-2",
    "href": "sample-study1.html#the-question-2",
    "title": "431 Project B Sample Study 1 Report",
    "section": "6.1 The Question",
    "text": "6.1 The Question\nWe’ll compare comfort_431 by grades_r in this analysis, using the analysis of variance, and related tools. We’re comparing the mean comfort_431 scores of the population represented by the respondents who got their best grades_r on individual work, to the population represented by the respondents who got their best grades_r with a partner, to the population represented by the respondents who got their best grades_r on group work. There is no link between subjects across the three grades_r groups, so the samples are independent. Plus, as we’ll see, there are different numbers of subjects in the three grades_r groups, so there’s no way their comfort_431 values could be matched. As a result, we’re going to be interested in looking at the three samples separately to help us understand issues related to hypothesis testing assumptions. Note that we’ll use a 90% confidence level throughout this demonstration project for all analyses, and I encourage you to do this in your actual Project B Study 1 work, as well.\nIf this were an actual Study 1, rather than a demonstration, I’d build a research question here, but I won’t."
  },
  {
    "objectID": "sample-study1.html#describing-the-data-2",
    "href": "sample-study1.html#describing-the-data-2",
    "title": "431 Project B Sample Study 1 Report",
    "section": "6.2 Describing the Data",
    "text": "6.2 Describing the Data\nI’ll start by looking at the range of the comfort_431 data within each grades_r group.\n\nsur15 |&gt; group_by(grades_r) |&gt; reframe(lovedist(comfort_431))\n\n# A tibble: 4 × 11\n  grades_r       n  miss  mean    sd   med   mad   min   q25   q75   max\n  &lt;fct&gt;      &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Individual    40     0  79.0  15.3    80  14.8    35  73.8    90   100\n2 Partner        6     0  53.3  26.8    60  25.9    15  35      70    85\n3 Group          6     0  79.5  16.1    85  10.4    50  76      88    95\n4 &lt;NA&gt;           1     0  70    NA      70   0      70  70      70    70\n\n\nWe have only 6 respondents in each of the Partner and Group grades_r categories, so that will make it difficult to say much about the distributions of comfort_431 in those populations.\n\n6.2.1 Dropping the subject with a missing grades_r value\n\ndescribe(sur15$grades_r) |&gt; html()\n\n\n\n\n\n Descriptives\nsur15$grades_r\n\n \n nmissingdistinct\n 5213\n \n\n Value      Individual    Partner      Group\n Frequency          40          6          6\n Proportion      0.769      0.115      0.115 \n\n\n\nAs you can see, we have one subject with a missing value for the grades_r variable. We’ll drop that subject for the remainder of Analysis 2 (and also for Analysis 3 to come). While I’m at it, I’ll also select only those variables that we might use in Analysis C. That combined effort will yield the new data frame: sur15_C, which I will use for the remainder of Analysis C.\n\nsur15_C &lt;- sur15 |&gt;\n  filter(complete.cases(grades_r)) |&gt;\n  select(s_id, grades_r, comfort_431)\n\n\n\n6.2.2 Graphical Summaries\nSince we are exploring the distributions of three independent samples, I’ll plot each of the groups in a comparison boxplot, as a start.\n\nggplot(sur15_C, aes(x = grades_r, y = comfort_431, fill = grades_r)) +\n  geom_violin(alpha = 0.3) +\n  geom_boxplot(width = 0.3) +\n  coord_flip() +\n  guides(fill = \"none\") +\n  labs(title = \"Comfort with 431 by Type of Assignment that produces best grades_r\",\n       y = \"Comfort with 431 Materials (0-100)\",\n       x = \"\")\n\n\n\n\n\n\n\n\n\nNotice that the boxplot notches would have been messy (they extend outside the levels of the boxes) in this case due to the small numbers of subjects in the Partner and Group grades_r groups.\n\nThe sample sizes are so small that histograms for those two levels of the grades_r factor (Partner and Group) tell us nothing of substantial value.\n\nggplot(sur15_C, aes(x = comfort_431)) +\n  geom_histogram(aes(fill = grades_r), bins = 10, col = \"white\") +\n  facet_wrap(~ grades_r, labeller = \"label_both\") +\n  guides(fill = \"none\") +\n  labs(title = \"Comfort with 431 by Type of Assignment that produces best grades_r\",\n       y = \"Comfort with 431 Materials (0-100)\",\n       x = \"\")\n\n\n\n\n\n\n\n\n\nIn addition, the Individual data look as though they may be either skewed to the left a bit or at least have one potential outlier.\nWith these tiny sample sizes (less than 10 observations) these plots don’t really help much. All of the values in each group are within the stated response levels (0-100) but otherwise, there’s not a lot to go on. ANOVA is quite robust, so we’ll run it, but I expect that a Kruskal-Wallis approach may also be useful here.\n\n\n\n6.2.3 Numerical Summaries\nWith just six observations in the Partner and Group grades_r levels, there’s not much to see in numerical summaries, either.\n\nsur15_C |&gt; group_by(grades_r) |&gt; reframe(lovedist(comfort_431))\n\n# A tibble: 3 × 11\n  grades_r       n  miss  mean    sd   med   mad   min   q25   q75   max\n  &lt;fct&gt;      &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Individual    40     0  79.0  15.3    80  14.8    35  73.8    90   100\n2 Partner        6     0  53.3  26.8    60  25.9    15  35      70    85\n3 Group          6     0  79.5  16.1    85  10.4    50  76      88    95\n\n\nWe have 40 Individual, 6 Partner and 6 Group subjects with known comfort levels.\nThe conclusion I draw from all of this is that we need to run both ANOVA and Kruskal-Wallis approaches, but that we probably can’t trust either of them too much, with such small sample sizes in the non-Individual grades_r levels. Anything below 10 subjects is just too small, and, practically, I’d consider collapsing the groups to Individual vs. All Other. But for this demonstration, I’ll press on."
  },
  {
    "objectID": "sample-study1.html#main-analysis-2",
    "href": "sample-study1.html#main-analysis-2",
    "title": "431 Project B Sample Study 1 Report",
    "section": "6.3 Main Analysis",
    "text": "6.3 Main Analysis\nAs you’ll recall, we have at least two available methods for building statistical inferences when comparing more than two independent samples.\n\nAnalysis of Variance\nThe Kruskal-Wallis Test\n\nThere is also a bootstrap approach but we’ll defer discussion of that until 432.\nLet’s run both methods here just so you have the code, even though we don’t have large enough data samples in the Partner and Group levels to justify statistical inference at all. In each case, we’ll build hypothesis tests, and compare the distributions of comfort_431 across levels of grades_r using a 90% confidence level.\n\n6.3.1 Kruskal-Wallis Test\nI’ll start with the Kruskal-Wallis test, which at least doesn’t require me to assume Normality in the three populations. The null hypothesis here is that there is no location shift in the distributions of comfort in 431 across the three levels of grades_r. Put another way, the location parameters of the distributions are the same across the three grades_r levels. The Kruskal-Wallis test is the extension of the Wilcoxon-Mann-Whitney rank sum test to studies involving more than two independent samples.\n\nkruskal.test(comfort_431 ~ grades_r, data = sur15_C)\n\n\n    Kruskal-Wallis rank sum test\n\ndata:  comfort_431 by grades_r\nKruskal-Wallis chi-squared = 6.8034, df = 2, p-value = 0.03332\n\n\n\nThis result suggests only that the separation we observe between the comfort_431 scores for the three grades_r categories is consistent with some true differences between those groups.\nThe assumptions of the Kruskal-Wallis test are the same as those of the Wilcoxon-Mann-Whitney rank sum test, specifically that\n\nthat the samples in each category are drawn independently of each other,\nand that the samples in each category represent a random sample of the population of interest,\n\n\nThe main problem here is that the sample size is so small that we can’t tell whether this result is truly more or less reasonable than an ANOVA approach. We really need a minimum of 15 observations (and ideally more like 30) in each group to let our histograms and boxplots have any chance to be informative on these points. So let’s look at the ANOVA results.\n\n\n6.3.2 Analysis of Variance\nThe Analysis of Variance compares the means of comfort_431 in the three grades_r populations. We can run the analysis using either of two approaches, each of which we’ll show in what follows.\n\nlm(comfort_431 ~ grades_r, data = sur15_C) |&gt;\n  anova()\n\nAnalysis of Variance Table\n\nResponse: comfort_431\n          Df  Sum Sq Mean Sq F value   Pr(&gt;F)   \ngrades_r   2  3504.1 1752.05  6.1301 0.004207 **\nResiduals 49 14004.7  285.81                    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\nHere, we’d conclude only that the results we have are not particularly consistent with an assumption that there are no differences between the population mean comfort_431 scores for the three grades_r categories.\nThe grades_r account for \\(\\eta^2 = \\frac{3504.1}{3504.1 + 14004.7} = 0.2\\) or 20% of the variation in comfort_431 scores in our sample.\nThe natural next question is to try to identify which pairs of grades_r categories show larger estimated differences, and we’ll tackle that in a moment with Bonferroni/Holm and Tukey HSD approaches.\nANOVA is the natural extension of the pooled t test for two independent samples, and so it has the same set of assumptions when we compare population means across multiple categories (here, the three grades_r categories)…\n\nthat the samples in each category are drawn independently of each other,\nthat the samples in each category represent a random sample of the population of interest,\nthe samples in each category are drawn from a Normally distributed population,\nand that either the sample sizes or the population variances are equal across the categories.\n\n\nThe main problem here is that the sample size is so small that we can’t tell whether this result is truly reasonable or not. We really need a minimum of 15 observations (and ideally more like 30) in each group to let our histograms and boxplots have any chance to be informative on these points. We’ll move on to looking at the pairwise comparisons, though, in this demonstration.\n\n\n6.3.3 Holm approach to Pairwise Comparisons of Means\nWe have two approaches available for dealing with multiple comparisons. If we had not pre-planned the full set of pairwise comparisons of comfort_431 across the grades_r categories, or if we wanted to use a fairly conservative approach, we could apply a Holm correction to our comparisons. This works reasonably well even with an unbalanced design, such as we have here.\n\npairwise.t.test(sur15_C$comfort_431, sur15_C$grades_r, \n                p.adjust = \"holm\")\n\n\n    Pairwise comparisons using t tests with pooled SD \n\ndata:  sur15_C$comfort_431 and sur15_C$grades_r \n\n        Individual Partner\nPartner 0.0034     -      \nGroup   0.9411     0.0200 \n\nP value adjustment method: holm \n\n\n\nOur process detects positive differences between the mean of the Partner category and the means of the other two categories, but suggests that the difference between Individual and Group means covers both positive and negative values.\nThe assumptions here include the ANOVA assumptions, which are no more or less justified than they were before. We do not, however, require that our pairwise comparisons be pre-planned.\nYou can learn more about the Holm method on its Wikipedia page.\n\n\n\n6.3.4 Tukey’s Honestly Significant Differences approach to Pairwise Comparisons of Means\nThe Tukey HSD approach requires us to use the aov approach to specifying the ANOVA model, as opposed to the anova with lm approach we took above. The results for aov are identical, as you can see below.\n\naov(sur15_C$comfort_431 ~ sur15_C$grades_r) |&gt; summary()\n\n                 Df Sum Sq Mean Sq F value  Pr(&gt;F)   \nsur15_C$grades_r  2   3504  1752.0    6.13 0.00421 **\nResiduals        49  14005   285.8                   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nNow, we run the Tukey HSD comparisons, both in a plot and table of results. As specified previously, we’ll use a 90% confidence level across the set of comparisons.\n\nTukeyHSD(aov(sur15_C$comfort_431 ~ sur15_C$grades_r), conf.level = 0.90)\n\n  Tukey multiple comparisons of means\n    90% family-wise confidence level\n\nFit: aov(formula = sur15_C$comfort_431 ~ sur15_C$grades_r)\n\n$`sur15_C$grades_r`\n                        diff        lwr       upr     p adj\nPartner-Individual -25.61667 -41.169906 -10.06343 0.0031728\nGroup-Individual     0.55000 -15.003240  16.10324 0.9969604\nGroup-Partner       26.16667   5.655662  46.67767 0.0265110\n\n\nThe confidence intervals suggest that the mean Partner scores are lower than both the mean Individual and Group scores, while the Group and Individual scores show differences from each other that could have either sign.\nNote that in the plot below, we see these results a bit more clearly after we adjust the margins of the plot and use the las = 1 bit at the end of the plotting call to get the x and y axis labels to be horizontal.\n\nmar.default &lt;- c(5,6,4,2) + 0.1\npar(mar = mar.default + c(0, 4, 0, 0))\nplot(TukeyHSD(aov(sur15_C$comfort_431 ~ sur15_C$grades_r),\n              conf.level = 0.90), las = 1)\n\n\n\n\n\n\n\npar(mar = mar.default)"
  },
  {
    "objectID": "sample-study1.html#conclusions-2",
    "href": "sample-study1.html#conclusions-2",
    "title": "431 Project B Sample Study 1 Report",
    "section": "6.4 Conclusions",
    "text": "6.4 Conclusions\nOur conclusions are:\n\nthat the sample size is just too small in the non-Individual grades_r categories to draw very firm conclusions, but\ndespite this, there appears to be evidence of some difference in comfort_431 across the three grades_r categories, according to either an ANOVA or Kruskal-Wallis approach, at the 90% confidence level, and\nspecifically, it appears from our 90% pairwise confidence intervals that the population means of the Group and Individual comfort levels are comparable and both are higher than the population mean of the Partner comfort levels.\n\nNote that I’ve made no effort here to write these conclusions in the format we’re looking for in your Study 1 work."
  },
  {
    "objectID": "sample-study1.html#the-question-3",
    "href": "sample-study1.html#the-question-3",
    "title": "431 Project B Sample Study 1 Report",
    "section": "7.1 The Question",
    "text": "7.1 The Question\nWe’ll look at the association of r_before with english in this analysis. The r_before variable and the english variable each have two levels, and suppose we are interested in whether english has an impact on r_before, so we’ll build a contingency table with english in the rows and r_before in the columns. Note that we’ll use a 90% confidence level and the add 2 successes and 2 failures Bayesian augmentation, and I encourage you to do this in your actual Project B Study 1 work, as well. I’ll remind you that in your Project B, we’re requiring you to have a minimum number of observations within each cell of the table that I cannot meet here with this tiny sample size.\nIf this were an actual Study 1, rather than a demonstration, I’d build a research question here, but I have decided to leave that work to you."
  },
  {
    "objectID": "sample-study1.html#describing-the-data-3",
    "href": "sample-study1.html#describing-the-data-3",
    "title": "431 Project B Sample Study 1 Report",
    "section": "7.2 Describing the Data",
    "text": "7.2 Describing the Data\nLet’s look at the 2x2 table we get.\n\ntable(sur15$english, sur15$r_before)\n\n     \n      No Yes\n  No  10   8\n  Yes 18  17\n\n\nThose names could use some work, I think.\n\nThe row names, in order, should be something like “English” (where “Yes” is now) and “Not English” with “English” first\nThe column names, respectively, should be “Prior R user” and “No Prior R”, with “Prior R User” first.\n\n\nsur15_D &lt;- sur15 |&gt;\n  select(s_id, english, r_before) |&gt;\n  mutate(english_r = fct_recode(factor(english),\n                                \"Not English\" = \"No\",\n                                \"English\" = \"Yes\"),\n         english_r = fct_relevel(english_r, \"English\"),\n         r_before_r = fct_recode(factor(r_before),\n                                 \"No Prior R\" = \"No\",\n                                 \"Prior R user\" = \"Yes\"),\n         r_before_r = fct_relevel(r_before_r, \"Prior R user\"))\n\n\nsur15_D |&gt; tabyl(english_r, r_before_r) \n\n   english_r Prior R user No Prior R\n     English           17         18\n Not English            8         10"
  },
  {
    "objectID": "sample-study1.html#main-analysis-3",
    "href": "sample-study1.html#main-analysis-3",
    "title": "431 Project B Sample Study 1 Report",
    "section": "7.3 Main Analysis",
    "text": "7.3 Main Analysis\nI strongly encourage you to use the Bayesian augmentation where we add two successes and add two failures, as recommended in Agresti and Coull, and to use 90% confidence levels. To accomplish this I’ll use the twoby2 function in the Epi package.\n\nt1 &lt;- table(sur15_D$english_r, sur15_D$r_before_r)\n\ntwoby2(t1 + 2, conf.level = 0.90) \n\n2 by 2 table analysis: \n------------------------------------------------------ \nOutcome   : Prior R user \nComparing : English vs. Not English \n\n            Prior R user No Prior R    P(Prior R user) 90% conf. interval\nEnglish               19         20             0.4872    0.3593   0.6167\nNot English           10         12             0.4545    0.2918   0.6276\n\n                                   90% conf. interval\n             Relative Risk: 1.0718    0.6701   1.7143\n         Sample Odds Ratio: 1.1400    0.4730   2.7473\nConditional MLE Odds Ratio: 1.1376    0.4174   3.1320\n    Probability difference: 0.0326   -0.1791   0.2375\n\n             Exact P-value: 1.0000 \n        Asymptotic P-value: 0.8064 \n------------------------------------------------------\n\n  # uses Bayesian augmentation, 90% confidence level\n\nNote what I did to add two observations to each cell of the table. We can draw conclusions now about:\n\nThe individual probabilities of being a prior R user in the English and non-English groups, and 90% confidence intervals for each at the top of the output, so that, for instance, we estimate the probability of prior R usage among subjects for whom English is not their best language at 0.45, with 90% confidence interval (0.29, 0.63).\nThe relative risk of Prior R use given English vs. Prior R use given non-English, which is estimated to be 1.07, and based on its 90% confidence interval is clearly not detectably different from 1 at \\(\\alpha = 0.10\\).\nThe odds ratio describing the odds of Prior R use given English vs. Non-English, which is estimated to be 1.14, and is clearly not detectably different from 1 at \\(\\alpha = 0.10\\).\nThe difference in probability of Prior R use for English vs. non-English subjects, which is estimated to be 0.033, with a 90% confidence interval of (-0.18, 0.24) and is not detectably different from 0 at \\(\\alpha = 0.10\\).\nThe chi-square test of independence, which assesses the null hypothesis of no association between language preference and prior R usage, using either Fisher’s exact test or the Pearson chi-square test (labeled asymptotic here.) The evidence does not let us reject the null hypothesis.\n\n\n7.3.1 Checking Assumptions\nSince each cell in our (non-augmented) 2x2 table is at least 5, R throws no warning messages. We should be reasonably comfortable with the chi-square test of independence here. If every cell was 10 or more, we’d be even more comfortable.\n\n\n7.3.2 What If We Wanted to Type in the Table Ourselves?\nWith the twobytwo function available in the Love-boost.R script, we can directly obtain 90% confidence intervals. For example, suppose we had the following data, pulled from our 2016 survey:\n\n\n\n2016 Survey\nDrank Tea Recently\nDidn’t Drink Tea\n\n\n\n\nNot Born in US\n21\n10\n\n\nUS Born\n20\n18\n\n\n\nSuppose we wanted to use twobytwo and the +2/+4 Bayesian augmentation (adding 2 to the count in each cell of our 2x2 table) and a 90% confidence interval for this comparison, to see whether the population proportions who drank tea recently differ between those born in and out of the US.\n\ntwobytwo(21+2, 10+2, 20+2, 18+2,\n         \"Not US Born\", \"US Born\", \"Drank Tea\", \"No Tea\",\n         conf.level = 0.90)\n\n2 by 2 table analysis: \n------------------------------------------------------ \nOutcome   : Drank Tea \nComparing : Not US Born vs. US Born \n\n            Drank Tea No Tea    P(Drank Tea) 90% conf. interval\nNot US Born        23     12          0.6571    0.5162   0.7749\nUS Born            22     20          0.5238    0.3982   0.6465\n\n                                   90% conf. interval\n             Relative Risk: 1.2545    0.9160   1.7181\n         Sample Odds Ratio: 1.7424    0.8024   3.7839\nConditional MLE Odds Ratio: 1.7299    0.7276   4.1948\n    Probability difference: 0.1333   -0.0512   0.3036\n\n             Exact P-value: 0.2561 \n        Asymptotic P-value: 0.2389 \n------------------------------------------------------"
  },
  {
    "objectID": "sample-study1.html#conclusions-3",
    "href": "sample-study1.html#conclusions-3",
    "title": "431 Project B Sample Study 1 Report",
    "section": "7.4 Conclusions",
    "text": "7.4 Conclusions\nOur primary conclusions about the study we’ve done here in Analysis D should be motivated by the fact that the 90% confidence intervals for the RR and the OR cross 1, and that the probability difference isn’t detectably different from 0, either, with 90% confidence.\nThen we’d write more about limitations and opportunities for further work, were this an actual Study 1, instead of just a demonstration."
  },
  {
    "objectID": "sample-study1.html#the-question-4",
    "href": "sample-study1.html#the-question-4",
    "title": "431 Project B Sample Study 1 Report",
    "section": "8.1 The Question",
    "text": "8.1 The Question\nWe’ll look at the association of two categorical factors we created earlier: medium_r and fiction_r in this analysis. We’re interested in whether there is an association between the ways in which subjects consumed their fiction, and the type of fiction they most enjoy. The medium_r data have three levels, and the fiction_r data have four levels. Note that we’ll use a 90% confidence level and I encourage you to do this in your actual Project B Study 1 work, as well.\nIf this were an actual Study 1, rather than a demonstration, I’d build a research question here, but I have decided to leave that work to you."
  },
  {
    "objectID": "sample-study1.html#describing-the-data-4",
    "href": "sample-study1.html#describing-the-data-4",
    "title": "431 Project B Sample Study 1 Report",
    "section": "8.2 Describing the Data",
    "text": "8.2 Describing the Data\nLet’s store this initial table of interest as table_E1\n\ntable_E1 &lt;- table(sur15$medium_r, sur15$fiction_r)\n\ntable_E1\n\n        \n         Comedy Drama Fantasy/SF Other\n  Movies      4     5          6     2\n  TV         11     5          2     4\n  Other       3     5          6     0\n\n\nWe could add the marginal totals, I suppose.\n\nsur15 |&gt;\n  tabyl(medium_r, fiction_r) |&gt;\n  adorn_totals(where = c(\"row\", \"col\"))\n\n medium_r Comedy Drama Fantasy/SF Other Total\n   Movies      4     5          6     2    17\n       TV     11     5          2     4    22\n    Other      3     5          6     0    14\n    Total     18    15         14     6    53\n\n\nNote that we don’t meet the Cochran conditions here. In particular, we still have a 0 cell, and that might motivate us to consider collapsing or removing the “Other” category from the fiction_r variable.\nNOTE: In doing your project B, I would only proceed once I’d identified variables (after whatever collapsing you decide to do) that meet the Cochran conditions (described below.)\nI’ll leave it alone for now, and see what happens, returning to this later. The research question, if I’d written would need to address whether which medium (Movies, TV or other) you like is associated with which genre (Comedy, Drama, Fantasy/SF) you prefer."
  },
  {
    "objectID": "sample-study1.html#main-analysis-4",
    "href": "sample-study1.html#main-analysis-4",
    "title": "431 Project B Sample Study 1 Report",
    "section": "8.3 Main Analysis",
    "text": "8.3 Main Analysis\n\n8.3.1 Running the Pearson \\(\\chi^2\\) Test\nWe’ll run the Pearson \\(\\chi^2\\) test using:\n\nchisq.test(table_E1)\n\nWarning in stats::chisq.test(x, y, ...): Chi-squared approximation may be\nincorrect\n\n\n\n    Pearson's Chi-squared test\n\ndata:  table_E1\nX-squared = 10.322, df = 6, p-value = 0.1117\n\n\nNote the warning, because our table does not meet the Cochran conditions.\n\n\n8.3.2 Running Fisher’s Exact Test\nNOTE: In doing your project B, I would only proceed once I’d identified variables (after whatever collapsing you decide to do) that meet the Cochran conditions (described below.) I would not run Fisher’s test.\nGiven a small overall sample size, the fisher.test command will also produce a Fisher’s exact test, which may be a little more appropriate here, given the presence of cells with small counts.\n\nfisher.test(table_E1)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table_E1\np-value = 0.0983\nalternative hypothesis: two.sided\n\n\nBased on the Fisher test, we would get only a slightly different conclusion than the Pearson test. However,\n\nOur conclusions are quite dependent on the choice of \\(\\alpha\\) level.\nNeither test is really appropriate, since we have very small cell counts, including a zero.\n\n\n\n8.3.3 Checking Assumptions - The Cochran Conditions\nThe “Cochran conditions”, which require that we have:\n\nno cells with 0 counts\nat least 80% of the cells in our table with counts of 5 or higher\nexpected counts in each cell of the table should be 5 or more\n\nWe don’t meet those Cochran conditions here. In addition, since each cell in our 3x4 table is NOT at least 5, R throws a warning message when we run the Pearson \\(\\chi^2\\) test, and since we don’t meet the Cochran conditions, the fisher.test results are questionable, as well. We should consider whether collapsing or deleting some of the rows or columns might be more reasonable. And we’ll do this next.\n\n\n8.3.4 An Association Plot for the 3x4 Table\nThe assocplot function in R produces a plot that indicates deviations from the assumption of independence of rows and columns in a two-way table. For instance, using our original table, we have:\n\nassocplot(table_E1)\n\n\n\n\n\n\n\n\nWe can see that the independence model really doesn’t work well for the cells with larger shapes here, which we note especially in the Fantasy/SF category, and to some extent in the Comedy category.\nHint: Finding a better scheme for visualizing a contingency table’s relationship to independence (or simply the table itself), especially if it’s using the gt package, would be a good idea to explore further in Analysis E, too, especially if you’re looking to learn to build savvy tables. But this is not necessary, certainly.\n\n\n8.3.5 A 2x3 Table, After Collapsing (Lumping) Some Small Rows and Columns\nSuppose we instead decided to drop down to a study of TV vs. Other media (combining Movies and Other) and also collapsed the Fantasy/SF and Other columns (so the remaining subjects form a 2x3 table), in an effort to remove zero cells, and reduce the incidence of cells with counts below 5.\nFirst, we’ll combine the Movies and Other groups to create medium_2 from medium_r using fct_recode.\n\nsur15 &lt;- sur15 |&gt;\n  mutate(medium_2 = fct_recode(medium_r, \n                                \"Not TV\" = \"Movies\",\n                                \"TV\" = \"TV\",\n                                \"Not TV\" = \"Other\"))\n\nOr, we can use the fct_lump function to lump together the two categories with the smallest overall counts directly, in creating fiction_3 from fiction_r.\n\nsur15 &lt;- sur15 |&gt;\n  mutate(fiction_3 = fct_lump(fiction_r, 2))\n\nLet’s call the collapsed table table_E2.\n\ntable_E2 &lt;- \n  table(sur15$medium_2, sur15$fiction_3)\n\ntable_E2\n\n        \n         Comedy Drama Other\n  Not TV      7    10    14\n  TV         11     5     6\n\n\nThis new 2x3 table loses some fidelity, but gains in that each cell now contains at least 5 subjects. I’ll remind you that in your Project B, we’re requiring you to have even more than that in each cell.\n\n\n8.3.6 Chi-Square Testing for the 2x3 Table\nAnd here are the results from chi-square testing…\n\nchisq.test(table_E2)\n\n\n    Pearson's Chi-squared test\n\ndata:  table_E2\nX-squared = 4.3528, df = 2, p-value = 0.1135\n\nfisher.test(table_E2)\n\n\n    Fisher's Exact Test for Count Data\n\ndata:  table_E2\np-value = 0.1483\nalternative hypothesis: two.sided\n\n\nFor the project, once all of the cells have at least 5 observations, I recommend the use of the Pearson approach, unless the table is square (# of rows = # of columns), in which case the Fisher test is also a reasonable choice. Generally, the Fisher test is more appropriate when the sample sizes are small. In this case, of course, it doesn’t matter much after collapsing cells and forming this 2x3 table. We’ll close with the association plot for this smaller table, which suggests that the independence model inverts its errors for Comedy as compared to the other two categories.\n\nassocplot(table_E2)"
  },
  {
    "objectID": "sample-study1.html#conclusions-4",
    "href": "sample-study1.html#conclusions-4",
    "title": "431 Project B Sample Study 1 Report",
    "section": "8.4 Conclusions",
    "text": "8.4 Conclusions\nUsing the collapsed table_E2 to meet the Cochran conditions, and either the Pearson or Fisher test we detect no strong association between the favorite consumption method and favorite genre. I’d also spend a bit of time talking about the results of the assocplot, I think, or at least make some effort to indicate where the independence assumption holds less well, even though it doesn’t reach the point where we can reject it with 90% confidence.\nAgain, it’s your job to identify and discuss your conclusions, as expected in the instructions for Project B Study 1. This is just a demonstration."
  },
  {
    "objectID": "self_eval.html",
    "href": "self_eval.html",
    "title": "Project B Self-Evaluation",
    "section": "",
    "text": "The self-evaluation form will appear on December 1 at https://bit.ly/431-2024-projectB-self-evaluation. If it’s after December 1, and the form isn’t available to you, please contact Dr. Love via email or Campuswire to remind him to turn it on.\nYou should complete the form after you have met with Dr. Love and given your project presentation. The deadline is the same as the deadline for your Final Report, and is posted on the Course Calendar.\nThe form is the usual sort of Google Form that Dr. Love uses for lots of things, and should take less than 15 minutes to complete. The form will ask you to reflect briefly on your project report and your presentation.\nIf you are working with a partner, each of you will need to separately complete the self-evaluation."
  },
  {
    "objectID": "study1b.html",
    "href": "study1b.html",
    "title": "Study 1 Report Specifications",
    "section": "",
    "text": "Produce a beautiful HTML report containing 8 main sections, as described below. It should include:"
  },
  {
    "objectID": "study1b.html#headings-you-should-use-in-the-study-1-report",
    "href": "study1b.html#headings-you-should-use-in-the-study-1-report",
    "title": "Study 1 Report Specifications",
    "section": "Headings you should use in the Study 1 report",
    "text": "Headings you should use in the Study 1 report\nAll of your work should be done in a fresh R project in a clean directory on your computer. - If you are working with NHANES data, your directory should include a data subdirectory, in which you will probably need to place the Love-431.R script. - If you need to ingest non-NHANES data, then your data directory should also include the raw data files.\n\nSetup and Data Ingest\n\nBe sure to load all necessary packages and ingest your data, either by reading it in with nhanesA or by reading in your raw non-NHANES data. Load the tidyverse last and do not load core packages from the tidyverse separately.\n\nCleaning the Data\n\nBe sure to review the material (including the Tips on Cleaning Data) provided in the Data Development section of this website.\nNote that it’s only necessary to clean the variables you will actually use in your four analyses below. Select only those variables (including the subject identifier) here when you create your analytic tibble.\nI also suggest applying janitor::clean_names at the start, but I wouldn’t otherwise change variable names if you’re not changing the meaning of the variables. If you want to change the names, you can, but then you must indicate that in your codebook, and do the renaming before you show the codebook.\nIf you create a new categorical variable from an existing quantitative variables, do so in this section of your report, and then refer to that work in the analyses below when you use the new variable.\n\nCodebook and Data Description\n\nThe first thing that should appear in the section is a description of the subjects of your study.\n\nAs an example of what I’m looking for, suppose that you are working with NHANES data and have identified 3500 adults between the ages of 21 and 79 who have complete data on the variables in your final data set. In that case, the description I would want to see would be: “3500 adults ages 21-79 participating in NHANES 2017-2020 with complete data on the variables listed in the table below.”\n\nIn the first subsection in this section, labeled Codebook, present a codebook where you list all of the variables you will actually use in your four chosen analyses, in the format you will use in those analyses. Do not include any other variables (besides the subject identifying code) in the codebook.\nPresent your codebook in a table, with either three or four columns.\nPlace the variable name you will use in your analyses in the left-most column. The Codebook lists all of the variables you will use in your analyses (plus the subject identifying code). If you’re working with NHANES data, you should include both SEQN (subject code) in this list.\nThe type of variable should be Quant (for quantitative variables), Binary (for two-category variables), or X-cat for multi-category variables) where X should either be 3, 4, 5 or 6, to indicate the number of levels in the variable.\nIf you’ve changed a variable name (other than the obvious changes made by clean_names) from what you imported initially from your data source, add a final column where you specify the original variable name. The original name alone is sufficient here.\n\nFor those working with NHANES data, we will already be able to tell which data set in NHANES you used to obtain this variable from your initial pull of the data with the nhanesA package, so don’t specify the data set name again here.\n\n\n\nMake sure your Codebook looks nice and is easy to read in your HTML result. - If you decide to rename any of the variables from the names provided with the raw data, you should specify your new name and the original name in your codebook. - Your codebook should also describe each of the variables you are using and specify whether they are quantitative, binary or multi-categorical. - In the second subsection (called Analytic Tibble), list your clean tibble that the codebook describes, so we can see it is a tibble. Only the variables in your Codebook should appear. - In the third and final subsection here, labeled Data Summary, provide useful descriptive summaries of each variable in your codebook other than the subject identifying code. You can use describe from Hmisc or another option of your choosing to accomplish this. You needn’t provide graphical summaries here, and include only variables that are in your codebook.\nThose first three sections should then be followed by any four of the following five sections (which will be sections 4-7 in your report)…\n\nAnalysis A: Comparing 2 Means with Paired Samples\nAnalysis B: Comparing 2 Means with Independent Samples\nAnalysis C: Comparing X Means with Independent Samples (where you’d substitute in the number of means you’re comparing for X)\nAnalysis D: Analyzing a 2x2 table\nAnalysis E: Analyzing a JxK table (where you substitute in the values for J and K)\n\n\nWithin each of the four analyses you present, I’d have four (numbered) subsections:\n\nThe Question\n\nStart by describing what you want to study, and then specify a research question (which should end with a question mark and be something you can resolve with the planned analysis.)\nDon’t boil the ocean here. You’re looking for a research question that can be reasonably addressed using your data, so it has to be pretty straightforward.\nIf you have a pre-existing belief about what will happen, before you look at the data, please feel encouraged to include a statement about that belief before specifying your question.\n\nDescribing The Data\n\nThis should start with specifications of what each of the variables you are studying in this analysis actually mean.\nYour cleaning, creation of factors and other data management activities for each analysis should already have been shown in earlier sections. Please refer back to that section and don’t repeat what you’ve already done. Be sure that the Codebook you provided describes all variables you are using in your analyses here.\nProvide numerical summaries and visualizations of interest that are relevant to the analysis, and comment on any issues you observe.\n\nMain Analysis\n\nShow your work, and comment on whatever decisions you make.\nBe sure to present and justify the assumptions you are making.\n\nConclusions\n\nAnswer your research question, by clearly linking the analytic results to what you were asking at the start.\nIf you can see a logical next step for the analysis of the question you asked, specify it. Also, if you specified a pre-existing belief about what would happen, reflect on that in light of the data."
  },
  {
    "objectID": "study1b.html#and-finally",
    "href": "study1b.html#and-finally",
    "title": "Study 1 Report Specifications",
    "section": "And finally…",
    "text": "And finally…\nAs the final section of your report (which should be section 8), include the session information using session_info() from the xfun package."
  },
  {
    "objectID": "study2a.html",
    "href": "study2a.html",
    "title": "Required Study 2 Analyses",
    "section": "",
    "text": "Once you have identified an acceptable data set, you will produce a report that demonstrates that you have accomplished the following:\n\nIdentify a quantitative outcome.\n\nFor purposes of this project, we will require your quantitative outcome to contain more than 15 unique values.\n\nIdentify a key predictor (which may be either quantitative or categorical.)\n\nIf the key predictor is categorical, it must have 3-6 categories, and each category must contain at least 30 observations.\n\nIdentify 3-8 other predictors of your outcome (demonstrating that either your key predictor or at least one of the “other” predictors is multi-categorical with 3-6 categories.)\nDefine a research question related to how effectively your key predictor predicts your quantitative outcome, while (possibly) adjusting for the other predictors.\nSteps 1-3 will yield a set of 6-11 variables (an outcome, a key predictor, 3-8 other predictors, and a subject identifier). Use those selections to create your analytic data set.\n\nYou must have between (500 and 7,500 observations if you’re using NHANES; 250 and 10,000 observations if not using NHANES) with complete data on all 6-11 variables included in your Study 2 analytic tibble. No other variables should be included in your Study 2 analytic tibble.\n\nClean the data in R, and this includes the creation of appropriately labeled (and if necessary, collapsed) factors for all categorical variables, and the investigation and decision-making regarding missing values, numbers of unique values and impossible values.\nComplete any imputation required to deal with missing data. Use single (simple) imputation with the mice package to create your imputed data. Do not impute your outcome or key predictor - you should filter to complete cases on those two variables.\nUse appropriate tools to provide useful numerical summaries for all data you will study, after all cleaning, so that these results describe the exact variables you will be modeling in the remaining work. Provide a clear note describing how much imputation you did.\nPartition the clean data into a model development (also called a model training) sample (60-80% of the data) and a model testing (also called a model validation) sample (the remaining 20-40%) using the approach recommended in the data .\n\nSuppose you had a tibble called original_data which identified its subjects with a subjID variable, and you wanted to place 75% of your data for development into training_sample and the rest into test_sample. You could do that with the following code…\n\n\n\nlibrary(tidyverse)\n\nset.seed(431) # pick a different seed than this\n\ntraining_sample &lt;- original_data |&gt; slice_sample(prop = 0.75)\n\ntest_sample &lt;- \n    anti_join(original_data, training_sample, by = \"subjID\")\n\n\nProvide appropriate, well-labeled visualizations of your outcome, and investigate potential transformations of that outcome for the purpose of fitting regression models in a useful way. Whatever transformation (including no transformation at all) should be used for the steps that follow.\nProduce two competitive models fit using least squares (rather than a Bayesian approach) for predicting your outcome using your clean data that provide evidence regarding your research question.\n\nOne of these models should be the full model with all candidate predictors included.\nYour other model should be a well-motivated subset of your full model, that at least includes the key predictor and one more predictor.\n\nAssess the performance of your two models (full model or subset) and come to a conclusion about which is better. This assessment should includes both in-sample (predictive performance and adherence to assumptions) and holdout sample (predictive quality) assessments. Be sure to attend to back-transformation properly should that be necessary, in evaluating the quality of predictions.\nUse the results of the model you chose to answer your research question, and then describe the limitations of this study and next steps you would like to pursue."
  },
  {
    "objectID": "study2c.html",
    "href": "study2c.html",
    "title": "Study 2 Sample Report",
    "section": "",
    "text": "A Study 2 Sample Report will be posted by class time on Thursday 2024-11-07."
  }
]